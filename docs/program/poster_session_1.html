<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Poster Session 1 – CERE2025 - 10th Conference of the Consortium of European Research on Emotion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../images/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-3b2160a2fc92221658aa6ab2fa9f3c79.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="../site_libs/core-js-2.5.3/shim.min.js"></script>
<script src="../site_libs/react-18.2.0/react.min.js"></script>
<script src="../site_libs/react-18.2.0/react-dom.min.js"></script>
<script src="../site_libs/reactwidget-2.0.0/react-tools.js"></script>
<link href="../site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="../site_libs/reactable-0.4.4/reactable.css" rel="stylesheet">
<script src="../site_libs/reactable-binding-0.4.4/reactable.js"></script>


<link rel="stylesheet" href="../assets/styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/logoCERE2025.png" alt="" class="navbar-logo">
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-program" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Program</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-program">    
        <li>
    <a class="dropdown-item" href="../program/index.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_16.html">
 <span class="dropdown-text">July 16</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_17.html">
 <span class="dropdown-text">July 17</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_18.html">
 <span class="dropdown-text">July 18</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-keynotes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Keynotes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-keynotes">    
        <li>
    <a class="dropdown-item" href="../keynotes/agnes_moors.html">
 <span class="dropdown-text">Prof.&nbsp;Agnes Moors</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../keynotes/jose-miguel_fernandez-dols.html">
 <span class="dropdown-text">Prof.&nbsp;José-Miguel Fernández-Dols</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../keynotes/steven_heine.html">
 <span class="dropdown-text">Prof.&nbsp;Steve Heine</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../submission/index.html"> 
<span class="menu-text">Instructions for Presenters</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-registration" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Registration</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-registration">    
        <li>
    <a class="dropdown-item" href="../attend/registration.html">
 <span class="dropdown-text">Registration Information</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://uga.azur-colloque.fr/inscription/en/232/inscription" target="_blank">
 <span class="dropdown-text">Log In the Registration Portal</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-attend" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Attend</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-attend">    
        <li>
    <a class="dropdown-item" href="../attend/venue.html">
 <span class="dropdown-text">Venue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/accommodation.html">
 <span class="dropdown-text">Accommodation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/social.html">
 <span class="dropdown-text">Social Events</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/transportation.html">
 <span class="dropdown-text">Transportation</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-people" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">People</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-people">    
        <li>
    <a class="dropdown-item" href="../people/index.html">
 <span class="dropdown-text">Organising Committee</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../people/committee.html">
 <span class="dropdown-text">Scientific Committee</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../faq.html"> 
<span class="menu-text">FAQ</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://x.com/CERE_Emotion" title="" class="quarto-navigation-tool px-1" aria-label="" target="_blank"><i class="bi bi-twitter-x"></i></a>
    <a href="https://www.instagram.com/CERE_Emotion/" title="" class="quarto-navigation-tool px-1" aria-label="" target="_blank"><i class="bi bi-instagram"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <div id="quarto-announcement" data-announcement-id="d6becb167fc673c7642ae6ac21a58c7f" class="alert alert-info hidden"><i class="bi bi-info-circle quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>A new version of the program is available <a href="https://www.cere2025.com/program/">here</a> (July 10th)</p>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Poster Session 1</h1>
</div>



<div class="quarto-title-meta column-page">

    
  
    
  </div>
  


</header>


<p>Abstracts available when clicking on “Show Abstract” buttons:</p>
<div class="cell">
<div class="cell-output-display">
<div class="reactable html-widget html-fill-item" id="htmlwidget-f74dbfba10eb5f2fd398" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-f74dbfba10eb5f2fd398">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"Title":["The Role of Integrative Emotion Regulation on Psychological Well-being: A Self-Determination Theory Perspective","Exploring Interpersonal Emotion Regulation Strategies in Parents of Children with Neurodevelopmental Conditions: A Qualitative Analysis","Emotion Regulation of Envy: The Role of Suppression and Cognitive Reappraisal","Investigating the Relationship between Social Anxiety and Face Perception","Exploring the Role of Emotion Intensity and Background on Face Emotion Recognition","Facial Mimicry Predicts Emotion Recognition Capacity","Mindfulness and Its Correlation with Youth Mental Health","The Language of Emotion and Identity in Emergencies","Processing negative stimuli and beyond: Emotional dynamics in at-risk individuals with independent or co-occurring anxiety and depression symptoms","Attentional Bias to Positive and Negative Stimuli: The Role of Intrinsic and Motivational Relevance","How do Achievement Goals Relate to Daily Personal Goal Pursuit? Emotion Regulation's Mediating Role","Is male sexual arousal an emotional state indexed by pre-attentional tendencies toward erotic pictures?","Human Values Elicit Negative Feelings And Therefore Ambivalence.","Cultural Differences in Beliefs about Emotions, Everyday Emotion Regulation and Affect Changes between UK and China","Evidence on female sexual arousal as an emotional state unconsciously triggered by sexual stimuli","Behavioural and neurophysiological correlates of enhanced L2 emotional vocabulary through targeted instruction","Odor-evoked affective responses: integrating fMRI, behavioral, olfactory, and psychometric data","How does thinking more positively change our brain?","Religious-Dependent Neural Synchronization","Emotional Vocal Instructions: Task Performance, Neural Processing, and Recognition Accuracy in Different Cultures","Prosodic Alignment and Individual's Speech Patterns as Predictors of Social Interaction Quality","The Effect of Guilt and Shame on Construal Level and Psychological Distance","Preferred and inferred empathic accuracy strategies between romantic partners","Exploration of students' use and development of emotion skills in biomedical science lab learning","Emotions in Intimate Relationships: A Cross-Cultural Perspective on Couples' Emotion Profiles and Partners' Well-being","Exploring the heterogeneity in depression through an interpersonal lens: The role of value attached to agency and communion","Feasibility of a novel open question design to assess dyadic events in daily life: a daily diary study"],"Authors":["Ataman Aslıhan","Ahmad Sam, Cai Ru Ying, Prosetzky Ingolf, Uljarevic Mirko, Zurbriggen Carmen, Gross James, Samson Andrea","Prikhidko Alena, Kushnerenko Dmitry, Qiu Yuxi","Liu Shengtong, Elliott Rebecca, Lander Karen","Peng Yuanyi, Lander Karen, Kafkas Alex","Amihai Liron, Maer Shachar, Yeshurun Yaara","Wasylkowska Maria, Kobylińska Dorota, Holas Paweł, Mituniewicz Julian, Robak Natalia","Murphy Madeline","Rendes Réka, Lang Diana Agnes, Varkonyi Gergo, Deak Anita","Boğa Merve, Koyuncu Mehmet","Katz-Vago Inbar, Benita Moti","Silva Samuel, Rosa Pedro J., Joana Carvalho","Maslamani Aysheh, Kanfo-Noam Ariel, Maio Greg, Mayo Ruth","Ge Yiran","Joana Carvalho, Rosa Pedro, Silva Samuel","Bermúdez Margaretto Beatriz, Pérez García Elisa, Trujillo Trujillo Cristian Camilo, Fernández Ángel, Sánchez Manzano María Jesús","Salagnon Mathilde, Delplanque Sylvain, Vuilleumier Patrik, Sander David","Shi Chunyan, Wirsich Jonathan, Chen Zile, Vuilleumier Patrik","Zvi Yohay, Kerem Nitai, Yeshurun Yaara","Zdanovica Anita, Trinite Baiba, Skilters Jurgis, Nakatani Chie","Aviv Eldad, Ravreby Inbal, Yeshurun Yaara","Marié Vincent, Alexopoulos Théodore","Goldberg Juli, Eyal Tal","Mura Manuela","Pirrone Davide, Schouten Anna, Ceulemans Eva, Mesquita Batja, & Verhofstadt Lesley","Kalkan-Cengiz Rana B., Verhees Martine, Sels Laura, Kuppens Peter","Carlier Chiara, Kuppens Peter, Ceulemans Eva"],"Abstract":["Given the well-established link between emotion regulation (ER) and mental health, adaptive ER processes are one of the fundamental areas of investigation in the clinical field. In this context, very recently, the concept of integrative emotion regulation (IER), which represents an open and accepting attitude towards emotional experiences and utilization of these experiences to guide behavior (Roth et al., 2019), has been proposed as an adaptive ER mode, grounded in Self-Determination Theory's organismic metatheory (SDT; Deci & Ryan, 2012). However, research on IER is still in its infancy and, to our knowledge, there is no such study, especially in a Turkish sample. Therefore, the aim of this research was to investigate the role of IER offered by SDT on a Turkish adult sample. Specifically, the research examined the relationship between IER and psychological well-being and the role of basic psychological needs satisfaction, namely autonomy, competence, and relatedness satisfaction, on this relationship as proposed by the SDT perspective. 250 participants completed an online survey including a demographic information form and questionnaires assessing the study variables. Pearson's correlation was used to examine correlations between variables of interest. Mediation analyses were performed using Jamovi's medmod module based on bootstrapping with 1000 bias-corrected and accelerated resamples. The findings indicated that IER use was positively correlated with psychological well-being, satisfaction of autonomy, competence and relatedness, and negatively correlated with depressive symptoms. Mediation analysis demonstrated that autonomy satisfaction fully mediated, while competence satisfaction partially mediated the association between IER and psychological well-being. Relatedness satisfaction was not found to have a mediator role.  The findings support the adaptive role of IER on psychological health and the role of psychological need satisfaction as an underlying mechanism between ER processes and psychological health. ","Emotion regulation (ER) is essential for mental health and well-being, yet individuals with neurodevelopmental conditions (NDCs) face unique challenges in this domain. Many individuals with NDCs require lifelong caregiver support for ER, emphasizing the importance of interpersonal ER strategies. Identifying effective interpersonal ER strategies is crucial for improving support systems, enhancing parent-child relationships, and fostering emotional development in children with NDCs. Further, gaining insights into the profiles of interpersonal ER strategies can inform family interventions and educational practices, providing tools to navigate the challenges of co-regulating a neurodivergent child. Unfortunately, despite its significance, little is known about the strategies caregivers use or their effectiveness, particularly across diverse NDCs. This study addresses this important gap and provide a comprehensive characterization of caregivers' interpersonal ER practices by employing a participatory framework. Guided by a parent advisory committee, the study ensures inclusivity and relevance. Parents will contribute to refining the research design, ensuring cultural and contextual alignment with their lived experiences. Identifying effective interpersonal ER strategies is crucial for improving support systems, enhancing parent-child relationships, and fostering emotional development in children with NDCs. These findings could inform family interventions and educational practices, providing tools to navigate the challenges of co-regulating a neurodivergent child. We used a participatory qualitative approach, integrating focus groups and semi-structured individual interviews with parents of children aged 7–17 years. Focus groups will explore shared challenges and common interpersonal ER strategies, while individual interviews will provide detailed insights into the contextual factors influencing ER strategy effectiveness and frequency. All data will undergo reflexive thematic analysis using the six-phase framework of Braun and Clarke (2006). Themes will be coded into themes and subthemes to identify patterns, with additional team discussions to ensure rigor and minimize bias. The preliminary results of the focus group and a few individual interviews will be presented through visual data graphs generated with Atlas software. By exploring interpersonal ER strategies through focus groups and individual interviews, this study bridges knowledge gaps, offering evidence-based solutions to support families and improve outcomes for children with NDCs.","Envy creates a confusing mixture of feelings toward people one sees as doing better in life in a way resembling internal conflict, which might lead to stress because envious people often do not realize that they experience envy. Some may suppress their emotions and show up in active or passive aggression toward the object of envy. Currently, there is scarce research on the emotion regulation of envy. Meanwhile, studies show that this emotion is tied to anxiety, resentment, depression, and anger. We surveyed 723 college students from an Urban, predominately Hispanic institution using Depression Anxiety and Stress Scales (DASS 42; Lovibond & Lovibond, 1995), The Benign and Malicious Envy Scale (BEMAS; Lange & Crusius, 2015), and Emotion Regulation Questionnaire (Gross & John, 2003) and found that cognitive reappraisal is negatively correlated to malicious envy. However, when people see displays of wealth and use cognitive reappraisal to change their thoughts, they become inspired rather than stressed. Stress, depression, and anxiety correlate with suppression of emotions, and suppression has a high correlation with malicious envy. The moderation effect of suppression on the relationship between malicious envy and depression differs between individuals with a religion and those without. Specifically, on average, the impact of suppression on the relationship between malicious envy and depression is more substantial for religious groups. Additionally, among people with the same level of suppression, those who have higher scores on benign envy tend to score less on stress and depression. Further studies are needed to understand the effect of various emotion regulation strategies on the relationship between envy and stress, anxiety, and depression.","Social anxiety, where people often avoid looking at faces in social situations, may be one of the reasons contributing to individual differences in face perception. Thus, the reported study explores how social anxiety relates to both facial identity and facial expression recognition ability in the same individual.  Participants (n = 144) were recruited from the University of Manchester and via Prolific. The online experiment included the Social Interaction Anxiety Scale (SIAS), State-Trait Anxiety Inventory (STAI), Beck Depression Inventory (BDI), and face recognition tasks including the Cambridge Face Memory Test (CFMT), Glasgow Face Matching Test (GFMT) and a facial expression recognition test (dynamic faces). A significant negative correlation was observed between social anxiety and facial identity recognition (r = -0.226, n = 144, p = 0.006). However, no significant relationship was found between social anxiety and facial expression recognition (rho = -0.04, n = 144, p = 0.628). Participants were divided into into a low social anxiety group (n = 77) and a high social anxiety group (n = 67) based on the SIAS cutoff score of 36. In both groups, fear was the least accurately recognised emotion at low intensity (low social anxiety: mean = 1.39; high social anxiety: mean = 1.27) and high intensity (low social anxiety: mean = 2.56; high social anxiety: mean = 2.69) on a 4-point scale. In addition, according to categorisation biases, social anxiety levels was correlated with miscategorising surprise as sadness, anger as fear, and fear as disgust among low-intensity facial expressions. Our findings indicate that participants with higher levels of social anxiety are more likely to exhibit impairments in recognising facial identity compared to facial expressions. Additionally, they demonstrate difficulties in recognising fear specifically.","The extent to which faces and background influence emotion recognition remains unclear. Previous studies have focused exclusively on the significance of either the face or the background but have overlooked the role of emotion intensity (how strongly the emotion is expressed). Hence, this research aims to systematically investigate the role of emotion intensity (on face and/or background) on facial emotion recognition. We hypothesised that the relative contribution of face and background on emotion recognition fluctuates depending on emotion intensity. In Experiment 1, 103 participants were recruited online to identify happy, sad, and neutral facial expressions presented within positive, negative, and neutral backgrounds. Happy and sad faces were morphed to depict both high and low-intensity levels. Participants rated face emotion from -4 (strongly sad) to 4 (strongly happy). Results showed that background influenced emotion recognition when the face was ambiguous (i.e., low intensity). However, as face intensity increased, it became the dominant factor, diminishing the background's influence. Experiment 2 employed eye-tracking to examine mechanisms involved in face emotion recognition, while intensity and type of background varied. Background stimuli were static or dynamic (movies) in a between-participants design. As in Experiment 1, participants in Experiment 2 viewed backgrounds and then faces superimposed onto the background. They were asked to rate face emotions on a scale from -4 (strongly sad) to 4 (strongly happy). Preliminary analyses from Experiment 2 showed that intensity and type of background also affected gaze scan paths within facial regions, supporting and extending the behavioural effects from Experiment 1. Overall, the findings indicate that background intensity and type play an important role in face emotional recognition. Faces with low emotional intensity rely more on background for accurate emotion recognition, a reliance that is heightened in dynamic backgrounds.","People tend to automatically mimic one another's facial expressions - a phenomenon known as facial mimicry, widely regarded as important for understanding others' emotions. Although its importance is well documented, there has been little exploration of whether individuals' capacity to mimic predicts their capacity for emotion recognition. To test this, thirty-five participants completed three emotion recognition tasks: (i) a facial expression and emotion word congruency task; (ii) a slow-motion facial expression video task in which participants paused once they recognized the emotion; and (iii) Film task - a complex emotion-matching task. Moreover, participants took part in a mimicry task in which they were instructed to mimic actors in four short videos displaying various facial expressions. Using a cutting-edge neural network-based method we developed to quantify synchronization, we found that accuracy and speed in mimicry each predict emotion recognition outcomes. There was a positive correlation with accuracy, such that participants that were more accurate in the synchronization task had a higher emotion recognition score. Interestingly, and counterintuitively, participants who were slower in their mimicry responses achieved higher emotion recognition scores. Remarkably, this relationship appears task independent, underscoring the robust connection between deliberate facial mimicry and the ability to recognize others' emotions. These results are novel as they show for the first time generalizability of synchronization capacity - that one's ability to accurately mimic other people's facial expressions in a deliberate synchronization task is associated with their ability to recognize emotions in separate emotional recognition tasks. Moreover, they suggest that in individuals who are good at recognizing other people's emotions, higher cognitive process may take place before actual mimicry (as reflected in slower mimicry response). Taken together, our results suggest that individual differences in mimicry capacity relate to individual differences in emotion recognition.","Mindfulness-based interventions for adolescents have recently become popular \nworldwide. Research shows they have positive effects on both mental \nand physical health. The present study aims to demonstrate the correlation \nbetween mindfulness and few of the most important factors of adolescent \ndevelopment. Mindfulness practice is considered emotionally, socially and \nacademically beneficial for adolescents fostering lasting improvements in well-\nbeing, emotion regulation, anxiety and self-compassion. \nNumber of interventions and research on mindfulness are rapidly increasing, \ntherefore there is a need for more studies showing what an important role \nmindfulness plays in everyday life. \nThis study examined the correlation between mindfulness and mental health \nsymptoms, emotion regulation difficulties, anxiety, well-being and self-\ncompassion within a sample of Polish adolescents aged 12 to 15 years (N = 122). \nThe following tools were used in the study: Child and Adolescent Mindfulness \nMeasure (CAMM), General Health Questionnaire (GHQ-12), Difficulties in \nEmotion Regulation Scale (DERS-SF), State-Trait Anxiety Inventory for Children \n(STAIC), Warwick Edinburgh Mental Well Being (WEMBWS), Self-Compassion \nScale for Youth (SCS-Y SF). \nOverall, the results show that mindfulness negatively correlates with mental \nhealth symptoms, difficulties with emotion regulation and state anxiety, while \npositively correlating with well-being and self-compassion.  ","Research aimed to compare language used in emergencies to normal conversations, with particular interest in social identity markers and emotion use. Natural language data was gathered from footage of emergencies and analysed in terms of emotion and social identity theory. The data were split into 3 groups- ‘zero' responders interacting with each other, ‘zero' and first responders talking, and first responders speaking amongst themselves. Analysis using the Linguistic Inquiry and Word Count (LIWC)-22 software produced percentage frequencies of the use of key words relating to emotion and social identity. These frequencies were then compared to the average frequencies of word use according to LIWC's test kitchen corpus of everyday conversations using Cohen's d analyses. Findings suggest use of emotional and social identity related words differ significantly between emergency situations and everyday language, and to differing degrees depending on the combination of ‘zero' and first responders involved in the interaction. Results support existing literature regarding increased levels of social identification in emergency situations compared to everyday life. They also present insights into how emotionality is different in emergencies compared to normal life, and how this may relate to social identity.","The emotional correlates of anxiety and depression have been extensively studied due to their substantial overlap. While a growing body of research has explored their relationship with affective processes, there is limited research on how co-occurring symptoms interact with emotional dynamics at subclinical level. Drawing from recent empirical findings on the core components within the anxiety-depression symptom network, we propose an expanded tripartite model, incorporating perceived control alongside positive (PA) and negative affect (NA). We hypothesized that subclinical anxiety and depression symptom severity and co-occurrence would influence the experience of NA, PA, and the level of perceived control across several emotional episodes, not limited to those elicited by negative stimuli.     The objective of the present study is to examine the differences in consecutive phases of an emotion induction task between low risk, depression risk, anxiety risk and comorbid risk groups. A sample of 284 individuals without diagnosed psychiatric disorders were presented movie clips to elicit neutral, negative and positive emotions. We inserted a recovery period to assess how participants would return to an emotional equilibrium after negative stimuli, Participants rated their emotional experience and perceived control at baseline and after each stimulus using PANAS.    Our findings indicated that participants with anxiety, depression, or comorbid risk differed in NA, PA and perceived control measured at baseline and after recovery with the largest differences between the low risk and comorbid risk groups. The results also show that NA, PA and perceived control during emotional episodes successfully predict the inclusion in low and high-risk groups presenting independent or co-occuring symptoms. By highlighting the patterns between emotional dynamics and affective symptoms, this study offers a valuable insight on how laboratory experiments could be of great importance in detecting at-risk individuals for anxiety, depression and co-occuring symptoms. ","Many studies have shown that negative stimuli – especially for threat-related content- are prioritised in the visual field compared to neutral stimuli. More recently, research on emotional attention has increasingly focused on the effects of positive stimuli. In the present study, attentional biases for negative (threat, disgust) and positive stimuli (romantic couple/baby face, food) were examined across three experiments using three different methods: spatial cueing task (Exp 1), dot probe task (Exp 2), and eye-tracking method (Exp 3). We also aimed to investigate the effects of motivational relevance on attention by manipulating participants' hunger state, in addition to examining intrinsic relevance of stimuli. In the first two experiments, an attentional bias was found for threat-related stimuli, whereas no attentional advantage was observed for stimuli with positive content. In the final experiment, results from the eye-tracking study revealed attentional biases toward both positive and negative stimuli in both early (initial orientation) and later (disengagement) stages of attention. However, disgust stimuli had enhanced attentional advantage compared to other emotional content in the both components of attention. The effects of motivational processes on attention—specifically, attention bias to food stimuli in hungry participants—were only observed in later attentional mechanisms. Overall, the results seem to support the relevance hypothesis; however, the disgust advantage in attention needs to be discussed in detail.","Background: When striving to attain their academic goals, students often experience setbacks that elicit negative emotions. Recent research reveals that the emotion regulation strategy of emotional integration (i.e., volitional exploration of emotions as they arise) predicts goal progress, while emotional suppression (i.e., efforts to hide or ignore emotions) negatively predicts these outcomes. However, little is known about the antecedents of these distinct emotion regulation strategies. Aim: This research proposes that the type of overarching goal students endorse dictates the type of emotion regulation strategies they use during goal striving. Specifically, it explores whether mastery and performance goals predict different emotion regulation strategies when navigating setbacks, ultimately affecting their goal attainment, well-being, progress, and effort. Method: Study 1 (daily diary) involved 366 American undergraduates, and Study 2 (experience sampling) included 187 Israeli undergraduates, all preparing for an exam. Both studies included baseline questionnaires on achievement goals and daily reports on goal progress, effort, well-being, and emotion regulation. Results: In Study 1, cross-level mediation analysis demonstrated that global performance goals were associated with daily emotional dysregulation, which in turn predicted reduced goal effort, decreased progress, and heightened depressed mood. Conversely, global mastery goals were linked to daily emotional integration, predicting increased goal effort, enhanced progress, and lower levels of depressed mood. Study 2, using multi-level modeling, revealed that morning performance goals predicted mid-day emotional dysregulation, which subsequently led to diminished daily progress and an elevated depressed mood. Additionally, global performance goals were found to predict mid-day emotional suppression, which was associated with increased depressed mood. In contrast, morning mastery-approach goals predicted mid-day emotional integration, which in turn predicted effort and progress toward the goal and less depressed mood. Conclusion: Mastery goals predicted emotional integration and positive goal outcomes, while performance goals predicted emotional dysregulation, suppression, and poorer outcomes, including increased depressed mood.","Background: Early conceptualizations of sexual arousal considered it an emotional response state prompted by exposure to erotic cues. The saliency effect of erotic cues was expected to be detected at the pre-attentional level of information processing, signaling human tendencies toward reproduction. Such an effect has been tested mainly in men, but studies reveal inconsistent result patterns across samples and methodologies.\n\n Aim and Methods: This study aimed to contribute to this research frame by testing the effects of three exposure conditions: (1) erotic images (male and female nudes); (2) non-erotic images (dressed men and women); and (3) neutral/objects images through a breaking continuous flash suppression task (b-CFS), in men. The b-CFS is a task aimed at capturing pre-attentional tendencies toward stimuli, hinting on their emotional saliency. Forty-seven cis-gender, heterosexual men participated in this study and were assigned to all exposure conditions. Results: After applying a Linear Mixed Model approach and controlling for low-level features of stimuli, findings revealed no main effects of exposure conditions on pre-attentional tendencies, i.e., reaction times toward the detection of stimuli. Additionally, Pearson's correlations showed no significant associations between reaction times toward the detection of erotic cues (nudes) and men's sexual excitation and sexual inhibition propensities.\n\n Conclusion: Contrary to theoretical expectations, men's pre-attentional responses captured by a b-CFS task did not support the emotional saliency effect often attributed to erotic cues. Findings align with empirical data challenging existing theoretical assumptions regarding automatic appraisal of sexual cues, pointing to the complexities underpinning the onset, maintenance, and function of sexual arousal in men.","Values are abstract ideals that serve as guiding principles in one's life. As inherently positive and desirable concepts, values are seen as motivators for actions and behaviors. However, research has largely ignored the possibility that values may elicit negative feelings despite being explicitly important to us. In the current study we aim to examine this possibility. Across two studies, 800 hundred participants over 18 years(M=41.6,SD=13.7) from the UK completed a questionnaire in which they were asked to indicate their level of positive/negative feelings towards a comprehensive list of values and then report the importance of these values to them. The results support our argument by showing that people can have negative feelings towards their values and that people can feel both positive and negative emotions towards their values simultaneously, which means feeling ambivalence. By using a mixed-effect model, our results revealed that less ambivalence values predicted higher ratings for value importance. This research contributes to the field of values on multiple levels. Theoretically, it will uncover new insights about values, such as the existence of negative emotions towards them, the presence of ambivalence towards values. These findings may inspire future studies to explore the effects of ambivalence on people's well-being, behaviors, cognition, and their affect.","Emotion beliefs shape individuals' motivation to regulate emotional experience, and cultural context influences how emotions are understood. Our previous cross-sectional study found that controllability belief predicted regulation strategy use at all four stages of Gross's (1998) process model, while usefulness and acceptability beliefs were only associated with use of suppression. Some of these associations were stronger for either Chinese or UK participants. The present study attempted to replicate these results using a 15-day daily diary study, rather than cross-sectional data. British (N = 80) and Chinese (N = 88) participants provided 2453 valid responses. We assessed how emotions beliefs affected the use of six strategies (situation modification, avoidance distraction, rumination, cognitive reappraisal, suppression) and their impact on daily affect. We also tested the association between regulation flexibility and affect. Chinese participants reported stronger emotion beliefs, consistent with prior findings. However, British participants reported more overall emotion regulation than Chinese participants. Chinese participants reported greater use of avoidance, cognitive reappraisal and suppression for positive emotions, while British participants applied these strategies more for negative emotions. Our multilevel models showed that increased daily use of avoidance, distraction, suppression and rumination was associated with heightened negative affect, controlling for previous day's affects. We found cross-lagged effects from previous day's affect and present strategy use, showing that individuals with more negative affects displayed higher level of strategy uses the next day. Results also revealed that greater controllability and acceptability beliefs about negative emotions predicted less variability in negative affect, with Chinese participants reporting stronger effect. Further, cultural differences moderated the association between between-strategy variability on negative affect, suggesting that flexibility in regulation strategy use may be beneficial, particular for Chinese participants. Our findings advance knowledge about the role of emotion beliefs as a motivational factor in emotion regulation and help to explain cultural differences.","Background: Sexual arousal has been defined as an emotional state underpinning sexual response. Information-processing models of sexual response consider that sexual arousal develops from the unconscious appraisal of sexual stimuli and progresses toward stages of overt sexual behavior. Sexual arousal as an emotional state is expected to be indexed by the privileged allocation of pre-attentional/unconscious resources toward sexual stimuli. Yet, evidence of the unconscious appraisal of sexual stimuli in women lacks empirical evidence; the onset of female sexual arousal remains a topic of debate. \nAim and Methods: The current study aimed to collect evidence on the unconscious processing of sexual stimuli (male and female nudes), as opposed to non-sexual (dressed male and female characters) and neutral (objects) stimuli, in cisgender, heterosexual women. Forty-seven women performed a breaking continuous flash suppression task (b-CFS); for each stimulus condition (sexual, non-sexual, and neutral condition), its upside-down version allowed the disentangling of the effects of low-level features. \nResults: Data were analyzed through a Linear Mixed Model approach. Findings revealed that the sexual stimulus condition did not affect pre-attentional responses, as indexed by women's reaction times toward the images. Furthermore, follow-up Pearson's correlations showed that women's reaction times toward sexual cues were not associated with participant's propensity to get sexually aroused or sexually inhibited. \nConclusion: In all, despite theoretical assumptions that consider female sexual arousal as an emotional state emerging at the unconscious level of information processing, findings do not support such a claim. Indeed, female sexual arousal likely develops through a complex chain of psychosocial events, being shaped by a series of learning and socializing processes.","Foreign languages are often learned in formal and restricted contexts, which can limit the emotional resonance of vocabulary in the second language (L2). This phenomenon, referred to as \"disembodied L2,\" likely affects the integration, use and pragmatics involved in foreign language communication. The present study sought to investigate behavioural and neurophysiological evidence for this disembodied representation of L2 emotional vocabulary and to examine how specific instructional methods focusing on emotional vocabulary might modulate these responses. A group of 28 Spanish undergraduate students of the Degree of English Studies participated in two classroom-based training sessions focused on emotional English vocabulary. Training sessions consisted of various generative exercises using a set of 36 English words (12 positive, 12 negative, 12 neutral). Before and after the training, participants underwent a lexical decision task in which the 36 trained English words were randomly presented alongside an additional set of 36 non-trained English words and 72 pseudowords. Both behavioural data and electrophysiological activity (via 64-channel EEG) were recorded during the tasks. Linear mixed-effects (LME) modeling revealed a significant training x phase x valence interaction for latency data. Specifically, reaction times were faster in post-training phase compared to pre-training, being such reduction greater for trained than non-trained stimuli and particularly for emotional (positive and negative) than neutral words. Furthermore, accuracy data showed a significant training effect, with trained words exhibiting a higher accuracy rate than non-trained stimuli. Preliminary ERP data showed differential training effects across positive and negative words at early (~175ms) and late (550ms) time windows, compatible with the modulation of EPN and LPP components, related to emotional processing. These findings demonstrate the effectiveness of targeted instructional methods in enhancing the lexico-semantic representation and processing of L2 emotional vocabulary, highlighting the importance of developing well-designed training programs to promote a more efficient L2 use.","Olfaction holds a distinctive position among sensory modalities in eliciting emotions, given its close association with the limbic system and a direct connection between the primary olfactory cortex and the amygdala (Gottfried et al., 2002). Although previous imaging studies in humans have explored representations of affective valence and arousal, these dichotomous dimensions may not capture the richness of odor-evoked emotions. We aim to assess the neural representation of olfactory feelings, using a model with six specific dimensions (i.e., the Geneva Emotion and Odour Scale, GEOS). This tool was designed and validated to collect odor-related emotions, reflecting diverse adaptive functions (Chrea et al., 2009; Delplanque et al., 2012; Ferdenzi et al., 2013). We hypothesise that distinct and unique neural patterns will be associated with each GEOS dimension, providing insight into the functional characterisation of brain processing of odour-elicited feelings, beyond the hedonic dimension. To investigate this, 100 healthy adults were recruited for a functional Magnetic Resonance Imaging (fMRI) study where they were exposed to 50 everyday odors (e.g., foods, products, cosmetics) with varying olfactory profiles. Participants rated each odor using GEOS during scanning, to capture the elicited feelings. Covariates related to individual differences in olfactory perception, emotional abilities, and affective states were collected through pre-scanning subjective questionnaires, including Importance of Olfaction questionnaire (Croy et al., 2009), Clobert Adult Sensitivity Scale (Gauvrit et al., 2023), Rotterdam Emotional Intelligence Scale (Pirsoul et al., 2022), Profile Of Mood States (Fillion & Gagnon, 1999), and the Sniffin' Sticks test to objectively assess olfactory function. Data collection and analysis are ongoing. By linking brain activity to odor-elicited feelings, subjective and objective measures of olfactory perception, emotional abilities, and affective states, this study aims to provide a comprehensive understanding of how the brain encodes affective responses to odors and how these representations may vary across individuals.","Reappraisal is an intentional attempt to change emotion through reconstrual or repurposing. Previous studies revealed that using reappraisal to decrease negative emotion will induce a reduction in late positive potential (LPP) amplitudes, a decrease in amygdala activity, increases in frontal theta oscillations and relative left frontal activity. However, most existing studies focus on manipulating regulation goals rather than manipulating different reappraisal tactics. In our study, we want to reveal the differences between positive reappraisal (reinterpret the cause, outcome and consequence in a more positive way) and less negative reappraisal (reinterpret in a less negative way). Seventeen university students with healthy mental states were recruited to perform an emotion regulation task, in which they need to watch or reappraise the emotion that are triggered by the pictures (40 neutral and 120 negative, from the Nencki Affective Picture System) according to the instructions. After each picture, they rated on positive emotion, negative emotion and arousal scales. At the same time, brain oscillations were measured using a 64-channel electroencephalography system and skin conductance level was measured with Biopack system. Results indicated that both positive reappraisal and less negative reappraisal reduced arousal, negative emotion and increased positive emotion. Less negative reappraisal is more effective in decreasing arousal level and negative emotion than positive reappraisal. Although positive reappraisal and less negative reappraisal seem to have a difference in early ERP components in frontal areas, and a difference in early LPP in parietal areas. There is a time lag between when the trigger was recorded and when the picture was presented the screen, therefore, we need to calibrate for each trial each participant in ERP analysis. The experiment and analysis is still ongoing, we are looking forward to the following results.","Emotions play a significant role in how individuals process and interpret their surroundings. When individuals share similar emotional experiences, they tend to exhibit synchronized neural responses, reflecting shared understanding. This study examines how emotional processing related to religious-sensitive content influences neural synchronization, particularly across different religious affiliations. We recruited 62 participants and divided them into three groups based on their religiosity: Religious, Secular, and Ex-Religious (ExRe). While undergoing functional Magnetic Resonance Imaging (fMRI), participants watched videos containing both religiously sensitive and neutral content. Additionaly, participants filled a questionnaire reffering to the explicit emotions elicited by each video. The results revealed higher in-group neural synchronization within the Religious group, particularly in the Default, Control, Attention, and Somatomotor networks, suggesting a deeper emotional resonance and shared understanding of the narratives. Interestingly, although the ExRe group reported similar emotional responses to the Secular, they exhibited stronger neural synchronization with the Religious group, including regions related to emotional processing. This finding suggests that early-life religious experiences continue to influence emotional processing and neural responses, even after a significant change in belief system. Overall, these findings suggest that emotional responses to religious content can foster stronger neural synchronization within groups. The study highlights the enduring impact of early socio-cultural environments on emotional and neural processes, providing insights into how shared emotional experiences can shape group identity and neural representations.","Affective prosody, which conveys emotions such as anger and happiness through vocal tone, plays a crucial role in communication both within and across cultures. This study examines the effects of affective prosody on response time (RT), accuracy, and neural processing during a manual joystick movement task, as well as the cross-cultural recognition of affective prosody. In a vocally guided task-performance study, forty-five participants responded to emotionally spoken instructions indicating spatial directions (up, down, left, right) delivered in angry, happy, or neutral tones. The results showed that angry prosody elicited faster RTs compared to neutral and happy instructions, though no significant differences in accuracy were observed, likely due to the task's low cognitive demands. Furthermore, the effect of angry prosody on RT persisted into subsequent neutral trials, highlighting the lasting influence of affective prosody on performance. Additionally, differences between emotional and neutral conditions in ERP components were observed across multiple electrode sites, particularly in late components (ranging from 500–1300 ms post-stimulus presentation). The cross-cultural component of this study explores how emotions expressed in the Latvian language are perceived by individuals from diverse linguistic and cultural backgrounds. Vocal stimuli include words, syllables, and phonemes spoken in angry, happy, and neutral prosody. Students from multiple European countries are participating in an online emotion recognition task, where they listen to each sample and assign an emotional label (angry, happy, sad, surprised, neutral). The inclusion of additional emotional categories allows for the exploration of whether other emotional dimensions emerge and how they vary across cultures. Data collection is currently ongoing to ensure that data will be gathered and analyzed in time for presentation at the conference. These findings contribute to a deeper understanding of how emotional prosody influences behavioral and neural responses during task execution and how cultural background affects emotion recognition.","Prosodic patterns—acoustic features of speech such as intonation, rhythm, and speaking durations—are fundamental to social interactions, conveying emotions, intentions, and levels of engagement that often transcend the literal meaning of words. This study investigates how individual's prosodic features and dyadic prosodic alignment predict self-assessed interaction quality in first-time social encounters that progressively transitioned from casual to highly intimate discussions. A total of 120 participants, forming 60 same-gender unfamiliar dyads, engaged in the 'Fast Friends' protocol—a structured dialogue designed to foster interpersonal connection by gradually deepening the intimacy between interlocutors. Participants then rated the interaction quality using a set of questions aimed at evaluating their perceived Goodness of Interaction (GOI). Results revealed that an Elastic Net regression model that included prosodic features (e.g., pitch variability, mean pitch, speech rate, and speaking time) explained 28.5% of the variance in GOI scores, identifying individual pitch variability and alignment in pitch variability as the most predictive features. These findings suggest that greater variability in pitch reflects expressiveness and emotional engagement, while alignment in pitch variability signals synchronization and mutual attunement—both critical elements for fostering rapport and connection. In contrast, speech rate and its alignment had negligible effect on GOI scores. These findings highlight the intricate role of prosody in social interactions, demonstrating how individual expressiveness and interpersonal synchronization jointly enhance perceptions of interaction quality. By leveraging machine learning techniques and exploring diverse communicative aspects, our results point to a fundamental unique role of pitch variability and pitch variability alignment, in social bonding.","According to Construal Level Theory (CLT; Trope & Liberman, 2010), a stimulus/object can be mentally represented in a more or less abstract way depending on its psychological distance (emcompassing the temporal, spatial, social, and hypothetical dimensions). CLT posits a bidirectional link: the farther the stimulus, the more abstract its representation, and vice-versa. Previous research suggests emotions influence construal level, often distinguishing between \"basic\" and \"self-conscious\" emotions, assumed to induce low and high construal levels, respectively. However, some theories (e.g., Tracy & Robins, 2004) propose a finer distinction within these categories : taking the case of self-conscious emotions, for example, guilt is linked to the negative evaluation of a specific behavior and should induce a low construal level, while shame is associated with a negative evaluation of the global self and should induce a high construal level. Three pre-registered experiments aimed to replicate Han et al.'s (2014) findings on these emotions' effects on construal level and extend them to psychological distance. Participants recalled autobiographical episodes (shame vs. control vs. guilt), then completed the Behavior Identification Form (Vallacher & Wegner, 1989) and a psychological distance task (Fiedler et al., 2012, 2015). Study 1 found an effect of guilt, but not shame, on both measures. Studies 2 and 3 failed to replicate this effect. However, a language concreteness index in Study 3 (Brysbaert et al., 2014) suggested an opposite pattern. Complementary analyses of autobiographical recalls from Studies 1 and 2 indicated that guilt may lead to a higher, rather than lower, construal level than a control state. These findings challenge the initial hypotheses but align with CLT predictions.","Understanding in romantic relationships is vital for well-being, trust, and satisfaction. However, accurately perceiving a partner's feelings can be challenging. While research suggests that directly asking a partner about their feelings (perspective getting) is the most effective strategy, many believe that imagining oneself in a partner's shoes (perspective taking) will help, despite that strategy being found to be less effective for accuracy. In our study, we explored the strategies individuals prefer for understanding their partner's feelings and what they believe their partner uses. We also examined how the discrepancy between these preferences and inferences impacts perceived understanding and relationship satisfaction.\n\nAcross Studies 1 and 2, we found that individuals favor both perspective-taking and perspective-getting as strategies for their partner to use. However, they often do not perceive their partner as engaging in perspective-taking. This gap was negatively correlated with relationship satisfaction. Study 3 delved into the different motivations behind the preference for each strategy, shedding light on the nuanced dynamics of empathic understanding in relationships.","Implementing learning activities that equip undergraduate students with social-emotional skills is fundamental to providing a comprehensive education that prepares students to navigate the challenges of academic life and their future careers. Research into the dynamics involved in scientific discovery and the learning of scientific disciplines has largely focused on cognitive aspects. Contrastingly, emotions have been marginalised as detrimental to a logical and analytical approach, and key elements of learning and discovery rooted in the emotional sphere—including motivation, social interactions and creativity—have been overlooked. To understand how emotions are perceived and used as a source of information in a scientific learning setting, we investigated the social-emotional skills that Biomedical Science undergraduate students develop while undertaking a laboratory research module by working in small groups. A qualitative, phenomenological approach was used to explore students' self-reported awareness of emotion in lab settings and their ability to recognise and regulate emotion in themselves and others. Data were collected with a qualitative survey and interviews. Findings suggest that a learning environment that fosters creativity, initiative, agency, and learning from errors—embedded in a context with complex social interactions—promotes the experience of a broad range of emotions and is suitable for embedding social-emotional learning. While working in the lab, students reported experiencing both situated and social emotions, attempted strategies for regulation and used emotion to navigate challenging experiences. Notably, some participants were unaware of the emotional skills they were developing, suggesting that signposting social-emotional learning activities could promote awareness. Important aspects emerging from this research indicate that embedding social-emotional learning effectively in science-based curricula, requires emotional scaffolding from peers and teachers, along with opportunities for iteration and reflection to create a safe space where students can experiment with emotion and refine strategies to develop intra and interpersonal emotion regulation skills.",null,null,null],"Group":["Emotion Regulation 1 - Chair: Aslıhan Ataman","Emotion Regulation 1 - Chair: Aslıhan Ataman","Emotion Regulation 1 - Chair: Aslıhan Ataman","Facial Expression Recognition - Chair: Liron Amihai ","Facial Expression Recognition - Chair: Liron Amihai ","Facial Expression Recognition - Chair: Liron Amihai ","Mental health/Mindfulness - Chair: Madeline Murphy ","Mental health/Mindfulness - Chair: Madeline Murphy ","Mental health/Mindfulness - Chair: Madeline Murphy ","Motivation/values and Emotion - Chair: Samuel Silva ","Motivation/values and Emotion - Chair: Samuel Silva ","Motivation/values and Emotion - Chair: Samuel Silva ","Motivation/values and Emotion - Chair: Samuel Silva ","Motivation/values and Emotion - Chair: Samuel Silva ","Motivation/values and Emotion - Chair: Samuel Silva ","Neuronal correlates of emotions - Chair: Beatriz Bermúdez Margaretto ","Neuronal correlates of emotions - Chair: Beatriz Bermúdez Margaretto ","Neuronal correlates of emotions - Chair: Beatriz Bermúdez Margaretto ","Neuronal correlates of emotions - Chair: Beatriz Bermúdez Margaretto ","Neuronal correlates of emotions - Chair: Beatriz Bermúdez Margaretto ","Emotions and social relations 1 - Chair: Manuela Mura","Emotions and social relations 1 - Chair: Manuela Mura","Emotions and social relations 1 - Chair: Manuela Mura","Emotions and social relations 1 - Chair: Manuela Mura","Emotions in Daily Life: Interpersonal Perspectives Across Contexts and Cultures - Chair: Davide Pirrone","Emotions in Daily Life: Interpersonal Perspectives Across Contexts and Cultures - Chair: Davide Pirrone","Emotions in Daily Life: Interpersonal Perspectives Across Contexts and Cultures - Chair: Davide Pirrone"]},"columns":[{"id":"Title","name":"Title","type":"character","minWidth":400},{"id":"Authors","name":"Authors","type":"character","minWidth":200},{"id":"Abstract","name":"","type":"character","sortable":false,"cell":[{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]}]},{"id":"Group","name":"Group","type":"character","minWidth":200}],"groupBy":["Group"],"searchable":true,"pagination":false,"defaultExpanded":true,"onClick":"function(rowInfo, column) {window.alert(rowInfo.values['Abstract'])}","highlight":true,"rowStyle":"function(rowInfo) {\n    if (rowInfo.subRows.length) {\n      return { borderBottom: '3px solid #E84E0F' }\n    }\n  }","dataKey":"d9e85ad8e1dfbf22e08cc2450578f394"},"children":[]},"class":"reactR_markup"},"evals":["tag.attribs.onClick","tag.attribs.rowStyle"],"jsHooks":[]}</script>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/www\.cere2025\.com\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><img src="https://www.univ-grenoble-alpes.fr/uas/SITEUI/UGA_LOGO_PAGE_INTERIEURE/logo_epe_blanc_sans_marges.svg" class="img-fluid" width="150"></p>
</div>   
    <div class="nav-footer-center">
<p>#CERE2025<br> Université Grenoble Alpes, July 16-18, 2025<br></p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.isre.org/mpage/cere">
      <i class="bi bi-globe" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/CERE_Emotion">
      <i class="bi bi-twitter-x" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.instagram.com/CERE_Emotion/">
      <i class="bi bi-instagram" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>