<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Poster Session 2 – CERE2025 - 10th Conference of the Consortium of European Research on Emotion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../images/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-3b2160a2fc92221658aa6ab2fa9f3c79.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="../site_libs/core-js-2.5.3/shim.min.js"></script>
<script src="../site_libs/react-18.2.0/react.min.js"></script>
<script src="../site_libs/react-18.2.0/react-dom.min.js"></script>
<script src="../site_libs/reactwidget-2.0.0/react-tools.js"></script>
<link href="../site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="../site_libs/reactable-0.4.4/reactable.css" rel="stylesheet">
<script src="../site_libs/reactable-binding-0.4.4/reactable.js"></script>


<link rel="stylesheet" href="../assets/styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/logoCERE2025.png" alt="" class="navbar-logo">
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-program" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Program</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-program">    
        <li>
    <a class="dropdown-item" href="../program/index.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_16.html">
 <span class="dropdown-text">July 16</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_17.html">
 <span class="dropdown-text">July 17</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_18.html">
 <span class="dropdown-text">July 18</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-keynotes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Keynotes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-keynotes">    
        <li>
    <a class="dropdown-item" href="../keynotes/agnes_moors.html">
 <span class="dropdown-text">Prof.&nbsp;Agnes Moors</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../keynotes/jose-miguel_fernandez-dols.html">
 <span class="dropdown-text">Prof.&nbsp;José-Miguel Fernández-Dols</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../keynotes/steven_heine.html">
 <span class="dropdown-text">Prof.&nbsp;Steve Heine</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../submission/index.html"> 
<span class="menu-text">Instructions for Presenters</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-registration" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Registration</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-registration">    
        <li>
    <a class="dropdown-item" href="../attend/registration.html">
 <span class="dropdown-text">Registration Information</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://uga.azur-colloque.fr/inscription/en/232/inscription" target="_blank">
 <span class="dropdown-text">Log In the Registration Portal</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-attend" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Attend</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-attend">    
        <li>
    <a class="dropdown-item" href="../attend/venue.html">
 <span class="dropdown-text">Venue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/accommodation.html">
 <span class="dropdown-text">Accommodation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/social.html">
 <span class="dropdown-text">Social Events</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/transportation.html">
 <span class="dropdown-text">Transportation</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-people" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">People</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-people">    
        <li>
    <a class="dropdown-item" href="../people/index.html">
 <span class="dropdown-text">Organising Committee</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../people/committee.html">
 <span class="dropdown-text">Scientific Committee</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../faq.html"> 
<span class="menu-text">FAQ</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://x.com/CERE_Emotion" title="" class="quarto-navigation-tool px-1" aria-label="" target="_blank"><i class="bi bi-twitter-x"></i></a>
    <a href="https://www.instagram.com/CERE_Emotion/" title="" class="quarto-navigation-tool px-1" aria-label="" target="_blank"><i class="bi bi-instagram"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <div id="quarto-announcement" data-announcement-id="d6becb167fc673c7642ae6ac21a58c7f" class="alert alert-info hidden"><i class="bi bi-info-circle quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>A new version of the program is available <a href="https://www.cere2025.com/program/">here</a> (July 10th)</p>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Poster Session 2</h1>
</div>



<div class="quarto-title-meta column-page">

    
  
    
  </div>
  


</header>


<p>Abstracts available when clicking on “Show Abstract” buttons:</p>
<div class="cell">
<div class="cell-output-display">
<div class="reactable html-widget html-fill-item" id="htmlwidget-1e6c956bb242a83a47f3" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-1e6c956bb242a83a47f3">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"Title":["Exploring Emotion Regulation through the Integration of ER Flexibility and ER Skills Models: A Network perspective","Is it easier to reduce your sadness or disgust? On the effectiveness of emotion regulation as an effect of strategy used, emotion and HRV","Bridging Cognitive Control and Emotion Regulation: New Findings from Meta-Analyses","FEEL the Difference: Concurrent and Prospective Validity of Emotion-Specific Regulation Strategies","Emotion recognition in Mild Cognitive Impairment (MCI): The role of face processing and emotional intelligence.","Emerging Trends in Anxiety Sensitive Artificial Intelligence","Too Real to Feel? Examining Avatar Realism in Digital Emotion Regulation Training","A Gamepad-based Interface for Continuous Real-Time Emotion Tracing","Transformative Learning and Artificial Intelligence: Emotions as Catalysts for Learning Processes","Comparing Theoretical Models of Co-Occurring Emotions Using Multi-Modal Time Series Data","The Role of Awareness in Unconscious Emotional Processing: Evidence from CFS and SCR Responses","Can Optical Heart Rate Measurement Track Emotional Processes in Children? Evaluating the Link Between Photoplethysmography and Emotional Processes in Preschool Children","I React to Bodies but not Faces, Replication and Extension of Aviezer et al., 2012","Mood modulations of affective word processing: a predictive perspective of encephalographic data","The Human Affectome","Perceived Threat as a Driver of Hate: Lessons from the 2024 U.S. Election in a Global Context","The Hidden Cost of Psychological Threat: How Economic Stress Fuels Emotional Suppression and Undermines Well-being","Climate change and hope ratings modulate valence and arousal ratings of emotional images","The Role of Emotion in Updating Expectations for the Distant Future","To synchronise or not to synchronise? Investigating physiological synchrony in emotional performances","Task switching during nonverbal interactions promotes cardiac synchrony, while social anxiety reduces it. Considering the role of reciprocal attention in physiological synchrony","Partner stress decreases cardiac synchronization in romantic couples","Harmful to Relationships, Helpful in Adversity: The Nuanced Role of Psychopathic Traits in Partner Support, Stress and Physiological Synchronisation"],"Authors":["Rolland-Carlichi Emma, Baeyens Céline, Bortolon Catherine","Kobylińska Dorota, Mituniewicz Julian","Schulze Katrin, Mueller Ilka, Holt Daniel V., Putz Sam, Barnow Sven, Pruessner Luise","Van Bockstaele Bram, Soenens Bart, Prinzie Peter","Mahadevan Rachana, Giesers Naomi, Liman Thomas, Witt Karsten, Hildebrandt Andrea, Roheger Mandy","Vanhée Loïs","Naumann Eva","Pathak Divya, Srinivasan Narayanan","Heidelmann Marc-André","Küppers Sebastian, Lange Jens","Gonul Turkmen Selen, Booth Robert","Lorusso Sonja, Nischak Pablo, Diebold Tatiana, Burkhardt Bossi Carine, Harel Ori, Pruessner Jens, Perren Sonja","Pillaud Nicolas, Chassaing-Monjou Clément, Cottin Adèle","Kopaeva Ekaterina, Blomberg Johan, Roll Mikael","Yu Alessandra N. C.","Aumer Katherine","Valor Segura Inmaculada, Alonso Ferres María, Guzmán María Teresa","Plonski Paul, Durgin Frank","Orphal Lara, Pinquart Martin","Goldsack Roydon, Hyland Nicola & Eisenbarth Hedwig","Boukarras Sarah, Placidi Valerio, Rossano Federico, Era Vanessa, Aglioti Salvatore Maria & Candidi Matteo","Denk Bernadette F., Meier Maria, Ocklenburg Sebastian, Packheiser Julian, Wienhold Stella, Volkmer Nina, Gaertner Raphaela J., Klink  Elea S.C., Dimitroff Stephanie J., Benz Annika B.E. & Pruessner Jens C.","Hissey Aaron, Hammond Matt & Eisenbarth Hedwig"],"Abstract":["Nardelli et al. (2023) proposed a theoretical model of emotion regulation (ER) in which specific ER skills, based on the Berking & Whitley's ACE Model (2014) support different stages of the ER flexibility model (Bonanno & Burton, 2013). However, this remains untested empirically. Thus, for this study, we aim to apply network analysis to identify which ER skills are most strongly associated with and central within the dimensions of ER flexibility (Borsboom, 2017; Fried et al., 2017). Our first objective is to use network analyses to test specific model-based hypotheses. We hypothesize positive associations between context sensitivity and feedback components with the skills of awareness, clarity, and understanding, and between the repertoire component and the skills of modification, acceptance, self-support, and confrontation. We also hypothesize that the feedback dimension will correlate with the modification skill. We also use network analyses to additional, unanticipated findings. Participants recruitment and data collection are in progress. We will conducted Gaussian Graphical Model (GGM; Epskamp et al., 2018) network analyses in R (version 4.4.2) and results will be presented.This approach highlights the importance of integrating ER flexibility and ER skills to deepen our understanding of emotion regulation flexibility and guiding future research and therapeutic interventions combining both ER flexibility and ER skills.","We investigated how emotion regulation (ER) effectiveness - operationalized via self-report subjective evaluation and electrodermal activity (EDA) - is influenced by the kind of emotion induced (sadness vs. disgust), emotion regulation strategy used (reappraisal vs. distraction vs. acceptance vs. no regulation control condition) and individual dispositions (resting state heart rate variability). In the laboratory experiment, after a training phase, 100 participants were instructed to regulate their emotions before watching negative NAPS photographs. Four blocks of sad photos and four blocks of disgusting photos were chosen on the basis of former studies. Before each block, the instruction to implement one of the ER strategies was exposed. EDA and HRV were measured. Participants also filled in several questionnaires for assessing their ER abilities, ER flexibility and positive and negative mental health. The results partially confirmed our predictions giving support to a novel ER flexibility framework. Effectiveness of ER differed based on strategy used, regulated emotion and baseline HRV. Sad photographs elicited lower negative emotions than disgusting photographs. The effects of ER strategy used were stronger for regulating disgust. Distraction and reappraisal were more effective than acceptance and no strategy for regulating both sadness and disgust.","Emotion regulation is a fundamental aspect of human adaptive functioning, and its connection to cognitive processes has long been of interest. However, the precise nature of the relationship between emotion regulation and cognitive control remains elusive, with a scarcity of systematic reviews and meta-analyses addressing this link. This study fills this research gap by conducting meta-analyses to systematically examine the relationship between individual differences in cognitive control – including the components of inhibition, memory updating, and set-shifting – and four emotion regulation strategies. Data were analysed from 52 studies on reappraisal, 63 on rumination, 30 on suppression, and 21 on worry. Preliminary results revealed a small positive association between reappraisal and cognitive control (r = 0.13, 95% CI [0.09, 0.18]) and a small negative correlation between rumination and cognitive control (r = −0.11, 95% CI [−0.15, −0.06]). No significant associations were found for suppression (r = 0.02, 95% CI [−0.05, 0.08]) or worry (r = −0.07, 95% CI [−0.15, 0.01]). Detailed results for specific cognitive control components will be presented. The small observed effects linking cognitive control with reappraisal and rumination suggest a modest relationship. In contrast, the lack of associations with suppression and worry challenges not only the notion of a strong but also a universal connection between emotion regulation and cognitive control—particularly when assessed using abstract tasks measuring inhibition, working memory, and shifting. Our meta-analytic findings offer new insights into the cognitive underpinnings of emotion regulation, highlighting the complexity of this relationship. Future research should investigate the flexibility of emotion regulation across contexts and how cognitive control influences this adaptability.","Emotion regulation plays a crucial role in psychological well-being. The FEEL-E questionnaire differentiates between putatively adaptive and maladaptive emotion regulation strategies across three negative emotions: Anger, fear, and sadness. However, little is known about whether and how these emotion regulation strategies for each emotion differentially predict psychological problems such as aggression, anxiety, and depression. Our study examines the psychometric properties of the FEEL-E, aiming to (1) determine whether individuals use different emotion regulation strategies depending on the emotion being regulated, and (2) investigate how these strategies uniquely and differentially predict psychological problems. We analysed the correlations between emotion regulation strategies and psychological problems, the factor structure of the FEEL-E, and how factor scores predict concurrent and prospective relationships between emotion regulation strategies and psychological problems. Participants completed the FEEL-E and the Adult Self Report (assessing aggression, anxiety, and depression) in two waves of the Flemish Study on Parenting, Personality, and Development. In wave 1 (N = 350), we found strong positive correlations between emotion regulation strategies for the three emotions, indicating that people do not differentiate between emotions when regulating them. Adaptive strategies were negatively related to all psychological problems, while maladaptive strategies were positively related to all psychological problems. However, emotion-specific regulation strategies were not differentially correlated with aggression, anxiety, or depression. Our analysis of the factor structure and longitudinal data collection (wave 2, current N = 304) is ongoing and will provide further insights into prospective relationships between emotion regulation strategies and psychological problems. While our initial results suggest that maladaptive strategies are broadly associated with increased psychopathology and adaptive strategies with decreased psychopathology, regardless of the emotion being regulated, further analyses will clarify whether emotion-specific strategies offer additional concurrent and prospective value for the prediction of psychological problems.","Abstract:  Introduction: Emotion recognition ability is essential for social cognition, enabling humans to interpret and respond to emotion-related cues effectively. However, so far it is not known how underlying cognitive deficits, including face processing, affect emotion recognition, particularly in patients with Mild Cognitive Impairment (MCI). Methods:  Sixty participants (patients with MCI = 30, healthy controls (HC) = 30), aged 50-86 years (M= 66.8, SD= 8.66) completed the emotion composite task (ECT), facial composite task (FCT), and emotion stroop task to measure emotion recognition (ER), face processing, and emotional arousal, respectively. Additional cognitive tests and an emotional intelligence (EI) questionnaire were included. Results:  Overall, patients with MCI performed about half of a standard deviation worse on ECT as compared with HC (β=-0.47), however, this effect was not significant. Emotion-specific analysis showed that anger recognition of the patients with MCI was particularly impaired (β=-0.86***). FCT showed a small positive effect on anger recognition (β=0.28*), indicating that participants with better facial processing skills recognized anger better. Self-control (β= 0.63), emotionality (β=0.71), and sociability (β=0.46) predicted ECT, indicating that participants with higher EI performed better in the ER task. Both FCT (β=0.17) and EI (β =0.98) contributed to the ER performance similarly in HC and MCI. Discussion:  While our results did not show significant overall ER performance deficits in patients with MCI, they showed specific impairments in anger recognition. Face processing ability contributed to anger recognition, suggesting that interventions, for example using ambulatory assessment, could train patients with MCI to maintain their face processing skills, especially for emotions that require more detailed processing, such as anger. Furthermore, emotion regulation training would help patients with MCI focus on real-world emotional cues, thereby improving their emotion recognition abilities. ","Anxiety, defined as the primary emotional response to uncertainty, is fascinating in its ambivalence, being both a catalyst and an inhibitor of intellectual faculties towards addressing potential, imagined threats. Widely recognized as a significant source of individual suffering --especially in the context of mental well-being issues like depression and self-harm; anxiety also imposes substantial societal costs. These costs, which include ill health and lost productivity, scale to trillions of euros annually. Furthermore, anxiety is deeply political, being both a side effect and an enabler of power imbalances, disproportionately affecting already disadvantaged groups. Despite anxiety's pervasive influence on individual decision-making and its profound societal impact, research on systematically accounting for anxiety in operational contexts (e.g., within workplace settings) remains limited. Similarly, there is little focus on explicitly organizing efforts to address anxiety, such as sensing, anticipating, avoiding, mitigating, or responding to its triggers. This contribution explores how computational methods can address these gaps and expand the research landscape on anxiety. Specifically, we examine emerging trends in Anxiety-Sensitive Artificial Intelligence (AnxSAI), which focuses on AI systems equipped with models of anxiety. AnxSAI systems may be human-centric, adapting to anxiety-related factors (e.g., identifying anxiety-inducing elements in an environment, predicting how a system's actions might affect the anxiety levels of individuals), or simulating human-like deliberative processes and behaviors influenced by anxiety (e.g., artificial companions, agents in social simulations). Key findings on practical development and interdisciplinary relevance of AnxSAI will be introduced, such autonomous agents, active inference models, and large language models (LLMs) for research on human empathy, futures studies, and digital humanities.","Background:\n Digital mental health interventions increasingly incorporate embodied conversational agents, such as avatars, to enhance user engagement and support emotion regulation—a key transdiagnostic factor in psychiatric disorders. However, the effects of avatar realism on intervention efficacy remain insufficiently explored, particularly in the context of digital emotion regulation training. This study examines the impact of avatar realism on training outcomes, user perception, and self-disclosure. Methods:\n A total of 203 participants completed a 30-minute digital emotion regulation training session facilitated by a conversational avatar. Participants were randomly assigned to one of four conditions: (1) ultra-realistic human avatar, (2) abstract toon-style human avatar, (3) robot avatar, or (4) control (audio waveform animation). Training effectiveness, user perception of the avatar, and self-disclosure were assessed using self-report measures, including the Client Satisfaction Questionnaire (CSQ), emotion ratings, and items from the Unified Theory of Acceptance and Use of Technology (UTAUT). Results:\n ANOVA analyses revealed a significant main effect of condition on training satisfaction, with the ultra-realistic human avatar receiving lower ratings than all other conditions. Furthermore, interactions with the ultra-realistic avatar were rated as significantly more anxiety-inducing and less pleasant than those with other avatars. Positive emotions increased across all conditions except in the ultra-realistic avatar group during a gratitude exercise. Additionally, participants in the ultra-realistic avatar condition reported significantly lower levels of self-disclosure compared to all other conditions. Conclusion:\n The findings suggest that ultra-realistic human avatars may induce discomfort, thereby reducing engagement and intervention effectiveness, aligning with the uncanny valley hypothesis. These results have important implications for optimizing avatar design in digital mental health applications to maximize user acceptance and therapeutic efficacy.","Emotional states fluctuate dynamically in response to stimuli, requiring precise real-time measurement. Existing methods, such as slider-based and joystick-based systems, often lack intuitive responsiveness and introduce delays. We designed an interface that offers enhanced response ergonomics, allowing real-time visual feedback by continuously mapping emotional states (valence and arousal). Our gamepad-based interface overlays directly on stimuli and enables two-dimensional (x-axis: valence; y-axis-arousal) tracking of emotional states in real time. Participants get visual feedback through a red dot in the two-dimensional space as they continuously map their emotional state, concluding with a final arousal and valence response via the trigger button.We implemented a staircase training protocol to mitigate response biases arising from device unfamiliarity while systematically acclimating participants to the interface. The protocol begins with basic motor skill training involving gamepad handling and control, followed by iterative practice using a perceptual random dot motion task. Performance metrics are assessed at each stage to ensure proficiency before advancing to the main task. Experiment1 validated the interface against traditional slider methods using 61 images from the NAPS database in a two-block (order counterbalanced) design. In Block1, participants rated the images using traditional slider responses. Block2 used our overlay interface. The ratings from both methods showed high consistency for valence (r = 0.721) and arousal (r = 0.77).Additionally, Bland-Altman analysis revealed minimal systematic bias, confirming measurement equivalence between our novel protocol and established slider-based rating methods. Experiment2 extends this validation to dynamic video stimuli to track fluctuations in valence and arousal values with participant-specific calibrations, minimizing center-drift biases inherent in gamepad-based responses. We applied a low-pass filter to reduce high-frequency noise in motor movement data, preserving critical signal features.This interface advances emotion dynamics research by providing a robust and precise tool for continuous emotion annotation and has application in fields requiring real-time high temporal resolution data.","Transformative learning, as described by Koller (2012), is not the mere accumulation of knowledge but a deep process of changing interpretative patterns. Learners face situations that challenge their previous perspectives, requiring them to develop new ways of understanding (Kokemohr 2007). Emotions are central to this process, acting as catalysts for change by triggering cognitive dissonance and prompting reflection. For transformative learning to occur, the unknown must be perceived as incomprehensible (Waldenfels 1997). The emotional response to unfamiliarity—such as irritation, uncertainty, or discomfort—often initiates transformation. When an experience cannot be integrated into one's existing worldview and self-concept, emotional pressure emerges, compelling individuals to question established patterns of interpretation (Marotzki 1999). This emotional tension fuels reflection and the development of new perspectives, making education an emotionally shaped encounter with the unknown (Koller 2012). As Artificial Intelligence (AI) becomes increasingly integrated into education, a key question arises: how does it impact emotional learning experiences (Wunder 2021)? AI systems can support transformative learning by adapting to learners' emotions through personalized feedback, emotion-recognition algorithms, and adaptive learning techniques. For instance, intelligent tutoring systems can create cognitive conflicts by exposing learners to unfamiliar perspectives (Zawacki-Richter et al. 2020). AI-enhanced learning environments can also regulate emotions by mitigating uncertainty or fostering motivation (Kasneci et al. 2023). However, to what extent can AI truly understand and respond to emotional reactions? How do algorithmic decisions influence emotional engagement in learning? This poster presentation examines the intersection of transformative learning, emotions, and AI from an interdisciplinary perspective. It highlights AI's potential to foster emotional learning while critically evaluating its impact on transformative education and the ethical implications of digitalization.","Many situations evoke multiple emotions at the same time. Lange and Zickfeld's (2023) work showed that from four parsimonious, formal emotion theories, the network theory of emotions explains these co-occurrences best. According to this theory, emotions co-occur because their respective networks of interacting emotion components overlap. Of note, Lange and Zickfeld's research is preliminary as participants provided only self-ratings of their emotional experiences (i.e., feelings, cognitions, motivations, physiological changes, expressions) once after watching arousing videos, neglecting the dynamic and person-specific nature of emotions. We aimed to replicate and extend their findings by (1) incorporating multi-modal emotion measures, (2) testing implications of a multidimensional approach to co-occurring emotions, and (3) comparing emotion theories separately for each participant. Participants watched four videos eliciting awe and fear simultaneously. We continuously assessed appraisals, heart rate, respiration rate, skin conductance level, facial expressions, and piloerection, complementing the single-timepoint self-ratings that were already part of Lange and Zickfeld's study. We expect to finish data collection early in February. Ultimately, this study contributes to developing a formal theory of co-occurring emotions.","Research suggests that unconscious emotional stimuli can elicit physiological and evaluative responses, yet the role of awareness in moderating these effects remains unclear. This study examined how emotions rendered unconscious through continuous flash suppression (CFS) influence skin conductance responses (SCR) and evaluations of novel faces. Forty-two undergraduate students (M = 21.98, SD = 4.21) participated in the study, and a two-alternative forced choice (2AFC) task was used to assess CFS efficacy, categorizing participants into aware (performers >50%) and unaware (guessers ≤50%) groups. Participants were exposed to disgust, fear, anger, and neutral expressions, while their SCR and post-trial face ratings were recorded. A 4 (emotion: disgust, fear, anger, neutral) × 2 (awareness: aware, unaware) mixed factorial ANOVA revealed that while emotion and awareness did not independently affect SCR, their interaction approached significance (p = .057, η² = .098), suggesting that emotional expressions may elicit stronger physiological responses in unaware participants. Descriptive statistics suggested that unaware participants showed numerically longer latencies across emotional conditions, with the largest difference occurring for neutral expressions, but this effect did not reach significance. In contrast, novel face ratings did not differ significantly across emotions or awareness levels (all p > .3). The overall mean face rating was 4.60 (SD = 0.96), with unaware participants ratings slightly higher (M = 4.90, SD = 1.19) than aware participants (M = 4.50, SD = 0.87), though this difference was not significant. These findings contribute to ongoing discussions on the dissociation between physiological responses and conscious affective evaluations, suggesting that while awareness may play a role in autonomic reactivity, its influence was not robustly significant. The results indicate that unconscious emotional processing may elicit physiological changes in some cases, but this does not necessarily translate into explicit affective judgments. ","Preschool age is a crucial period for developing emotional competence, with deficits linked to long-term negative outcomes. However, studying emotions in young children is challenging, as their emerging regulation skills make emotions less observable, and their limited awareness and vocabulary hinder self-reports. Heart rate is a common physiological marker of emotional intensity and regulation, traditionally measured using electrocardiography (ECG) with chest electrodes. In contrast, wrist-worn sports watches offer a less invasive, more familiar alternative, increasing acceptance by children. These devices rely on photoplethysmography (PPG), which measures pulse rate by detecting blood volume changes in tissue via light sensors. While heart rate is well established in emotion research, the benefit of PPG-derived pulse rate as an indicator of emotion-related arousal remains unclear. To investigate this, 94 children from 16 German-speaking Swiss playgroups (Mage = 3.75 years, 58.62% female) participated in three standardized emotion-eliciting tasks designed to induce frustration, anticipation, and dynamic emotional shifts and one tablet-based emotion knowledge test serving as a physiological baseline. Each session was video-recorded, with children wearing Polar Vantage V2 watches for continuous physiological monitoring. Trained raters assessed emotional expression based on the recordings using the Emotion Regulation Scoring System. Linear mixed models will examine (1) whether pulse rate is associated with observed emotional expression, and (2) whether pulse rate differs between the emotion-eliciting tasks. If pulse rate reliably reflects emotion-related arousal, we expect higher pulse rates to correspond with more intense emotional expression during the emotion-inducing tasks. Additionally, we expect pulse rates to be highest during the frustration task, lower during anticipation, even lower during dynamic emotional shifts, and lowest in the baseline condition. If we can demonstrate that pulse rates reliably capture emotional processes in children, they could enhance field research and expand studies on institutional factors, such as peer influence and group dynamics. Keywords: Photoplethysmography (PPG), preschool children, emotional arousal, emotion expression  ","How do we truly assess the emotions of others? While numerous theories have highlighted the central role of facial expressions in evaluating emotions, some studies have challenged the ability to gauge others' feelings based solely on their faces (Aviezer et al., 2012). These studies suggest that we preferentially use bodies rather than faces to assess others' affective states. The aim of the present work is to replicate and extend these findings. A first preregistered experiment replicated the results obtained by Aviezer et al. (2012, Exp. 1). That is, the results (NExp1 = 194 - https://osf.io/h9pkn/?view_only=3716295e91614fbbb4d5706b3668923a) show that participants identified the expressed emotion only when bodies are presented on the picture. We conduct four other experiments to extend these results to other tasks (i.e., affective priming, affective misattribution procedure, feeling, and action tendencies). The results of the four preregistered experiments (NExp2 = 134 - https://osf.io/k6w2r/?view_only=5038a177e3944a53ad550ee1e8ae7965, NExp3 = 209 - https://osf.io/q4sut/?view_only=56fd0d79eb8e448a80539dbd3a0dedb3, NExp4 = 304 - https://osf.io/6zhdx/?view_only=3f33925fa59640afb68aec4b89b9eaed, NExp5 = 194 - https://osf.io/3n8m7/?view_only=505d186662614112a6b0813a2ea5cc41) show that stimuli presenting only bodies, rather than faces, consistently produce these classic effects found in the literature. Overall, these findings highlight that faces do not seem to be discriminative in detecting emotions, nor do they elicit affective reactions when affective stimuli are extreme. These results thus support the idea that context is predominant in the detection of emotions.","An individual's emotional state, or mood, has been shown to influence perception, attention, decision-making and other cognitive processes. Its effects extend to language processing, where it is seen as part of the pragmatic context. If a linguistic expression is non-neutral in itself, mood might augment or attenuate its perceived valence. Motivated by a lack of clarity regarding the nature and temporal dynamics of mood-valence interaction, we conducted an exploratory EEG study to find whether an individual's mood might change the temporal profile of emotional word processing. We looked at the interaction of mood and valence in a control and two mood-induced conditions over three consecutive time windows in a semantic categorisation task focusing on early processing, where data is inconsistent. In the three mood conditions, twenty-two healthy participants performed valence ratings of neutral, positive and negative words. Non-parametric cluster-based permutation tests were performed for the selected time windows and components to determine an unbiased scalp distribution. Results revealed an interaction in a happy but not sad mood. High valence words elicited greater N1 amplitudes (130-190 ms) in the control condition, but none in happy. In the subsequent time window (200-300 ms), congruence effects persisted: low valence words were attended to in a happy mood, as seen in increased P2 amplitudes, and high valence words were facilitated, as less negative EPN slopes show. In predictive-coding frameworks, mood is seen as a hyperprior that affects both the model and incoming signal. Happy moods make the model more precise and the input controllable. In this view, the results are interpreted as indicators of prediction error marked by the N1 and subsequent model update in the P2 time-window, with reduced amplitudes signalling a better-fitted model. A lack of a reverse pattern in a sad mood speaks in favour of asymmetrical mood effects on cognition.","Theoretical perspectives in the interdisciplinary field of the affective sciences have proliferated rather than converged due to differing assumptions about what human affective phenomena are and how they work. These metaphysical and mechanistic assumptions—shaped by academic context and values—have dictated the field's affective constructs and operationalizations. However, a foundational premise concerning the purpose of affective phenomena can guide us to a common set of metaphysical and mechanistic assumptions. In the capstone paper for the special issue “Towards an Integrated Understanding of the Human Affectome”, a collaboration among 173 affective researchers from 23 countries, we converge on a nested teleological principle for human affective phenomena: from the broadest purpose of an organism (to ensure viability), to complex organisms (to execute operations), then mechanisms of meaning (to enact relevance), and finally their human-specific projectivity (to entertain abstraction). Based on this principle, human affective phenomena can collectively be considered as algorithms that either adjust based on the comfort zone (affective concerns) or monitor those adaptive processes (affective features). Those for affective concerns indicate the adaptive relevance of the environment. These can be organized hierarchically according to distance from metabolic impact (immediate to distal), including physiological and operational concerns, and can also act as global summaries of concerns across time, such as trajectory and optimization. Those for affective features monitor how the adaptive process is going on a momentary basis, include valence (how well or not) and arousal (the extent to which various systems are mobilized), and can inform global concerns. This teleologically-grounded framework offers a principled agenda for organizing existing perspectives as well as generating new ones. Ultimately, we hope the Human Affectome brings us a step closer to not only an integrated understanding of human affective phenomena—but an integrated field for affective research through a forum for discussion.","Hate in social science is often linked to perceived threats to identity, values, or safety. Allport (1954) associated prejudice and dehumanization with group-based threats, while Sternberg's \"Duplex Theory of Hate\" (2003) emphasized fear and anger as amplifiers. The 2024 U.S. election served as a catalyst for hate, with political opponents framed as existential or moral threats. Research by Fischer et al. (2018) and Halperin (2011) suggests that moral violations and political contexts magnify threat perceptions, while Aumer and Bahn (2016) argue that hate functions as a self-protective response. This study tested whether hate correlates more strongly with perceived threat than with prejudice or dehumanization. A total of 645 participants were recruited via Amazon Turk, with a final sample of 499 after data cleaning. Participants were divided into four groups—Democrats Pre-Election, Democrats Post-Election, Republicans Pre-Election, and Republicans Post-Election. Of these, 301 completed the survey before the election, and 198 after. The sample leaned Democratic (n = 366) over Republican (n = 133). Participants rated political figures and parties on measures of hate, perceived threat, and dehumanization, with the latter assessed through beliefs about targets' “evolved” status. Across groups, hate correlated with perceived threat (r = .53 to .62) significantly more than with prejudice (r = .0 to .23) or dehumanization (r = -.2 to .0). Fisher's Z-tests confirmed these differences (p < .01). Findings underscore perceived threat as the primary driver of hate, aligning with theoretical models from Allport to contemporary research. Hate arises when individuals perceive existential or moral threats, reinforcing political hostility. Addressing threat-based narratives may be key to reducing polarization and fostering societal understanding.","Objectives. When individuals feel psychologically threatened—whether due to financial instability or health concerns—their well-being often suffers. However, the underlying mechanisms driving this relationship remain unclear. This study investigates emotional suppression as a key pathway through which psychological threats may erode well-being. We propose that suppressing emotions in response to economic or health-related stressors can be counterproductive, draining self-regulatory resources and impairing problem-solving and social support. Specifically, we examine whether emotional suppression mediates the link between psychological threat, and overall well-being and health. Methods. A nationally representative sample of Spanish adults (N = 969) participated in the study. The average participant was 52 years old (range: 18–89), with a gender distribution of 55% male and 45% female. Household income averaged €2,469 per month, and all participants were in a romantic relationship at the time of the study. Results. Our findings reveal a striking pattern: individuals facing greater economic (but not health-related) psychological threat were significantly more likely to engage in emotional suppression. In turn, this suppression was strongly associated with diminished life satisfaction, lower happiness and positive affect, poorer physical health, and heightened levels of depression and anxiety. Crucially, these effects persisted even after accounting for gender, age, and socio-economic status. Conclusions. These findings highlight the hidden emotional cost of financial stress and the pivotal role of emotion regulation in shaping mental and physical health outcomes. When individuals suppress their emotions in response to economic hardship, they may inadvertently amplify their distress rather than alleviate it. Interventions that encourage healthier emotion regulation strategies could offer a powerful buffer against the negative effects of economic insecurity, ultimately promoting resilience and well-being in the face of psychological threat.","Theories of emotion and emotion regulation posit temporally recursive cycles between components of emotional episodes, including appraisals and subjective feelings (McRae & Gross, 2020; Scherer, 2022). Changing appraisals can modulate emotion, such as thinking about a situation as less relevant to oneself (Opitz et al., 2015). Despite substantial research on appraisal, less is known about the effect of relevance contexts other than one's own goals and well-being on emotion processes. We hypothesized that rating how much an emotional stimulus represents climate change or hope would affect valence and arousal ratings. United States adults (N = 298) from Prolific viewed 90 images, equally split between negative images of climate change, positive images of nature, and neutral images. After four seconds, response scales appeared, sequentially, below the image. Participants randomly assigned to the control condition rated only valence and arousal. In two experimental conditions, participants rated how much the image represented either climate change or hope, then rated valence and arousal. We tested effects with two linear mixed-effects models with random intercepts for participant and image, and a random slope for image type by participant. Fixed effects were condition (treatment coded), image type (sum-to-zero coded), and the interactions. Rating climate change increased negativity and negative emotion, whereas rating hope increased negativity but upregulated positive arousal and downregulated negative arousal. Results suggest that thinking about relevance to contexts beyond the self can affect emotion. These evaluations may involve processes similar to affect labelling, which, like hope ratings, can downregulate negative (Lieberman et al., 2011) and upregulate positive emotion (Vlasenko et al., 2021). More research would be necessary to compare relevance contexts to appraisals of relevance to one's own goals (Lazarus, 1991; Moors, 2017; Scherer, 2009). Lazarus, R. S. (1991). Cognition and motivation in emotion. American Psychologist, 46(4), 352–367. http://dx.doi.org/10.1037/0003-066X.46.4.352 Lieberman, M. D., Inagaki, T. K., Tabibnia, G., & Crockett, M. J. (2011). Subjective responses to emotional stimuli during labeling, reappraisal, and distraction. Emotion, 11(3), 468–480. https://doi.org/10.1037/a0023503 McRae, K., & Gross, J. J. (2020). Emotion regulation. Emotion, 20(1), 1. https://doi.org/10.1037/emo0000703 Moors, A. (2017). Appraisal Theory of Emotion. In V. Zeigler-Hill & T. K. Shackelford (Eds.), Encyclopedia of Personality and Individual Differences (pp. 1–9). Springer International Publishing. https://doi.org/10.1007/978-3-319-28099-8_493-1 Opitz, P. C., Cavanagh, S. R., & Urry, H. L. (2015). Uninstructed emotion regulation choice in four studies of cognitive reappraisal,. Personality and Individual Differences, 86, 455–464. https://doi.org/10.1016/j.paid.2015.06.048 Scherer, K. R. (2009). The dynamic architecture of emotion: Evidence for the component process model. Cognition & Emotion, 23(7), 1307–1351. https://doi.org/10.1080/02699930902928969 Scherer, K. R. (2022). Theory convergence in emotion science is timely and realistic. Cognition and Emotion, 36(2), 154–170. https://doi.org/10.1080/02699931.2021.1973378 Vlasenko, V. V., Rogers, E. G., & Waugh, C. E. (2021). Affect labelling increases the intensity of positive emotions. Cognition and Emotion, 35(7), 1350–1364. https://doi.org/10.1080/02699931.2021.1959302","People update their expectations when presented with new information, but emotions may systematically influence how much they revise their beliefs. Positive emotions have been linked to greater openness to new information, while negative emotions have been associated with skepticism. However, it remains unclear whether such effects extend to expectations about an uncertain future. This study investigates whether emotions (positive, negative, neutral) influence the degree to which people update their expectations about future world events after receiving probabilistic expert feedback. Participants are randomly assigned to one of three emotional conditions (positive, negative, neutral) and complete an emotion induction task, selecting which of two emotional images (from the OASIS database) better fits an emotional quote. They then estimate the probability (0-100%) that a given statement about the world in 50-100 years will come true (e.g., “As automation takes over most professions, many countries will introduce a universal basic income.”). Next, they receive expert expectations about the event's likelihood, described as 75% reliable, and subsequently update their probability estimates. This sequence—emotional induction, prior expectation, expert feedback, updated expectation—is repeated for 15 statements. Finally, participants complete a PANAS questionnaire and a cognitive conflict detection task. To ensure statements were neutral in valence and moderately realistic, a pretest (N = 47) assessed 120 statements on perceived likelihood and desirability. The pretest confirmed that desirability significantly predicted likelihood ratings, and the main study includes 15 statements rated as neither desirable nor undesirable, with average likelihood ratings. Expectation updating will be modeled using linear mixed-effects models, testing whether (1) emotional states influence the magnitude and direction of updating (toward or away from expert feedback), and (2) emotions lead to systematic deviations from Bayesian updating. Exploratory analyses will examine (3) whether cognitive conflict detection moderates expectation updating, (4) whether the magnitude of expectation violation (the absolute difference between prior beliefs and expert feedback) modulates the effect of emotion and (5) whether emotional states influence trust in expert feedback, measured by calculating the weight of the expert's feedback in the participant's update. This study integrates emotional states and Bayesian updating to examine how emotions shape expectation revision about uncertain, real-world questions. Data collection will begin in February 2025, and results will be available at the time of the conference.",null,null,null,null],"Group":["Emotion Regulation 2 - Chair: Emma Rolland-Carlichi","Emotion Regulation 2 - Chair: Emma Rolland-Carlichi","Emotion Regulation 2 - Chair: Emma Rolland-Carlichi","Emotion Regulation 2 - Chair: Emma Rolland-Carlichi","Emotion Regulation 2 - Chair: Emma Rolland-Carlichi","HCI / AI and Emotion - Chair: Eva Naumann","HCI / AI and Emotion - Chair: Eva Naumann","HCI / AI and Emotion - Chair: Eva Naumann","HCI / AI and Emotion - Chair: Eva Naumann","Emotion, Psychophysiology, Multimodality - Chair: Alessandra N. C. Yu","Emotion, Psychophysiology, Multimodality - Chair: Alessandra N. C. Yu","Emotion, Psychophysiology, Multimodality - Chair: Alessandra N. C. Yu","Emotion, Psychophysiology, Multimodality - Chair: Alessandra N. C. Yu","Emotion, Psychophysiology, Multimodality - Chair: Alessandra N. C. Yu","Emotion, Psychophysiology, Multimodality - Chair: Alessandra N. C. Yu","Politics and Emotion - Chair: Katherine Aumer ","Politics and Emotion - Chair: Katherine Aumer ","Politics and Emotion - Chair: Katherine Aumer ","Politics and Emotion - Chair: Katherine Aumer ","In sync or not: What are the correlates of physiological synchronicity? - Chair: Hedwig Eisenbarth","In sync or not: What are the correlates of physiological synchronicity? - Chair: Hedwig Eisenbarth","In sync or not: What are the correlates of physiological synchronicity? - Chair: Hedwig Eisenbarth","In sync or not: What are the correlates of physiological synchronicity? - Chair: Hedwig Eisenbarth"]},"columns":[{"id":"Title","name":"Title","type":"character","minWidth":400},{"id":"Authors","name":"Authors","type":"character","minWidth":200},{"id":"Abstract","name":"","type":"character","sortable":false,"cell":[{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]}]},{"id":"Group","name":"Group","type":"character","minWidth":200}],"groupBy":["Group"],"searchable":true,"pagination":false,"defaultExpanded":true,"onClick":"function(rowInfo, column) {window.alert(rowInfo.values['Abstract'])}","highlight":true,"rowStyle":"function(rowInfo) {\n    if (rowInfo.subRows.length) {\n      return { borderBottom: '3px solid #E84E0F' }\n    }\n  }","dataKey":"df3c61be77971347ff7a6cbc085dc37e"},"children":[]},"class":"reactR_markup"},"evals":["tag.attribs.onClick","tag.attribs.rowStyle"],"jsHooks":[]}</script>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/www\.cere2025\.com\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><img src="https://www.univ-grenoble-alpes.fr/uas/SITEUI/UGA_LOGO_PAGE_INTERIEURE/logo_epe_blanc_sans_marges.svg" class="img-fluid" width="150"></p>
</div>   
    <div class="nav-footer-center">
<p>#CERE2025<br> Université Grenoble Alpes, July 16-18, 2025<br></p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.isre.org/mpage/cere">
      <i class="bi bi-globe" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/CERE_Emotion">
      <i class="bi bi-twitter-x" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.instagram.com/CERE_Emotion/">
      <i class="bi bi-instagram" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>