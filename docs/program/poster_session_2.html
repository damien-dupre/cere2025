<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Poster Session 2 – CERE2025 - 10th Conference of the Consortium of European Research on Emotion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../images/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-3b2160a2fc92221658aa6ab2fa9f3c79.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="../site_libs/core-js-2.5.3/shim.min.js"></script>
<script src="../site_libs/react-18.2.0/react.min.js"></script>
<script src="../site_libs/react-18.2.0/react-dom.min.js"></script>
<script src="../site_libs/reactwidget-2.0.0/react-tools.js"></script>
<link href="../site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="../site_libs/reactable-0.4.4/reactable.css" rel="stylesheet">
<script src="../site_libs/reactable-binding-0.4.4/reactable.js"></script>


<link rel="stylesheet" href="../assets/styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/logoCERE2025.png" alt="" class="navbar-logo">
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-program" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Program</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-program">    
        <li>
    <a class="dropdown-item" href="../program/index.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_16.html">
 <span class="dropdown-text">July 16</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_17.html">
 <span class="dropdown-text">July 17</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_18.html">
 <span class="dropdown-text">July 18</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-keynotes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Keynotes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-keynotes">    
        <li>
    <a class="dropdown-item" href="../keynotes/agnes_moors.html">
 <span class="dropdown-text">Prof.&nbsp;Agnes Moors</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../keynotes/jose-miguel_fernandez-dols.html">
 <span class="dropdown-text">Prof.&nbsp;José-Miguel Fernández-Dols</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../keynotes/steven_heine.html">
 <span class="dropdown-text">Prof.&nbsp;Steve Heine</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../submission/index.html"> 
<span class="menu-text">Instructions for Presenters</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-registration" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Registration</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-registration">    
        <li>
    <a class="dropdown-item" href="../attend/registration.html">
 <span class="dropdown-text">Registration Information</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://uga.azur-colloque.fr/inscription/en/232/inscription" target="_blank">
 <span class="dropdown-text">Log In the Registration Portal</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-attend" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Attend</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-attend">    
        <li>
    <a class="dropdown-item" href="../attend/venue.html">
 <span class="dropdown-text">Venue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/accommodation.html">
 <span class="dropdown-text">Accommodation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/social.html">
 <span class="dropdown-text">Social Events</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/transportation.html">
 <span class="dropdown-text">Transportation</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-people" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">People</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-people">    
        <li>
    <a class="dropdown-item" href="../people/index.html">
 <span class="dropdown-text">Organising Committee</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../people/committee.html">
 <span class="dropdown-text">Scientific Committee</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../faq.html"> 
<span class="menu-text">FAQ</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://x.com/CERE_Emotion" title="" class="quarto-navigation-tool px-1" aria-label="" target="_blank"><i class="bi bi-twitter-x"></i></a>
    <a href="https://www.instagram.com/CERE_Emotion/" title="" class="quarto-navigation-tool px-1" aria-label="" target="_blank"><i class="bi bi-instagram"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <div id="quarto-announcement" data-announcement-id="a099f15fa5df9b7c51d563318a7a5b0d" class="alert alert-info hidden"><i class="bi bi-info-circle quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>A new version of the program is available <a href="https://www.cere2025.com/program/">here</a> (July 4th)</p>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Poster Session 2</h1>
</div>



<div class="quarto-title-meta column-page">

    
  
    
  </div>
  


</header>


<p>Abstract available when rows are expended:</p>
<div class="cell">
<div class="cell-output-display">
<div class="reactable html-widget html-fill-item" id="htmlwidget-1b1b8600f16efacf3636" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-1b1b8600f16efacf3636">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"Nb":["611123","611547","611837","617304","619030","620958","616639","617322","607844","611011","611486","615576","608001","619650","619086","619881","618508","608852","614218","614678","610945","618816","618906","614532","618540","618540#1","618540#2","618540#3","618540#4"],"Title":["Exploring Emotion Regulation through the Integration of ER Flexibility and ER Skills Models: A Network perspective","Emotion Regulation of Envy: The Role of Suppression and Cognitive Reappraisal","Is it easier to reduce your sadness or disgust? On the effectiveness of emotion regulation as an effect of strategy used, emotion and HRV","Bridging Cognitive Control and Emotion Regulation: New Findings from Meta-Analyses","FEEL the Difference: Concurrent and Prospective Validity of Emotion-Specific Regulation Strategies","Decoding Emotions Beyond Facial Expressions: Behavioral and Neuroelectrophysiological Evidence of Contextual Influence","I React to Bodies but not Faces, Replication and Extension of Aviezer et al., 2012","Emotion recognition in Mild Cognitive Impairment (MCI): The role of face processing and emotional intelligence.","Emerging Trends in Anxiety Sensitive Artificial Intelligence","Too Real to Feel? Examining Avatar Realism in Digital Emotion Regulation Training","A Gamepad-based Interface for Continuous Real-Time Emotion Tracing","Transformative Learning and Artificial Intelligence: Emotions as Catalysts for Learning Processes","Comparing Theoretical Models of Co-Occurring Emotions Using Multi-Modal Time Series Data","CAMPEONES: Continuous Annotation and Multimodal Processing of EmOtions in Naturalistic EnvironmentS – Pilot Data and Preliminary Analysis","The Role of Awareness in Unconscious Emotional Processing: Evidence from CFS and SCR Responses","Can Optical Heart Rate Measurement Track Emotional Processes in Children? Evaluating the Link Between Photoplethysmography and Emotional Processes in Preschool Children","The Human Affectome","Mood modulations of affective word processing: a predictive perspective of encephalographic data","Disentangling the influence of emotional and semantic values on inattentional blindness: theoretical and applied perspectives","The Role of Emotion in Updating Expectations for the Distant Future","Perceived Threat as a Driver of Hate: Lessons from the 2024 U.S. Election in a Global Context","The Hidden Cost of Psychological Threat: How Economic Stress Fuels Emotional Suppression and Undermines Well-being","Climate change and hope ratings modulate valence and arousal ratings of emotional images","Cognitive Reappraisal in Climate Communication: Transforming Ideological Legacies for Pro-Environmental Action","In sync or not: What are the correlates of physiological synchronicity?","To synchronise or not to synchronise? Investigating physiological synchrony in emotional performances","Task switching during nonverbal interactions promotes cardiac synchrony, while social anxiety reduces it. Considering the role of reciprocal attention in physiological synchrony","Partner stress decreases cardiac synchronization in romantic couples","Harmful to Relationships, Helpful in Adversity: The Nuanced Role of Psychopathic Traits in Partner Support, Stress and Physiological Synchronisation"],"Authors":["Rolland-Carlichi Emma, Baeyens Céline, Bortolon Catherine","Prikhidko Alena, Kushnerenko Dmitry, Qiu Yuxi","Kobylińska Dorota, Mituniewicz Julian","Schulze Katrin, Mueller Ilka, Holt Daniel V., Putz Sam, Barnow Sven, Pruessner Luise","Van Bockstaele Bram, Soenens Bart, Prinzie Peter","Toro Monica, Pizarro Claudia, Cortés Cristian, Ceric Fracisco","Pillaud Nicolas, Chassaing-Monjou Clément, Cottin Adèle","Mahadevan Rachana, Giesers Naomi, Liman Thomas, Witt Karsten, Hildebrandt Andrea, Roheger Mandy","Vanhée Loïs","Naumann Eva","Pathak Divya, Srinivasan Narayanan","Heidelmann Marc-André","Küppers Sebastian, Lange Jens","D'amelio Tomás, Rodriguez Cuello Jerónimo, Aboitiz Julieta, Bruno Nicolás Marcelo, Cavanna Federico, De La Fuente Laura Alethia, Müller Stephanie Andrea, Pallavicini Carla, Engemann Denis-Alexander, Vidaurre Diego, Tagliazucchi Enzo","Gonul Turkmen Selen, Booth Robert","Lorusso Sonja, Nischak Pablo, Diebold Tatiana, Burkhardt Bossi Carine, Harel Ori, Pruessner Jens, Perren Sonja","Yu Alessandra N. C.","Kopaeva Ekaterina, Blomberg Johan, Roll Mikael","Pavic Katarina, Izaute Marie, Ferrand Ludovic, Silvert Laetitia","Orphal Lara, Pinquart Martin","Aumer Katherine","Valor Segura Inmaculada, Alonso Ferres María, Guzmán María Teresa","Plonski Paul, Durgin Frank","Mahmoodi Kahriz Bahram",null,"Roydon Goldsack, Nicola Hyland & Hedwig Eisenbarth","Sarah Boukarras, Valerio Placidi, Federico Rossano, Vanessa Era, Salvatore Maria Aglioti & Matteo Candidi","Bernadette F. Denk, Maria Meier, Sebastian Ocklenburg, Julian Packheiser, Stella Wienhold, Nina Volkmer, Raphaela J. Gaertner, Elea S.C. Klink, Stephanie J. Dimitroff, Annika B.E. Benz & Jens C. Pruessner","Aaron Hissey, Matt Hammond & Hedwig Eisenbarth"],"Abstract":["Nardelli et al. (2023) proposed a theoretical model of emotion regulation (ER) in which specific ER skills, based on the Berking & Whitley's ACE Model (2014) support different stages of the ER flexibility model (Bonanno & Burton, 2013). However, this remains untested empirically. Thus, for this study, we aim to apply network analysis to identify which ER skills are most strongly associated with and central within the dimensions of ER flexibility (Borsboom, 2017; Fried et al., 2017). Our first objective is to use network analyses to test specific model-based hypotheses. We hypothesize positive associations between context sensitivity and feedback components with the skills of awareness, clarity, and understanding, and between the repertoire component and the skills of modification, acceptance, self-support, and confrontation. We also hypothesize that the feedback dimension will correlate with the modification skill. We also use network analyses to additional, unanticipated findings. Participants recruitment and data collection are in progress. We will conducted Gaussian Graphical Model (GGM; Epskamp et al., 2018) network analyses in R (version 4.4.2) and results will be presented.This approach highlights the importance of integrating ER flexibility and ER skills to deepen our understanding of emotion regulation flexibility and guiding future research and therapeutic interventions combining both ER flexibility and ER skills.","Envy creates a confusing mixture of feelings toward people one sees as doing better in life in a way resembling internal conflict, which might lead to stress because envious people often do not realize that they experience envy. Some may suppress their emotions and show up in active or passive aggression toward the object of envy. Currently, there is scarce research on the emotion regulation of envy. Meanwhile, studies show that this emotion is tied to anxiety, resentment, depression, and anger. We surveyed 723 college students from an Urban, predominately Hispanic institution using Depression Anxiety and Stress Scales (DASS 42; Lovibond & Lovibond, 1995), The Benign and Malicious Envy Scale (BEMAS; Lange & Crusius, 2015), and Emotion Regulation Questionnaire (Gross & John, 2003) and found that cognitive reappraisal is negatively correlated to malicious envy. However, when people see displays of wealth and use cognitive reappraisal to change their thoughts, they become inspired rather than stressed. Stress, depression, and anxiety correlate with suppression of emotions, and suppression has a high correlation with malicious envy. The moderation effect of suppression on the relationship between malicious envy and depression differs between individuals with a religion and those without. Specifically, on average, the impact of suppression on the relationship between malicious envy and depression is more substantial for religious groups. Additionally, among people with the same level of suppression, those who have higher scores on benign envy tend to score less on stress and depression. Further studies are needed to understand the effect of various emotion regulation strategies on the relationship between envy and stress, anxiety, and depression.","We investigated how emotion regulation (ER) effectiveness - operationalized via self-report subjective evaluation and electrodermal activity (EDA) - is influenced by the kind of emotion induced (sadness vs. disgust), emotion regulation strategy used (reappraisal vs. distraction vs. acceptance vs. no regulation control condition) and individual dispositions (resting state heart rate variability). In the laboratory experiment, after a training phase, 100 participants were instructed to regulate their emotions before watching negative NAPS photographs. Four blocks of sad photos and four blocks of disgusting photos were chosen on the basis of former studies. Before each block, the instruction to implement one of the ER strategies was exposed. EDA and HRV were measured. Participants also filled in several questionnaires for assessing their ER abilities, ER flexibility and positive and negative mental health. The results partially confirmed our predictions giving support to a novel ER flexibility framework. Effectiveness of ER differed based on strategy used, regulated emotion and baseline HRV. Sad photographs elicited lower negative emotions than disgusting photographs. The effects of ER strategy used were stronger for regulating disgust. Distraction and reappraisal were more effective than acceptance and no strategy for regulating both sadness and disgust.","Emotion regulation is a fundamental aspect of human adaptive functioning, and its connection to cognitive processes has long been of interest. However, the precise nature of the relationship between emotion regulation and cognitive control remains elusive, with a scarcity of systematic reviews and meta-analyses addressing this link. This study fills this research gap by conducting meta-analyses to systematically examine the relationship between individual differences in cognitive control – including the components of inhibition, memory updating, and set-shifting – and four emotion regulation strategies. Data were analysed from 52 studies on reappraisal, 63 on rumination, 30 on suppression, and 21 on worry. Preliminary results revealed a small positive association between reappraisal and cognitive control (r = 0.13, 95% CI [0.09, 0.18]) and a small negative correlation between rumination and cognitive control (r = −0.11, 95% CI [−0.15, −0.06]). No significant associations were found for suppression (r = 0.02, 95% CI [−0.05, 0.08]) or worry (r = −0.07, 95% CI [−0.15, 0.01]). Detailed results for specific cognitive control components will be presented. The small observed effects linking cognitive control with reappraisal and rumination suggest a modest relationship. In contrast, the lack of associations with suppression and worry challenges not only the notion of a strong but also a universal connection between emotion regulation and cognitive control—particularly when assessed using abstract tasks measuring inhibition, working memory, and shifting. Our meta-analytic findings offer new insights into the cognitive underpinnings of emotion regulation, highlighting the complexity of this relationship. Future research should investigate the flexibility of emotion regulation across contexts and how cognitive control influences this adaptability.","Emotion regulation plays a crucial role in psychological well-being. The FEEL-E questionnaire differentiates between putatively adaptive and maladaptive emotion regulation strategies across three negative emotions: Anger, fear, and sadness. However, little is known about whether and how these emotion regulation strategies for each emotion differentially predict psychological problems such as aggression, anxiety, and depression. Our study examines the psychometric properties of the FEEL-E, aiming to (1) determine whether individuals use different emotion regulation strategies depending on the emotion being regulated, and (2) investigate how these strategies uniquely and differentially predict psychological problems. We analysed the correlations between emotion regulation strategies and psychological problems, the factor structure of the FEEL-E, and how factor scores predict concurrent and prospective relationships between emotion regulation strategies and psychological problems. Participants completed the FEEL-E and the Adult Self Report (assessing aggression, anxiety, and depression) in two waves of the Flemish Study on Parenting, Personality, and Development. In wave 1 (N = 350), we found strong positive correlations between emotion regulation strategies for the three emotions, indicating that people do not differentiate between emotions when regulating them. Adaptive strategies were negatively related to all psychological problems, while maladaptive strategies were positively related to all psychological problems. However, emotion-specific regulation strategies were not differentially correlated with aggression, anxiety, or depression. Our analysis of the factor structure and longitudinal data collection (wave 2, current N = 304) is ongoing and will provide further insights into prospective relationships between emotion regulation strategies and psychological problems. While our initial results suggest that maladaptive strategies are broadly associated with increased psychopathology and adaptive strategies with decreased psychopathology, regardless of the emotion being regulated, further analyses will clarify whether emotion-specific strategies offer additional concurrent and prospective value for the prediction of psychological problems.","Are facial expressions enough to recognize emotions? This study challenges the widely accepted assumption of facial expression universality in emotional recognition by investigating how contextual cues from visual and auditory sources modulate emotional perception in a Chilean population. We conducted three distinct experiments—unimodal visual, unimodal auditory, and bimodal visual-auditory—on 117 participants (50% women), employing the largest EEG sample in Latin America for this type of research. The goal was to explore the influence of context on emotional recognition beyond facial expressions alone. Our findings show that facial expressions, while important, do not fully determine the recognition of emotions. The congruence between facial expressions and surrounding visual or auditory contexts significantly affects both behavioral responses (reaction times and accuracy) and neural processing. EEG analyses revealed that the N170, P300, and N400 components responded to contextual information at both early and late stages of processing, with increased cognitive effort in conditions where there was incongruence between the facial expression and the contextual cues. Specifically, when the visual or auditory context was inconsistent with the facial expression, participants exhibited slower reaction times and lower accuracy, indicating higher cognitive load and deeper processing. In the bimodal experiment, both visual and auditory cues worked synergistically, enhancing the accuracy of emotional recognition. These results suggest that emotions are not solely processed through facial expressions; rather, they are shaped by a broader range of contextual information, which includes both auditory and visual elements. This study contributes to ongoing debates in the field of emotional perception, providing robust behavioral and neuroelectrophysiological evidence that challenges traditional models of facial expression universality. Our findings highlight the need for a more culturally inclusive approach to studying emotions and suggest that context plays a critical role in the accurate interpretation of emotional expressions, expanding the scope of affective neuroscience research.","How do we truly assess the emotions of others? While numerous theories have highlighted the central role of facial expressions in evaluating emotions, some studies have challenged the ability to gauge others' feelings based solely on their faces (Aviezer et al., 2012). These studies suggest that we preferentially use bodies rather than faces to assess others' affective states. The aim of the present work is to replicate and extend these findings. A first preregistered experiment replicated the results obtained by Aviezer et al. (2012, Exp. 1). That is, the results (NExp1 = 194 - https://osf.io/h9pkn/?view_only=3716295e91614fbbb4d5706b3668923a) show that participants identified the expressed emotion only when bodies are presented on the picture. We conduct four other experiments to extend these results to other tasks (i.e., affective priming, affective misattribution procedure, feeling, and action tendencies). The results of the four preregistered experiments (NExp2 = 134 - https://osf.io/k6w2r/?view_only=5038a177e3944a53ad550ee1e8ae7965, NExp3 = 209 - https://osf.io/q4sut/?view_only=56fd0d79eb8e448a80539dbd3a0dedb3, NExp4 = 304 - https://osf.io/6zhdx/?view_only=3f33925fa59640afb68aec4b89b9eaed, NExp5 = 194 - https://osf.io/3n8m7/?view_only=505d186662614112a6b0813a2ea5cc41) show that stimuli presenting only bodies, rather than faces, consistently produce these classic effects found in the literature. Overall, these findings highlight that faces do not seem to be discriminative in detecting emotions, nor do they elicit affective reactions when affective stimuli are extreme. These results thus support the idea that context is predominant in the detection of emotions.","Abstract:  Introduction: Emotion recognition ability is essential for social cognition, enabling humans to interpret and respond to emotion-related cues effectively. However, so far it is not known how underlying cognitive deficits, including face processing, affect emotion recognition, particularly in patients with Mild Cognitive Impairment (MCI). Methods:  Sixty participants (patients with MCI = 30, healthy controls (HC) = 30), aged 50-86 years (M= 66.8, SD= 8.66) completed the emotion composite task (ECT), facial composite task (FCT), and emotion stroop task to measure emotion recognition (ER), face processing, and emotional arousal, respectively. Additional cognitive tests and an emotional intelligence (EI) questionnaire were included. Results:  Overall, patients with MCI performed about half of a standard deviation worse on ECT as compared with HC (β=-0.47), however, this effect was not significant. Emotion-specific analysis showed that anger recognition of the patients with MCI was particularly impaired (β=-0.86***). FCT showed a small positive effect on anger recognition (β=0.28*), indicating that participants with better facial processing skills recognized anger better. Self-control (β= 0.63), emotionality (β=0.71), and sociability (β=0.46) predicted ECT, indicating that participants with higher EI performed better in the ER task. Both FCT (β=0.17) and EI (β =0.98) contributed to the ER performance similarly in HC and MCI. Discussion:  While our results did not show significant overall ER performance deficits in patients with MCI, they showed specific impairments in anger recognition. Face processing ability contributed to anger recognition, suggesting that interventions, for example using ambulatory assessment, could train patients with MCI to maintain their face processing skills, especially for emotions that require more detailed processing, such as anger. Furthermore, emotion regulation training would help patients with MCI focus on real-world emotional cues, thereby improving their emotion recognition abilities. ","Anxiety, defined as the primary emotional response to uncertainty, is fascinating in its ambivalence, being both a catalyst and an inhibitor of intellectual faculties towards addressing potential, imagined threats. Widely recognized as a significant source of individual suffering --especially in the context of mental well-being issues like depression and self-harm; anxiety also imposes substantial societal costs. These costs, which include ill health and lost productivity, scale to trillions of euros annually. Furthermore, anxiety is deeply political, being both a side effect and an enabler of power imbalances, disproportionately affecting already disadvantaged groups. Despite anxiety's pervasive influence on individual decision-making and its profound societal impact, research on systematically accounting for anxiety in operational contexts (e.g., within workplace settings) remains limited. Similarly, there is little focus on explicitly organizing efforts to address anxiety, such as sensing, anticipating, avoiding, mitigating, or responding to its triggers. This contribution explores how computational methods can address these gaps and expand the research landscape on anxiety. Specifically, we examine emerging trends in Anxiety-Sensitive Artificial Intelligence (AnxSAI), which focuses on AI systems equipped with models of anxiety. AnxSAI systems may be human-centric, adapting to anxiety-related factors (e.g., identifying anxiety-inducing elements in an environment, predicting how a system's actions might affect the anxiety levels of individuals), or simulating human-like deliberative processes and behaviors influenced by anxiety (e.g., artificial companions, agents in social simulations). Key findings on practical development and interdisciplinary relevance of AnxSAI will be introduced, such autonomous agents, active inference models, and large language models (LLMs) for research on human empathy, futures studies, and digital humanities.","Background:\n Digital mental health interventions increasingly incorporate embodied conversational agents, such as avatars, to enhance user engagement and support emotion regulation—a key transdiagnostic factor in psychiatric disorders. However, the effects of avatar realism on intervention efficacy remain insufficiently explored, particularly in the context of digital emotion regulation training. This study examines the impact of avatar realism on training outcomes, user perception, and self-disclosure. Methods:\n A total of 203 participants completed a 30-minute digital emotion regulation training session facilitated by a conversational avatar. Participants were randomly assigned to one of four conditions: (1) ultra-realistic human avatar, (2) abstract toon-style human avatar, (3) robot avatar, or (4) control (audio waveform animation). Training effectiveness, user perception of the avatar, and self-disclosure were assessed using self-report measures, including the Client Satisfaction Questionnaire (CSQ), emotion ratings, and items from the Unified Theory of Acceptance and Use of Technology (UTAUT). Results:\n ANOVA analyses revealed a significant main effect of condition on training satisfaction, with the ultra-realistic human avatar receiving lower ratings than all other conditions. Furthermore, interactions with the ultra-realistic avatar were rated as significantly more anxiety-inducing and less pleasant than those with other avatars. Positive emotions increased across all conditions except in the ultra-realistic avatar group during a gratitude exercise. Additionally, participants in the ultra-realistic avatar condition reported significantly lower levels of self-disclosure compared to all other conditions. Conclusion:\n The findings suggest that ultra-realistic human avatars may induce discomfort, thereby reducing engagement and intervention effectiveness, aligning with the uncanny valley hypothesis. These results have important implications for optimizing avatar design in digital mental health applications to maximize user acceptance and therapeutic efficacy.","Emotional states fluctuate dynamically in response to stimuli, requiring precise real-time measurement. Existing methods, such as slider-based and joystick-based systems, often lack intuitive responsiveness and introduce delays. We designed an interface that offers enhanced response ergonomics, allowing real-time visual feedback by continuously mapping emotional states (valence and arousal). Our gamepad-based interface overlays directly on stimuli and enables two-dimensional (x-axis: valence; y-axis-arousal) tracking of emotional states in real time. Participants get visual feedback through a red dot in the two-dimensional space as they continuously map their emotional state, concluding with a final arousal and valence response via the trigger button.We implemented a staircase training protocol to mitigate response biases arising from device unfamiliarity while systematically acclimating participants to the interface. The protocol begins with basic motor skill training involving gamepad handling and control, followed by iterative practice using a perceptual random dot motion task. Performance metrics are assessed at each stage to ensure proficiency before advancing to the main task. Experiment1 validated the interface against traditional slider methods using 61 images from the NAPS database in a two-block (order counterbalanced) design. In Block1, participants rated the images using traditional slider responses. Block2 used our overlay interface. The ratings from both methods showed high consistency for valence (r = 0.721) and arousal (r = 0.77).Additionally, Bland-Altman analysis revealed minimal systematic bias, confirming measurement equivalence between our novel protocol and established slider-based rating methods. Experiment2 extends this validation to dynamic video stimuli to track fluctuations in valence and arousal values with participant-specific calibrations, minimizing center-drift biases inherent in gamepad-based responses. We applied a low-pass filter to reduce high-frequency noise in motor movement data, preserving critical signal features.This interface advances emotion dynamics research by providing a robust and precise tool for continuous emotion annotation and has application in fields requiring real-time high temporal resolution data.","Transformative learning, as described by Koller (2012), is not the mere accumulation of knowledge but a deep process of changing interpretative patterns. Learners face situations that challenge their previous perspectives, requiring them to develop new ways of understanding (Kokemohr 2007). Emotions are central to this process, acting as catalysts for change by triggering cognitive dissonance and prompting reflection. For transformative learning to occur, the unknown must be perceived as incomprehensible (Waldenfels 1997). The emotional response to unfamiliarity—such as irritation, uncertainty, or discomfort—often initiates transformation. When an experience cannot be integrated into one's existing worldview and self-concept, emotional pressure emerges, compelling individuals to question established patterns of interpretation (Marotzki 1999). This emotional tension fuels reflection and the development of new perspectives, making education an emotionally shaped encounter with the unknown (Koller 2012). As Artificial Intelligence (AI) becomes increasingly integrated into education, a key question arises: how does it impact emotional learning experiences (Wunder 2021)? AI systems can support transformative learning by adapting to learners' emotions through personalized feedback, emotion-recognition algorithms, and adaptive learning techniques. For instance, intelligent tutoring systems can create cognitive conflicts by exposing learners to unfamiliar perspectives (Zawacki-Richter et al. 2020). AI-enhanced learning environments can also regulate emotions by mitigating uncertainty or fostering motivation (Kasneci et al. 2023). However, to what extent can AI truly understand and respond to emotional reactions? How do algorithmic decisions influence emotional engagement in learning? This poster presentation examines the intersection of transformative learning, emotions, and AI from an interdisciplinary perspective. It highlights AI's potential to foster emotional learning while critically evaluating its impact on transformative education and the ethical implications of digitalization.","Many situations evoke multiple emotions at the same time. Lange and Zickfeld's (2023) work showed that from four parsimonious, formal emotion theories, the network theory of emotions explains these co-occurrences best. According to this theory, emotions co-occur because their respective networks of interacting emotion components overlap. Of note, Lange and Zickfeld's research is preliminary as participants provided only self-ratings of their emotional experiences (i.e., feelings, cognitions, motivations, physiological changes, expressions) once after watching arousing videos, neglecting the dynamic and person-specific nature of emotions. We aimed to replicate and extend their findings by (1) incorporating multi-modal emotion measures, (2) testing implications of a multidimensional approach to co-occurring emotions, and (3) comparing emotion theories separately for each participant. Participants watched four videos eliciting awe and fear simultaneously. We continuously assessed appraisals, heart rate, respiration rate, skin conductance level, facial expressions, and piloerection, complementing the single-timepoint self-ratings that were already part of Lange and Zickfeld's study. We expect to finish data collection early in February. Ultimately, this study contributes to developing a formal theory of co-occurring emotions.","The integration of continuous self-reports of subjective experience with physiological data is essential for advancing both cognitive and affective science. Here, we present CAMPEONES, a novel public database designed to capture the temporal evolution of emotional experiences in immersive virtual reality (VR) environments.\nIn this study, participants engaged in controlled VR tasks specifically designed to elicit a range of emotional responses. Emotional states were continuously recorded using a joystick that tracked dynamic rating trajectories, while peripheral physiological signals were simultaneously measured. Synchronization protocols ensured high-quality, multimodal data collection, providing a robust framework for subsequent predictive modeling.\nPreliminary analyses reveal associations between continuous emotional annotations and their corresponding physiological markers. The VR paradigm successfully elicited realistic emotional responses that correlated with the temporal dynamics of the continuous annotations.\nCAMPEONES makes a significant contribution to affective science by integrating subjective emotional experience with objective physiological correlates. This framework not only deepens our understanding of emotional dynamics in naturalistic settings, but also lays the foundation for AI-driven models capable of predicting the continuous experience of affective states.","Research suggests that unconscious emotional stimuli can elicit physiological and evaluative responses, yet the role of awareness in moderating these effects remains unclear. This study examined how emotions rendered unconscious through continuous flash suppression (CFS) influence skin conductance responses (SCR) and evaluations of novel faces. Forty-two undergraduate students (M = 21.98, SD = 4.21) participated in the study, and a two-alternative forced choice (2AFC) task was used to assess CFS efficacy, categorizing participants into aware (performers >50%) and unaware (guessers ≤50%) groups. Participants were exposed to disgust, fear, anger, and neutral expressions, while their SCR and post-trial face ratings were recorded. A 4 (emotion: disgust, fear, anger, neutral) × 2 (awareness: aware, unaware) mixed factorial ANOVA revealed that while emotion and awareness did not independently affect SCR, their interaction approached significance (p = .057, η² = .098), suggesting that emotional expressions may elicit stronger physiological responses in unaware participants. Descriptive statistics suggested that unaware participants showed numerically longer latencies across emotional conditions, with the largest difference occurring for neutral expressions, but this effect did not reach significance. In contrast, novel face ratings did not differ significantly across emotions or awareness levels (all p > .3). The overall mean face rating was 4.60 (SD = 0.96), with unaware participants ratings slightly higher (M = 4.90, SD = 1.19) than aware participants (M = 4.50, SD = 0.87), though this difference was not significant. These findings contribute to ongoing discussions on the dissociation between physiological responses and conscious affective evaluations, suggesting that while awareness may play a role in autonomic reactivity, its influence was not robustly significant. The results indicate that unconscious emotional processing may elicit physiological changes in some cases, but this does not necessarily translate into explicit affective judgments. ","Preschool age is a crucial period for developing emotional competence, with deficits linked to long-term negative outcomes. However, studying emotions in young children is challenging, as their emerging regulation skills make emotions less observable, and their limited awareness and vocabulary hinder self-reports. Heart rate is a common physiological marker of emotional intensity and regulation, traditionally measured using electrocardiography (ECG) with chest electrodes. In contrast, wrist-worn sports watches offer a less invasive, more familiar alternative, increasing acceptance by children. These devices rely on photoplethysmography (PPG), which measures pulse rate by detecting blood volume changes in tissue via light sensors. While heart rate is well established in emotion research, the benefit of PPG-derived pulse rate as an indicator of emotion-related arousal remains unclear. To investigate this, 94 children from 16 German-speaking Swiss playgroups (Mage = 3.75 years, 58.62% female) participated in three standardized emotion-eliciting tasks designed to induce frustration, anticipation, and dynamic emotional shifts and one tablet-based emotion knowledge test serving as a physiological baseline. Each session was video-recorded, with children wearing Polar Vantage V2 watches for continuous physiological monitoring. Trained raters assessed emotional expression based on the recordings using the Emotion Regulation Scoring System. Linear mixed models will examine (1) whether pulse rate is associated with observed emotional expression, and (2) whether pulse rate differs between the emotion-eliciting tasks. If pulse rate reliably reflects emotion-related arousal, we expect higher pulse rates to correspond with more intense emotional expression during the emotion-inducing tasks. Additionally, we expect pulse rates to be highest during the frustration task, lower during anticipation, even lower during dynamic emotional shifts, and lowest in the baseline condition. If we can demonstrate that pulse rates reliably capture emotional processes in children, they could enhance field research and expand studies on institutional factors, such as peer influence and group dynamics. Keywords: Photoplethysmography (PPG), preschool children, emotional arousal, emotion expression  ","Theoretical perspectives in the interdisciplinary field of the affective sciences have proliferated rather than converged due to differing assumptions about what human affective phenomena are and how they work. These metaphysical and mechanistic assumptions—shaped by academic context and values—have dictated the field's affective constructs and operationalizations. However, a foundational premise concerning the purpose of affective phenomena can guide us to a common set of metaphysical and mechanistic assumptions. In the capstone paper for the special issue “Towards an Integrated Understanding of the Human Affectome”, a collaboration among 173 affective researchers from 23 countries, we converge on a nested teleological principle for human affective phenomena: from the broadest purpose of an organism (to ensure viability), to complex organisms (to execute operations), then mechanisms of meaning (to enact relevance), and finally their human-specific projectivity (to entertain abstraction). Based on this principle, human affective phenomena can collectively be considered as algorithms that either adjust based on the comfort zone (affective concerns) or monitor those adaptive processes (affective features). Those for affective concerns indicate the adaptive relevance of the environment. These can be organized hierarchically according to distance from metabolic impact (immediate to distal), including physiological and operational concerns, and can also act as global summaries of concerns across time, such as trajectory and optimization. Those for affective features monitor how the adaptive process is going on a momentary basis, include valence (how well or not) and arousal (the extent to which various systems are mobilized), and can inform global concerns. This teleologically-grounded framework offers a principled agenda for organizing existing perspectives as well as generating new ones. Ultimately, we hope the Human Affectome brings us a step closer to not only an integrated understanding of human affective phenomena—but an integrated field for affective research through a forum for discussion.","An individual's emotional state, or mood, has been shown to influence perception, attention, decision-making and other cognitive processes. Its effects extend to language processing, where it is seen as part of the pragmatic context. If a linguistic expression is non-neutral in itself, mood might augment or attenuate its perceived valence. Motivated by a lack of clarity regarding the nature and temporal dynamics of mood-valence interaction, we conducted an exploratory EEG study to find whether an individual's mood might change the temporal profile of emotional word processing. We looked at the interaction of mood and valence in a control and two mood-induced conditions over three consecutive time windows in a semantic categorisation task focusing on early processing, where data is inconsistent. In the three mood conditions, twenty-two healthy participants performed valence ratings of neutral, positive and negative words. Non-parametric cluster-based permutation tests were performed for the selected time windows and components to determine an unbiased scalp distribution. Results revealed an interaction in a happy but not sad mood. High valence words elicited greater N1 amplitudes (130-190 ms) in the control condition, but none in happy. In the subsequent time window (200-300 ms), congruence effects persisted: low valence words were attended to in a happy mood, as seen in increased P2 amplitudes, and high valence words were facilitated, as less negative EPN slopes show. In predictive-coding frameworks, mood is seen as a hyperprior that affects both the model and incoming signal. Happy moods make the model more precise and the input controllable. In this view, the results are interpreted as indicators of prediction error marked by the N1 and subsequent model update in the P2 time-window, with reduced amplitudes signalling a better-fitted model. A lack of a reverse pattern in a sad mood speaks in favour of asymmetrical mood effects on cognition.","Inattentional blindness refers to the failure to consciously perceive clearly visible information that unexpectedly appears while performing a task. Numerous studies have shown that inattentional blindness decreases (i.e., attentional capture increases) when unexpected stimuli have high emotional value, such as smiling faces or images of threatening objects or animals. However, emotional value often overlaps with the semantic value of the stimulus, which is also known to reduce inattentional blindness. To address this confound, three studies were conducted to 1) disentangle the distinct effects of emotional and semantic value on inattentional blindness, and 2) identify the conditions that optimize the conscious perception of unexpected stimuli. In all three studies, participants performed a line-length judgment task while being exposed to the same unexpected stimuli. The emotional and semantic values of these stimuli were systematically manipulated across the experiments. Additionally, two of the studies aimed to determine whether attention set theory or cognitive load theory better explains inattentional blindness. To this end, the task relevance of the stimuli and cognitive load of the task were manipulated. Task relevance was manipulated by embedding the line judgment in a driving context, using a narrative emphasizing the semantic or emotional significance of the task in a road scenario. Cognitive load was manipulated by asking participants to perform a digit span task at the beginning of each trial (retaining either one or six digits throughout the trial). Results will be discussed from a theoretical perspective, shedding light on the factors influencing attentional capture. Practical implications will also be addressed, offering recommendations for driving contexts to mitigate the potentially hazardous effects of inattentional blindness on the perception of warning signals.","People update their expectations when presented with new information, but emotions may systematically influence how much they revise their beliefs. Positive emotions have been linked to greater openness to new information, while negative emotions have been associated with skepticism. However, it remains unclear whether such effects extend to expectations about an uncertain future. This study investigates whether emotions (positive, negative, neutral) influence the degree to which people update their expectations about future world events after receiving probabilistic expert feedback. Participants are randomly assigned to one of three emotional conditions (positive, negative, neutral) and complete an emotion induction task, selecting which of two emotional images (from the OASIS database) better fits an emotional quote. They then estimate the probability (0-100%) that a given statement about the world in 50-100 years will come true (e.g., “As automation takes over most professions, many countries will introduce a universal basic income.”). Next, they receive expert expectations about the event's likelihood, described as 75% reliable, and subsequently update their probability estimates. This sequence—emotional induction, prior expectation, expert feedback, updated expectation—is repeated for 15 statements. Finally, participants complete a PANAS questionnaire and a cognitive conflict detection task. To ensure statements were neutral in valence and moderately realistic, a pretest (N = 47) assessed 120 statements on perceived likelihood and desirability. The pretest confirmed that desirability significantly predicted likelihood ratings, and the main study includes 15 statements rated as neither desirable nor undesirable, with average likelihood ratings. Expectation updating will be modeled using linear mixed-effects models, testing whether (1) emotional states influence the magnitude and direction of updating (toward or away from expert feedback), and (2) emotions lead to systematic deviations from Bayesian updating. Exploratory analyses will examine (3) whether cognitive conflict detection moderates expectation updating, (4) whether the magnitude of expectation violation (the absolute difference between prior beliefs and expert feedback) modulates the effect of emotion and (5) whether emotional states influence trust in expert feedback, measured by calculating the weight of the expert's feedback in the participant's update. This study integrates emotional states and Bayesian updating to examine how emotions shape expectation revision about uncertain, real-world questions. Data collection will begin in February 2025, and results will be available at the time of the conference.","Hate in social science is often linked to perceived threats to identity, values, or safety. Allport (1954) associated prejudice and dehumanization with group-based threats, while Sternberg's \"Duplex Theory of Hate\" (2003) emphasized fear and anger as amplifiers. The 2024 U.S. election served as a catalyst for hate, with political opponents framed as existential or moral threats. Research by Fischer et al. (2018) and Halperin (2011) suggests that moral violations and political contexts magnify threat perceptions, while Aumer and Bahn (2016) argue that hate functions as a self-protective response. This study tested whether hate correlates more strongly with perceived threat than with prejudice or dehumanization. A total of 645 participants were recruited via Amazon Turk, with a final sample of 499 after data cleaning. Participants were divided into four groups—Democrats Pre-Election, Democrats Post-Election, Republicans Pre-Election, and Republicans Post-Election. Of these, 301 completed the survey before the election, and 198 after. The sample leaned Democratic (n = 366) over Republican (n = 133). Participants rated political figures and parties on measures of hate, perceived threat, and dehumanization, with the latter assessed through beliefs about targets' “evolved” status. Across groups, hate correlated with perceived threat (r = .53 to .62) significantly more than with prejudice (r = .0 to .23) or dehumanization (r = -.2 to .0). Fisher's Z-tests confirmed these differences (p < .01). Findings underscore perceived threat as the primary driver of hate, aligning with theoretical models from Allport to contemporary research. Hate arises when individuals perceive existential or moral threats, reinforcing political hostility. Addressing threat-based narratives may be key to reducing polarization and fostering societal understanding.","Objectives. When individuals feel psychologically threatened—whether due to financial instability or health concerns—their well-being often suffers. However, the underlying mechanisms driving this relationship remain unclear. This study investigates emotional suppression as a key pathway through which psychological threats may erode well-being. We propose that suppressing emotions in response to economic or health-related stressors can be counterproductive, draining self-regulatory resources and impairing problem-solving and social support. Specifically, we examine whether emotional suppression mediates the link between psychological threat, and overall well-being and health. Methods. A nationally representative sample of Spanish adults (N = 969) participated in the study. The average participant was 52 years old (range: 18–89), with a gender distribution of 55% male and 45% female. Household income averaged €2,469 per month, and all participants were in a romantic relationship at the time of the study. Results. Our findings reveal a striking pattern: individuals facing greater economic (but not health-related) psychological threat were significantly more likely to engage in emotional suppression. In turn, this suppression was strongly associated with diminished life satisfaction, lower happiness and positive affect, poorer physical health, and heightened levels of depression and anxiety. Crucially, these effects persisted even after accounting for gender, age, and socio-economic status. Conclusions. These findings highlight the hidden emotional cost of financial stress and the pivotal role of emotion regulation in shaping mental and physical health outcomes. When individuals suppress their emotions in response to economic hardship, they may inadvertently amplify their distress rather than alleviate it. Interventions that encourage healthier emotion regulation strategies could offer a powerful buffer against the negative effects of economic insecurity, ultimately promoting resilience and well-being in the face of psychological threat.","Theories of emotion and emotion regulation posit temporally recursive cycles between components of emotional episodes, including appraisals and subjective feelings (McRae & Gross, 2020; Scherer, 2022). Changing appraisals can modulate emotion, such as thinking about a situation as less relevant to oneself (Opitz et al., 2015). Despite substantial research on appraisal, less is known about the effect of relevance contexts other than one's own goals and well-being on emotion processes. We hypothesized that rating how much an emotional stimulus represents climate change or hope would affect valence and arousal ratings. United States adults (N = 298) from Prolific viewed 90 images, equally split between negative images of climate change, positive images of nature, and neutral images. After four seconds, response scales appeared, sequentially, below the image. Participants randomly assigned to the control condition rated only valence and arousal. In two experimental conditions, participants rated how much the image represented either climate change or hope, then rated valence and arousal. We tested effects with two linear mixed-effects models with random intercepts for participant and image, and a random slope for image type by participant. Fixed effects were condition (treatment coded), image type (sum-to-zero coded), and the interactions. Rating climate change increased negativity and negative emotion, whereas rating hope increased negativity but upregulated positive arousal and downregulated negative arousal. Results suggest that thinking about relevance to contexts beyond the self can affect emotion. These evaluations may involve processes similar to affect labelling, which, like hope ratings, can downregulate negative (Lieberman et al., 2011) and upregulate positive emotion (Vlasenko et al., 2021). More research would be necessary to compare relevance contexts to appraisals of relevance to one's own goals (Lazarus, 1991; Moors, 2017; Scherer, 2009). Lazarus, R. S. (1991). Cognition and motivation in emotion. American Psychologist, 46(4), 352–367. http://dx.doi.org/10.1037/0003-066X.46.4.352 Lieberman, M. D., Inagaki, T. K., Tabibnia, G., & Crockett, M. J. (2011). Subjective responses to emotional stimuli during labeling, reappraisal, and distraction. Emotion, 11(3), 468–480. https://doi.org/10.1037/a0023503 McRae, K., & Gross, J. J. (2020). Emotion regulation. Emotion, 20(1), 1. https://doi.org/10.1037/emo0000703 Moors, A. (2017). Appraisal Theory of Emotion. In V. Zeigler-Hill & T. K. Shackelford (Eds.), Encyclopedia of Personality and Individual Differences (pp. 1–9). Springer International Publishing. https://doi.org/10.1007/978-3-319-28099-8_493-1 Opitz, P. C., Cavanagh, S. R., & Urry, H. L. (2015). Uninstructed emotion regulation choice in four studies of cognitive reappraisal,. Personality and Individual Differences, 86, 455–464. https://doi.org/10.1016/j.paid.2015.06.048 Scherer, K. R. (2009). The dynamic architecture of emotion: Evidence for the component process model. Cognition & Emotion, 23(7), 1307–1351. https://doi.org/10.1080/02699930902928969 Scherer, K. R. (2022). Theory convergence in emotion science is timely and realistic. Cognition and Emotion, 36(2), 154–170. https://doi.org/10.1080/02699931.2021.1973378 Vlasenko, V. V., Rogers, E. G., & Waugh, C. E. (2021). Affect labelling increases the intensity of positive emotions. Cognition and Emotion, 35(7), 1350–1364. https://doi.org/10.1080/02699931.2021.1959302","Political polarisation remains a major barrier to effective climate action, as fear-based messaging often reinforces ideological resistance rather than fostering engagement. This study explores cognitive reappraisal—a psychological strategy that reframes distressing narratives—as a potential tool for reducing defensiveness and inspiring pro-environmental behavior across ideological divides. Drawing on emotion regulation theory (Gross, 1998) and consumer culture perspectives, this research investigates whether reappraisal-based climate communication can increase hope, enhance self-efficacy, and promote constructive engagement. This study employs a two-phase experimental design. Phase 1 examines the emotional and cognitive impact of climate messaging across three conditions: (1) reappraisal-based (framing climate action as achievable and collaborative), (2) fear-based (highlighting catastrophic consequences of inaction), and (3) neutral (providing factual information). Participants (N = 400) are stratified by political ideology, and measures include emotional response (hope, fear), ideological defensiveness, and climate policy support. Phase 2 (N = 600) extends this analysis by examining behavioural intentions, including sustainable consumption and environmental actions. As an ongoing project, preliminary insights suggest that reappraisal messaging may foster more inclusive and action-oriented climate engagement by shifting focus from fear to empowerment and collective efficacy. This research contributes to consumer culture theory (CCT) by examining how psychological mechanisms shape climate discourse and legacy-building. Findings will offer practical guidance for marketing practitioners, policymakers, and NGOs in designing climate campaigns that resonate across ideological divides. By reimagining climate narratives through cognitive reappraisal, this study aims to transform socio-political legacies of climate discourse and promote a more constructive, inclusive, and action-driven approach to environmental communication. Keywords: Cognitive Reappraisal, Climate Communication, Emotion Regulation, Political Polarization, Consumer Culture","When we think of social interactions between humans, we might think of the way we talk with each other to express our intentions and emotions, or our how we use our facial expressions to communicate an emotional state. However, there is another level in social interactions, driven by physiological activity. Not only do we re-act to others' emotions with changes in physiological activity such as heart rate or electrodermal activity, but we also seem to inter-act on a physiological level. Physiological synchrony, the co-regulation of physiological activity in a physiological measure across time has been found to be related to some positive outcomes, like better treatment outcomes based on client-therapist interactions. However, variations in synchrony might depend on situational factors, including emotional states. This symposium will discuss both trait and situational correlates of being in-sync or not, across various contexts. Roydon Goldsack will present a study investigating how physiological synchrony varies across emotional states and intensity levels when actors perform guided by a dramaturg and its impact on perceived effectiveness of a performance. Another context which requires perspective taking and hence adaptation to situational changes is joint action. When switching between tasks requiring collaboration, we need to read the other person's state. Sarah Boukarras will discuss how physiological synchrony changes based on these demands, and also consider variations in social anxiety. Sharing a moment of moment of intense stress takes the situational adaptation into the opposite direction. The last two presentations will focus on the effects of physical stress through the cold pressor test on physiological synchrony in couples. Bernadette Denk will speak about how partner stress decreases cardiac synchronization in romantic couples, and Aaron Hissey will present a study that included variation in personality to investigate the role of physiological synchrony in partner support during such a stressful situation.\n\nTo synchronise or not to synchronise? Investigating physiological synchrony in emotional performances\nRoydon Goldsack1,2, Nicola Hyland3 & Hedwig Eisenbarth2\n1School of Engineering, Victoria University of Wellington, New Zealand\n2School of Psychology, Victoria University of Wellington, New Zealand\n3School of School of English, Film, Theatre, Media and Communication, and Art History, Victoria University of Wellington, New Zealand\n\nInterpersonal collaboration, such as between audience members and musical performers, benefit from increased co-regulation of physiological activity i.e. synchrony. Additionally, emotional responses of audience members and their synchrony vary across different types of performances, such as variation in emotional content. However, these effects have been scarcely investigated in the context of theatrical performance let alone in an actor-director dyadic interaction. This context varies from the strictly audience-performer relationship as there is direct collaboration and impact on the final performance. We therefore hypothesized that variation in physiological synchrony between actor and director is related to actor-perceived effectiveness of the performance. We sampled actor and director heart rate, chest expansion and body acceleration across ~30 hours of performance varying in emotion and intensity. Actors (n = 2) rated their emotional state and performance convincingness after each recorded performance. Physiological Synchrony for heart rate, chest expansion and body acceleration were calculated using Surrogate Synchrony. T-Tests of estimated surrogate synchrony effect sizes indicated significant synchrony for almost all measures of synchrony, except non-absolute heart rate synchrony. Results from Linear Mixed Models showed that Physiological Synchrony varied significantly by the emotion performed, the level of intensity performed, and the physiological measure used. However, physiological synchrony was only rarely significantly related to the self-reported emotional state of the Actor and not at all related to the effectiveness of the performance. These findings suggest that the impact of physiological synchrony for performance might depend on the content of the performance. \n\n\nTask switching during nonverbal interactions promotes cardiac synchrony, while social anxiety reduces it. Considering the role of reciprocal attention in physiological synchrony.\nSarah Boukarras1,2, Valerio Placidi1,3,4, Federico Rossano1,2,4, Vanessa Era1,2, Salvatore Maria Aglioti1,2,4 & Matteo Candidi1,2\n1 Department of Psychology, Sapienza University of Rome, Italy\n2 Santa Lucia Foundation (IRCCS), Rome, Italy\n3 School of Advanced Studies, Centre for Neuroscience, University of Camerino, Camerino, Italy\n4 Sapienza University of Rome and CLN2S@Sapienza, Italian Institute of Technology, Rome, Italy\n\nIn nonverbal joint action tasks, two or more individuals must coordinate their movements in space and time to achieve a shared goal. This ability relies on processes of reciprocal prediction and monitoring, perception-action integration, and perspective-taking, all occurring simultaneously within the dyad or group. Such coordination can lead to the emergence of autonomic synchrony, as demonstrated in previous studies. However, the extent to which contextual and individual factors influence or modulate this synchrony in joint actions remains underexplored. In this study, we investigated how cardiac synchrony in joint actions is shaped by contextual demands—specifically, leader-follower roles and task novelty—as well as by dyad-level differences in willingness and ability to interact, measured through Social Anxiety and Perspective Taking. Our primary finding was that physiological synchrony increased whenever the dyad switched to a slightly modified version of the task. This suggests that the need to adapt and learn something new together enhances the interpersonal synchronization of physiological states. Additionally, subclinical social anxiety—characterized by an excessive shift of attention toward the self—hindered the emergence of physiological synchrony and reduced participants' enjoyment of the interaction. These findings indicate that physiological alignment is not merely a byproduct of behavioural coordination or shared task demands. Instead, it may reflect fundamental processes of reciprocal attention and social monitoring that support successful joint action.\n\n\nPartner stress decreases cardiac synchronization in romantic couples\nBernadette F. Denk1,2, Maria Meier1, Sebastian Ocklenburg3, 4, 5, Julian Packheiser6, Stella Wienhold1,2, Nina Volkmer1, 2, Raphaela J. Gaertner1, Elea S.C. Klink1, Stephanie J. Dimitroff7, Annika B.E. Benz1 & Jens C. Pruessner1,2\n1University of Konstanz, Konstanz, Germany\n2Centre for the Advanced Study of Collective Behaviour, Konstanz, Germany\n3Department of Psychology, Medical School Hamburg, Hamburg, Germany\n4ICAN Institute for Cognitive and Affective Neuroscience, Medical School Hamburg, Hamburg, Germany\n5Institute for Cognitive Neuroscience, Biopsychology, Faculty of Psychology, Ruhr University Bochum, Bochum, Germany\n6Social Neuroscience Lab, Ruhr University Bochum, Bochum, Germany\n7University of Montana, Missoula, Montana, USA\n\nPhysiological synchrony (PS), i.e., the alignment of physiological changes across individuals, is an established phenomenon characterizing social interactions. The degree to which interaction partners synchronize may depend on various relationship- and situation-specific factors. Stress profoundly affects behavior and cognition, but its effect on PS is still unknown. In a preregistered study, we thus investigated the effect of stress on PS in N = 75 romantic couples (mean age = 22.66 ±2.99, 51% female). Partners were separated upon arrival in the laboratory. In n = 38 stress dyads, one partner underwent the Socially Evaluated Cold Pressor Task (SECPT) while the other partner completed a non-stressful control task; in control dyads, both partners underwent the non-stressful task. After completing the intervention separately, partners were reunited and participated in a non-verbal synchronization task, a walking task, and an unstructured interaction. PS was operationalized by calculating cross-wavelet power of partners' heart rate trajectories. We hypothesized that PS would be altered in couples with one stressed partner compared to the non-stressed control group. Across all interaction tasks, PS was lower in stress than in control dyads. Our findings indicate that stress disrupts PS. In the discussion, we present possible mechanisms for this effect. Our results highlight that stress is not only an intra- but also an interpersonal phenomenon affecting interpersonal physiological processes and social interactions beyond the acute stressor. \n\n\nHarmful to Relationships, Helpful in Adversity: The Nuanced Role of Psychopathic Traits in Partner Support, Stress and Physiological Synchronisation\nAaron Hissey, Matt Hammond & Hedwig Eisenbarth\nSchool of Psychology, Victoria University of Wellington, New Zealand\n\nPsychopathic traits are associated with poorer romantic relationship functioning, yet their role in shaping partner stress responses during times of adversity remains unclear. This study explores associations among psychopathic traits, partner support, and stress in 100 romantic couples (N = 200) during a stress-induction task. We also examine whether psychopathic traits are related to physiological synchronization between partners and whether synchronization mediates links between psychopathic traits and stress. To assess physiological stress and synchronization, we measured heart rate, respiration, and skin conductance. Results suggest that individuals with higher psychopathic traits provide less support during times of stress, engage in less supportive relationships overall, and report poorer relationship quality. However, higher psychopathic traits were correlated with lower subjective stress and skin conductance scores during the stress-induction task, as well as lower heart rate scores for partners. These findings suggest that psychopathic traits may serve as a protective factor for stress in individuals, with some evidence indicating minor protection for partners as well. Furthermore, psychopathic traits were generally negatively associated with physiological synchronization, although evidence that synchronization mediates links between psychopathic traits and stress is limited. Our findings indicate that psychopathic traits offer some resilience to stress, but also undermine relationship quality, highlighting the complex role of psychopathic traits in romantic relationships.",null,null,null,null]},"columns":[{"id":".details","name":"","type":null,"sortable":false,"resizable":false,"filterable":false,"searchable":false,"width":45,"align":"center","details":[{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Nardelli et al. (2023) proposed a theoretical model of emotion regulation (ER) in which specific ER skills, based on the Berking & Whitley's ACE Model (2014) support different stages of the ER flexibility model (Bonanno & Burton, 2013). However, this remains untested empirically. Thus, for this study, we aim to apply network analysis to identify which ER skills are most strongly associated with and central within the dimensions of ER flexibility (Borsboom, 2017; Fried et al., 2017). Our first objective is to use network analyses to test specific model-based hypotheses. We hypothesize positive associations between context sensitivity and feedback components with the skills of awareness, clarity, and understanding, and between the repertoire component and the skills of modification, acceptance, self-support, and confrontation. We also hypothesize that the feedback dimension will correlate with the modification skill. We also use network analyses to additional, unanticipated findings. Participants recruitment and data collection are in progress. We will conducted Gaussian Graphical Model (GGM; Epskamp et al., 2018) network analyses in R (version 4.4.2) and results will be presented.This approach highlights the importance of integrating ER flexibility and ER skills to deepen our understanding of emotion regulation flexibility and guiding future research and therapeutic interventions combining both ER flexibility and ER skills."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Envy creates a confusing mixture of feelings toward people one sees as doing better in life in a way resembling internal conflict, which might lead to stress because envious people often do not realize that they experience envy. Some may suppress their emotions and show up in active or passive aggression toward the object of envy. Currently, there is scarce research on the emotion regulation of envy. Meanwhile, studies show that this emotion is tied to anxiety, resentment, depression, and anger. We surveyed 723 college students from an Urban, predominately Hispanic institution using Depression Anxiety and Stress Scales (DASS 42; Lovibond & Lovibond, 1995), The Benign and Malicious Envy Scale (BEMAS; Lange & Crusius, 2015), and Emotion Regulation Questionnaire (Gross & John, 2003) and found that cognitive reappraisal is negatively correlated to malicious envy. However, when people see displays of wealth and use cognitive reappraisal to change their thoughts, they become inspired rather than stressed. Stress, depression, and anxiety correlate with suppression of emotions, and suppression has a high correlation with malicious envy. The moderation effect of suppression on the relationship between malicious envy and depression differs between individuals with a religion and those without. Specifically, on average, the impact of suppression on the relationship between malicious envy and depression is more substantial for religious groups. Additionally, among people with the same level of suppression, those who have higher scores on benign envy tend to score less on stress and depression. Further studies are needed to understand the effect of various emotion regulation strategies on the relationship between envy and stress, anxiety, and depression."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["We investigated how emotion regulation (ER) effectiveness - operationalized via self-report subjective evaluation and electrodermal activity (EDA) - is influenced by the kind of emotion induced (sadness vs. disgust), emotion regulation strategy used (reappraisal vs. distraction vs. acceptance vs. no regulation control condition) and individual dispositions (resting state heart rate variability). In the laboratory experiment, after a training phase, 100 participants were instructed to regulate their emotions before watching negative NAPS photographs. Four blocks of sad photos and four blocks of disgusting photos were chosen on the basis of former studies. Before each block, the instruction to implement one of the ER strategies was exposed. EDA and HRV were measured. Participants also filled in several questionnaires for assessing their ER abilities, ER flexibility and positive and negative mental health. The results partially confirmed our predictions giving support to a novel ER flexibility framework. Effectiveness of ER differed based on strategy used, regulated emotion and baseline HRV. Sad photographs elicited lower negative emotions than disgusting photographs. The effects of ER strategy used were stronger for regulating disgust. Distraction and reappraisal were more effective than acceptance and no strategy for regulating both sadness and disgust."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Emotion regulation is a fundamental aspect of human adaptive functioning, and its connection to cognitive processes has long been of interest. However, the precise nature of the relationship between emotion regulation and cognitive control remains elusive, with a scarcity of systematic reviews and meta-analyses addressing this link. This study fills this research gap by conducting meta-analyses to systematically examine the relationship between individual differences in cognitive control – including the components of inhibition, memory updating, and set-shifting – and four emotion regulation strategies. Data were analysed from 52 studies on reappraisal, 63 on rumination, 30 on suppression, and 21 on worry. Preliminary results revealed a small positive association between reappraisal and cognitive control (r = 0.13, 95% CI [0.09, 0.18]) and a small negative correlation between rumination and cognitive control (r = −0.11, 95% CI [−0.15, −0.06]). No significant associations were found for suppression (r = 0.02, 95% CI [−0.05, 0.08]) or worry (r = −0.07, 95% CI [−0.15, 0.01]). Detailed results for specific cognitive control components will be presented. The small observed effects linking cognitive control with reappraisal and rumination suggest a modest relationship. In contrast, the lack of associations with suppression and worry challenges not only the notion of a strong but also a universal connection between emotion regulation and cognitive control—particularly when assessed using abstract tasks measuring inhibition, working memory, and shifting. Our meta-analytic findings offer new insights into the cognitive underpinnings of emotion regulation, highlighting the complexity of this relationship. Future research should investigate the flexibility of emotion regulation across contexts and how cognitive control influences this adaptability."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Emotion regulation plays a crucial role in psychological well-being. The FEEL-E questionnaire differentiates between putatively adaptive and maladaptive emotion regulation strategies across three negative emotions: Anger, fear, and sadness. However, little is known about whether and how these emotion regulation strategies for each emotion differentially predict psychological problems such as aggression, anxiety, and depression. Our study examines the psychometric properties of the FEEL-E, aiming to (1) determine whether individuals use different emotion regulation strategies depending on the emotion being regulated, and (2) investigate how these strategies uniquely and differentially predict psychological problems. We analysed the correlations between emotion regulation strategies and psychological problems, the factor structure of the FEEL-E, and how factor scores predict concurrent and prospective relationships between emotion regulation strategies and psychological problems. Participants completed the FEEL-E and the Adult Self Report (assessing aggression, anxiety, and depression) in two waves of the Flemish Study on Parenting, Personality, and Development. In wave 1 (N = 350), we found strong positive correlations between emotion regulation strategies for the three emotions, indicating that people do not differentiate between emotions when regulating them. Adaptive strategies were negatively related to all psychological problems, while maladaptive strategies were positively related to all psychological problems. However, emotion-specific regulation strategies were not differentially correlated with aggression, anxiety, or depression. Our analysis of the factor structure and longitudinal data collection (wave 2, current N = 304) is ongoing and will provide further insights into prospective relationships between emotion regulation strategies and psychological problems. While our initial results suggest that maladaptive strategies are broadly associated with increased psychopathology and adaptive strategies with decreased psychopathology, regardless of the emotion being regulated, further analyses will clarify whether emotion-specific strategies offer additional concurrent and prospective value for the prediction of psychological problems."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Are facial expressions enough to recognize emotions? This study challenges the widely accepted assumption of facial expression universality in emotional recognition by investigating how contextual cues from visual and auditory sources modulate emotional perception in a Chilean population. We conducted three distinct experiments—unimodal visual, unimodal auditory, and bimodal visual-auditory—on 117 participants (50% women), employing the largest EEG sample in Latin America for this type of research. The goal was to explore the influence of context on emotional recognition beyond facial expressions alone. Our findings show that facial expressions, while important, do not fully determine the recognition of emotions. The congruence between facial expressions and surrounding visual or auditory contexts significantly affects both behavioral responses (reaction times and accuracy) and neural processing. EEG analyses revealed that the N170, P300, and N400 components responded to contextual information at both early and late stages of processing, with increased cognitive effort in conditions where there was incongruence between the facial expression and the contextual cues. Specifically, when the visual or auditory context was inconsistent with the facial expression, participants exhibited slower reaction times and lower accuracy, indicating higher cognitive load and deeper processing. In the bimodal experiment, both visual and auditory cues worked synergistically, enhancing the accuracy of emotional recognition. These results suggest that emotions are not solely processed through facial expressions; rather, they are shaped by a broader range of contextual information, which includes both auditory and visual elements. This study contributes to ongoing debates in the field of emotional perception, providing robust behavioral and neuroelectrophysiological evidence that challenges traditional models of facial expression universality. Our findings highlight the need for a more culturally inclusive approach to studying emotions and suggest that context plays a critical role in the accurate interpretation of emotional expressions, expanding the scope of affective neuroscience research."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["How do we truly assess the emotions of others? While numerous theories have highlighted the central role of facial expressions in evaluating emotions, some studies have challenged the ability to gauge others' feelings based solely on their faces (Aviezer et al., 2012). These studies suggest that we preferentially use bodies rather than faces to assess others' affective states. The aim of the present work is to replicate and extend these findings. A first preregistered experiment replicated the results obtained by Aviezer et al. (2012, Exp. 1). That is, the results (NExp1 = 194 - https://osf.io/h9pkn/?view_only=3716295e91614fbbb4d5706b3668923a) show that participants identified the expressed emotion only when bodies are presented on the picture. We conduct four other experiments to extend these results to other tasks (i.e., affective priming, affective misattribution procedure, feeling, and action tendencies). The results of the four preregistered experiments (NExp2 = 134 - https://osf.io/k6w2r/?view_only=5038a177e3944a53ad550ee1e8ae7965, NExp3 = 209 - https://osf.io/q4sut/?view_only=56fd0d79eb8e448a80539dbd3a0dedb3, NExp4 = 304 - https://osf.io/6zhdx/?view_only=3f33925fa59640afb68aec4b89b9eaed, NExp5 = 194 - https://osf.io/3n8m7/?view_only=505d186662614112a6b0813a2ea5cc41) show that stimuli presenting only bodies, rather than faces, consistently produce these classic effects found in the literature. Overall, these findings highlight that faces do not seem to be discriminative in detecting emotions, nor do they elicit affective reactions when affective stimuli are extreme. These results thus support the idea that context is predominant in the detection of emotions."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Abstract:  Introduction: Emotion recognition ability is essential for social cognition, enabling humans to interpret and respond to emotion-related cues effectively. However, so far it is not known how underlying cognitive deficits, including face processing, affect emotion recognition, particularly in patients with Mild Cognitive Impairment (MCI). Methods:  Sixty participants (patients with MCI = 30, healthy controls (HC) = 30), aged 50-86 years (M= 66.8, SD= 8.66) completed the emotion composite task (ECT), facial composite task (FCT), and emotion stroop task to measure emotion recognition (ER), face processing, and emotional arousal, respectively. Additional cognitive tests and an emotional intelligence (EI) questionnaire were included. Results:  Overall, patients with MCI performed about half of a standard deviation worse on ECT as compared with HC (β=-0.47), however, this effect was not significant. Emotion-specific analysis showed that anger recognition of the patients with MCI was particularly impaired (β=-0.86***). FCT showed a small positive effect on anger recognition (β=0.28*), indicating that participants with better facial processing skills recognized anger better. Self-control (β= 0.63), emotionality (β=0.71), and sociability (β=0.46) predicted ECT, indicating that participants with higher EI performed better in the ER task. Both FCT (β=0.17) and EI (β =0.98) contributed to the ER performance similarly in HC and MCI. Discussion:  While our results did not show significant overall ER performance deficits in patients with MCI, they showed specific impairments in anger recognition. Face processing ability contributed to anger recognition, suggesting that interventions, for example using ambulatory assessment, could train patients with MCI to maintain their face processing skills, especially for emotions that require more detailed processing, such as anger. Furthermore, emotion regulation training would help patients with MCI focus on real-world emotional cues, thereby improving their emotion recognition abilities. "]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Anxiety, defined as the primary emotional response to uncertainty, is fascinating in its ambivalence, being both a catalyst and an inhibitor of intellectual faculties towards addressing potential, imagined threats. Widely recognized as a significant source of individual suffering --especially in the context of mental well-being issues like depression and self-harm; anxiety also imposes substantial societal costs. These costs, which include ill health and lost productivity, scale to trillions of euros annually. Furthermore, anxiety is deeply political, being both a side effect and an enabler of power imbalances, disproportionately affecting already disadvantaged groups. Despite anxiety's pervasive influence on individual decision-making and its profound societal impact, research on systematically accounting for anxiety in operational contexts (e.g., within workplace settings) remains limited. Similarly, there is little focus on explicitly organizing efforts to address anxiety, such as sensing, anticipating, avoiding, mitigating, or responding to its triggers. This contribution explores how computational methods can address these gaps and expand the research landscape on anxiety. Specifically, we examine emerging trends in Anxiety-Sensitive Artificial Intelligence (AnxSAI), which focuses on AI systems equipped with models of anxiety. AnxSAI systems may be human-centric, adapting to anxiety-related factors (e.g., identifying anxiety-inducing elements in an environment, predicting how a system's actions might affect the anxiety levels of individuals), or simulating human-like deliberative processes and behaviors influenced by anxiety (e.g., artificial companions, agents in social simulations). Key findings on practical development and interdisciplinary relevance of AnxSAI will be introduced, such autonomous agents, active inference models, and large language models (LLMs) for research on human empathy, futures studies, and digital humanities."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Background:\n Digital mental health interventions increasingly incorporate embodied conversational agents, such as avatars, to enhance user engagement and support emotion regulation—a key transdiagnostic factor in psychiatric disorders. However, the effects of avatar realism on intervention efficacy remain insufficiently explored, particularly in the context of digital emotion regulation training. This study examines the impact of avatar realism on training outcomes, user perception, and self-disclosure. Methods:\n A total of 203 participants completed a 30-minute digital emotion regulation training session facilitated by a conversational avatar. Participants were randomly assigned to one of four conditions: (1) ultra-realistic human avatar, (2) abstract toon-style human avatar, (3) robot avatar, or (4) control (audio waveform animation). Training effectiveness, user perception of the avatar, and self-disclosure were assessed using self-report measures, including the Client Satisfaction Questionnaire (CSQ), emotion ratings, and items from the Unified Theory of Acceptance and Use of Technology (UTAUT). Results:\n ANOVA analyses revealed a significant main effect of condition on training satisfaction, with the ultra-realistic human avatar receiving lower ratings than all other conditions. Furthermore, interactions with the ultra-realistic avatar were rated as significantly more anxiety-inducing and less pleasant than those with other avatars. Positive emotions increased across all conditions except in the ultra-realistic avatar group during a gratitude exercise. Additionally, participants in the ultra-realistic avatar condition reported significantly lower levels of self-disclosure compared to all other conditions. Conclusion:\n The findings suggest that ultra-realistic human avatars may induce discomfort, thereby reducing engagement and intervention effectiveness, aligning with the uncanny valley hypothesis. These results have important implications for optimizing avatar design in digital mental health applications to maximize user acceptance and therapeutic efficacy."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Emotional states fluctuate dynamically in response to stimuli, requiring precise real-time measurement. Existing methods, such as slider-based and joystick-based systems, often lack intuitive responsiveness and introduce delays. We designed an interface that offers enhanced response ergonomics, allowing real-time visual feedback by continuously mapping emotional states (valence and arousal). Our gamepad-based interface overlays directly on stimuli and enables two-dimensional (x-axis: valence; y-axis-arousal) tracking of emotional states in real time. Participants get visual feedback through a red dot in the two-dimensional space as they continuously map their emotional state, concluding with a final arousal and valence response via the trigger button.We implemented a staircase training protocol to mitigate response biases arising from device unfamiliarity while systematically acclimating participants to the interface. The protocol begins with basic motor skill training involving gamepad handling and control, followed by iterative practice using a perceptual random dot motion task. Performance metrics are assessed at each stage to ensure proficiency before advancing to the main task. Experiment1 validated the interface against traditional slider methods using 61 images from the NAPS database in a two-block (order counterbalanced) design. In Block1, participants rated the images using traditional slider responses. Block2 used our overlay interface. The ratings from both methods showed high consistency for valence (r = 0.721) and arousal (r = 0.77).Additionally, Bland-Altman analysis revealed minimal systematic bias, confirming measurement equivalence between our novel protocol and established slider-based rating methods. Experiment2 extends this validation to dynamic video stimuli to track fluctuations in valence and arousal values with participant-specific calibrations, minimizing center-drift biases inherent in gamepad-based responses. We applied a low-pass filter to reduce high-frequency noise in motor movement data, preserving critical signal features.This interface advances emotion dynamics research by providing a robust and precise tool for continuous emotion annotation and has application in fields requiring real-time high temporal resolution data."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Transformative learning, as described by Koller (2012), is not the mere accumulation of knowledge but a deep process of changing interpretative patterns. Learners face situations that challenge their previous perspectives, requiring them to develop new ways of understanding (Kokemohr 2007). Emotions are central to this process, acting as catalysts for change by triggering cognitive dissonance and prompting reflection. For transformative learning to occur, the unknown must be perceived as incomprehensible (Waldenfels 1997). The emotional response to unfamiliarity—such as irritation, uncertainty, or discomfort—often initiates transformation. When an experience cannot be integrated into one's existing worldview and self-concept, emotional pressure emerges, compelling individuals to question established patterns of interpretation (Marotzki 1999). This emotional tension fuels reflection and the development of new perspectives, making education an emotionally shaped encounter with the unknown (Koller 2012). As Artificial Intelligence (AI) becomes increasingly integrated into education, a key question arises: how does it impact emotional learning experiences (Wunder 2021)? AI systems can support transformative learning by adapting to learners' emotions through personalized feedback, emotion-recognition algorithms, and adaptive learning techniques. For instance, intelligent tutoring systems can create cognitive conflicts by exposing learners to unfamiliar perspectives (Zawacki-Richter et al. 2020). AI-enhanced learning environments can also regulate emotions by mitigating uncertainty or fostering motivation (Kasneci et al. 2023). However, to what extent can AI truly understand and respond to emotional reactions? How do algorithmic decisions influence emotional engagement in learning? This poster presentation examines the intersection of transformative learning, emotions, and AI from an interdisciplinary perspective. It highlights AI's potential to foster emotional learning while critically evaluating its impact on transformative education and the ethical implications of digitalization."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Many situations evoke multiple emotions at the same time. Lange and Zickfeld's (2023) work showed that from four parsimonious, formal emotion theories, the network theory of emotions explains these co-occurrences best. According to this theory, emotions co-occur because their respective networks of interacting emotion components overlap. Of note, Lange and Zickfeld's research is preliminary as participants provided only self-ratings of their emotional experiences (i.e., feelings, cognitions, motivations, physiological changes, expressions) once after watching arousing videos, neglecting the dynamic and person-specific nature of emotions. We aimed to replicate and extend their findings by (1) incorporating multi-modal emotion measures, (2) testing implications of a multidimensional approach to co-occurring emotions, and (3) comparing emotion theories separately for each participant. Participants watched four videos eliciting awe and fear simultaneously. We continuously assessed appraisals, heart rate, respiration rate, skin conductance level, facial expressions, and piloerection, complementing the single-timepoint self-ratings that were already part of Lange and Zickfeld's study. We expect to finish data collection early in February. Ultimately, this study contributes to developing a formal theory of co-occurring emotions."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["The integration of continuous self-reports of subjective experience with physiological data is essential for advancing both cognitive and affective science. Here, we present CAMPEONES, a novel public database designed to capture the temporal evolution of emotional experiences in immersive virtual reality (VR) environments.\nIn this study, participants engaged in controlled VR tasks specifically designed to elicit a range of emotional responses. Emotional states were continuously recorded using a joystick that tracked dynamic rating trajectories, while peripheral physiological signals were simultaneously measured. Synchronization protocols ensured high-quality, multimodal data collection, providing a robust framework for subsequent predictive modeling.\nPreliminary analyses reveal associations between continuous emotional annotations and their corresponding physiological markers. The VR paradigm successfully elicited realistic emotional responses that correlated with the temporal dynamics of the continuous annotations.\nCAMPEONES makes a significant contribution to affective science by integrating subjective emotional experience with objective physiological correlates. This framework not only deepens our understanding of emotional dynamics in naturalistic settings, but also lays the foundation for AI-driven models capable of predicting the continuous experience of affective states."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Research suggests that unconscious emotional stimuli can elicit physiological and evaluative responses, yet the role of awareness in moderating these effects remains unclear. This study examined how emotions rendered unconscious through continuous flash suppression (CFS) influence skin conductance responses (SCR) and evaluations of novel faces. Forty-two undergraduate students (M = 21.98, SD = 4.21) participated in the study, and a two-alternative forced choice (2AFC) task was used to assess CFS efficacy, categorizing participants into aware (performers >50%) and unaware (guessers ≤50%) groups. Participants were exposed to disgust, fear, anger, and neutral expressions, while their SCR and post-trial face ratings were recorded. A 4 (emotion: disgust, fear, anger, neutral) × 2 (awareness: aware, unaware) mixed factorial ANOVA revealed that while emotion and awareness did not independently affect SCR, their interaction approached significance (p = .057, η² = .098), suggesting that emotional expressions may elicit stronger physiological responses in unaware participants. Descriptive statistics suggested that unaware participants showed numerically longer latencies across emotional conditions, with the largest difference occurring for neutral expressions, but this effect did not reach significance. In contrast, novel face ratings did not differ significantly across emotions or awareness levels (all p > .3). The overall mean face rating was 4.60 (SD = 0.96), with unaware participants ratings slightly higher (M = 4.90, SD = 1.19) than aware participants (M = 4.50, SD = 0.87), though this difference was not significant. These findings contribute to ongoing discussions on the dissociation between physiological responses and conscious affective evaluations, suggesting that while awareness may play a role in autonomic reactivity, its influence was not robustly significant. The results indicate that unconscious emotional processing may elicit physiological changes in some cases, but this does not necessarily translate into explicit affective judgments. "]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Preschool age is a crucial period for developing emotional competence, with deficits linked to long-term negative outcomes. However, studying emotions in young children is challenging, as their emerging regulation skills make emotions less observable, and their limited awareness and vocabulary hinder self-reports. Heart rate is a common physiological marker of emotional intensity and regulation, traditionally measured using electrocardiography (ECG) with chest electrodes. In contrast, wrist-worn sports watches offer a less invasive, more familiar alternative, increasing acceptance by children. These devices rely on photoplethysmography (PPG), which measures pulse rate by detecting blood volume changes in tissue via light sensors. While heart rate is well established in emotion research, the benefit of PPG-derived pulse rate as an indicator of emotion-related arousal remains unclear. To investigate this, 94 children from 16 German-speaking Swiss playgroups (Mage = 3.75 years, 58.62% female) participated in three standardized emotion-eliciting tasks designed to induce frustration, anticipation, and dynamic emotional shifts and one tablet-based emotion knowledge test serving as a physiological baseline. Each session was video-recorded, with children wearing Polar Vantage V2 watches for continuous physiological monitoring. Trained raters assessed emotional expression based on the recordings using the Emotion Regulation Scoring System. Linear mixed models will examine (1) whether pulse rate is associated with observed emotional expression, and (2) whether pulse rate differs between the emotion-eliciting tasks. If pulse rate reliably reflects emotion-related arousal, we expect higher pulse rates to correspond with more intense emotional expression during the emotion-inducing tasks. Additionally, we expect pulse rates to be highest during the frustration task, lower during anticipation, even lower during dynamic emotional shifts, and lowest in the baseline condition. If we can demonstrate that pulse rates reliably capture emotional processes in children, they could enhance field research and expand studies on institutional factors, such as peer influence and group dynamics. Keywords: Photoplethysmography (PPG), preschool children, emotional arousal, emotion expression  "]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Theoretical perspectives in the interdisciplinary field of the affective sciences have proliferated rather than converged due to differing assumptions about what human affective phenomena are and how they work. These metaphysical and mechanistic assumptions—shaped by academic context and values—have dictated the field's affective constructs and operationalizations. However, a foundational premise concerning the purpose of affective phenomena can guide us to a common set of metaphysical and mechanistic assumptions. In the capstone paper for the special issue “Towards an Integrated Understanding of the Human Affectome”, a collaboration among 173 affective researchers from 23 countries, we converge on a nested teleological principle for human affective phenomena: from the broadest purpose of an organism (to ensure viability), to complex organisms (to execute operations), then mechanisms of meaning (to enact relevance), and finally their human-specific projectivity (to entertain abstraction). Based on this principle, human affective phenomena can collectively be considered as algorithms that either adjust based on the comfort zone (affective concerns) or monitor those adaptive processes (affective features). Those for affective concerns indicate the adaptive relevance of the environment. These can be organized hierarchically according to distance from metabolic impact (immediate to distal), including physiological and operational concerns, and can also act as global summaries of concerns across time, such as trajectory and optimization. Those for affective features monitor how the adaptive process is going on a momentary basis, include valence (how well or not) and arousal (the extent to which various systems are mobilized), and can inform global concerns. This teleologically-grounded framework offers a principled agenda for organizing existing perspectives as well as generating new ones. Ultimately, we hope the Human Affectome brings us a step closer to not only an integrated understanding of human affective phenomena—but an integrated field for affective research through a forum for discussion."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["An individual's emotional state, or mood, has been shown to influence perception, attention, decision-making and other cognitive processes. Its effects extend to language processing, where it is seen as part of the pragmatic context. If a linguistic expression is non-neutral in itself, mood might augment or attenuate its perceived valence. Motivated by a lack of clarity regarding the nature and temporal dynamics of mood-valence interaction, we conducted an exploratory EEG study to find whether an individual's mood might change the temporal profile of emotional word processing. We looked at the interaction of mood and valence in a control and two mood-induced conditions over three consecutive time windows in a semantic categorisation task focusing on early processing, where data is inconsistent. In the three mood conditions, twenty-two healthy participants performed valence ratings of neutral, positive and negative words. Non-parametric cluster-based permutation tests were performed for the selected time windows and components to determine an unbiased scalp distribution. Results revealed an interaction in a happy but not sad mood. High valence words elicited greater N1 amplitudes (130-190 ms) in the control condition, but none in happy. In the subsequent time window (200-300 ms), congruence effects persisted: low valence words were attended to in a happy mood, as seen in increased P2 amplitudes, and high valence words were facilitated, as less negative EPN slopes show. In predictive-coding frameworks, mood is seen as a hyperprior that affects both the model and incoming signal. Happy moods make the model more precise and the input controllable. In this view, the results are interpreted as indicators of prediction error marked by the N1 and subsequent model update in the P2 time-window, with reduced amplitudes signalling a better-fitted model. A lack of a reverse pattern in a sad mood speaks in favour of asymmetrical mood effects on cognition."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Inattentional blindness refers to the failure to consciously perceive clearly visible information that unexpectedly appears while performing a task. Numerous studies have shown that inattentional blindness decreases (i.e., attentional capture increases) when unexpected stimuli have high emotional value, such as smiling faces or images of threatening objects or animals. However, emotional value often overlaps with the semantic value of the stimulus, which is also known to reduce inattentional blindness. To address this confound, three studies were conducted to 1) disentangle the distinct effects of emotional and semantic value on inattentional blindness, and 2) identify the conditions that optimize the conscious perception of unexpected stimuli. In all three studies, participants performed a line-length judgment task while being exposed to the same unexpected stimuli. The emotional and semantic values of these stimuli were systematically manipulated across the experiments. Additionally, two of the studies aimed to determine whether attention set theory or cognitive load theory better explains inattentional blindness. To this end, the task relevance of the stimuli and cognitive load of the task were manipulated. Task relevance was manipulated by embedding the line judgment in a driving context, using a narrative emphasizing the semantic or emotional significance of the task in a road scenario. Cognitive load was manipulated by asking participants to perform a digit span task at the beginning of each trial (retaining either one or six digits throughout the trial). Results will be discussed from a theoretical perspective, shedding light on the factors influencing attentional capture. Practical implications will also be addressed, offering recommendations for driving contexts to mitigate the potentially hazardous effects of inattentional blindness on the perception of warning signals."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["People update their expectations when presented with new information, but emotions may systematically influence how much they revise their beliefs. Positive emotions have been linked to greater openness to new information, while negative emotions have been associated with skepticism. However, it remains unclear whether such effects extend to expectations about an uncertain future. This study investigates whether emotions (positive, negative, neutral) influence the degree to which people update their expectations about future world events after receiving probabilistic expert feedback. Participants are randomly assigned to one of three emotional conditions (positive, negative, neutral) and complete an emotion induction task, selecting which of two emotional images (from the OASIS database) better fits an emotional quote. They then estimate the probability (0-100%) that a given statement about the world in 50-100 years will come true (e.g., “As automation takes over most professions, many countries will introduce a universal basic income.”). Next, they receive expert expectations about the event's likelihood, described as 75% reliable, and subsequently update their probability estimates. This sequence—emotional induction, prior expectation, expert feedback, updated expectation—is repeated for 15 statements. Finally, participants complete a PANAS questionnaire and a cognitive conflict detection task. To ensure statements were neutral in valence and moderately realistic, a pretest (N = 47) assessed 120 statements on perceived likelihood and desirability. The pretest confirmed that desirability significantly predicted likelihood ratings, and the main study includes 15 statements rated as neither desirable nor undesirable, with average likelihood ratings. Expectation updating will be modeled using linear mixed-effects models, testing whether (1) emotional states influence the magnitude and direction of updating (toward or away from expert feedback), and (2) emotions lead to systematic deviations from Bayesian updating. Exploratory analyses will examine (3) whether cognitive conflict detection moderates expectation updating, (4) whether the magnitude of expectation violation (the absolute difference between prior beliefs and expert feedback) modulates the effect of emotion and (5) whether emotional states influence trust in expert feedback, measured by calculating the weight of the expert's feedback in the participant's update. This study integrates emotional states and Bayesian updating to examine how emotions shape expectation revision about uncertain, real-world questions. Data collection will begin in February 2025, and results will be available at the time of the conference."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Hate in social science is often linked to perceived threats to identity, values, or safety. Allport (1954) associated prejudice and dehumanization with group-based threats, while Sternberg's \"Duplex Theory of Hate\" (2003) emphasized fear and anger as amplifiers. The 2024 U.S. election served as a catalyst for hate, with political opponents framed as existential or moral threats. Research by Fischer et al. (2018) and Halperin (2011) suggests that moral violations and political contexts magnify threat perceptions, while Aumer and Bahn (2016) argue that hate functions as a self-protective response. This study tested whether hate correlates more strongly with perceived threat than with prejudice or dehumanization. A total of 645 participants were recruited via Amazon Turk, with a final sample of 499 after data cleaning. Participants were divided into four groups—Democrats Pre-Election, Democrats Post-Election, Republicans Pre-Election, and Republicans Post-Election. Of these, 301 completed the survey before the election, and 198 after. The sample leaned Democratic (n = 366) over Republican (n = 133). Participants rated political figures and parties on measures of hate, perceived threat, and dehumanization, with the latter assessed through beliefs about targets' “evolved” status. Across groups, hate correlated with perceived threat (r = .53 to .62) significantly more than with prejudice (r = .0 to .23) or dehumanization (r = -.2 to .0). Fisher's Z-tests confirmed these differences (p < .01). Findings underscore perceived threat as the primary driver of hate, aligning with theoretical models from Allport to contemporary research. Hate arises when individuals perceive existential or moral threats, reinforcing political hostility. Addressing threat-based narratives may be key to reducing polarization and fostering societal understanding."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Objectives. When individuals feel psychologically threatened—whether due to financial instability or health concerns—their well-being often suffers. However, the underlying mechanisms driving this relationship remain unclear. This study investigates emotional suppression as a key pathway through which psychological threats may erode well-being. We propose that suppressing emotions in response to economic or health-related stressors can be counterproductive, draining self-regulatory resources and impairing problem-solving and social support. Specifically, we examine whether emotional suppression mediates the link between psychological threat, and overall well-being and health. Methods. A nationally representative sample of Spanish adults (N = 969) participated in the study. The average participant was 52 years old (range: 18–89), with a gender distribution of 55% male and 45% female. Household income averaged €2,469 per month, and all participants were in a romantic relationship at the time of the study. Results. Our findings reveal a striking pattern: individuals facing greater economic (but not health-related) psychological threat were significantly more likely to engage in emotional suppression. In turn, this suppression was strongly associated with diminished life satisfaction, lower happiness and positive affect, poorer physical health, and heightened levels of depression and anxiety. Crucially, these effects persisted even after accounting for gender, age, and socio-economic status. Conclusions. These findings highlight the hidden emotional cost of financial stress and the pivotal role of emotion regulation in shaping mental and physical health outcomes. When individuals suppress their emotions in response to economic hardship, they may inadvertently amplify their distress rather than alleviate it. Interventions that encourage healthier emotion regulation strategies could offer a powerful buffer against the negative effects of economic insecurity, ultimately promoting resilience and well-being in the face of psychological threat."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Theories of emotion and emotion regulation posit temporally recursive cycles between components of emotional episodes, including appraisals and subjective feelings (McRae & Gross, 2020; Scherer, 2022). Changing appraisals can modulate emotion, such as thinking about a situation as less relevant to oneself (Opitz et al., 2015). Despite substantial research on appraisal, less is known about the effect of relevance contexts other than one's own goals and well-being on emotion processes. We hypothesized that rating how much an emotional stimulus represents climate change or hope would affect valence and arousal ratings. United States adults (N = 298) from Prolific viewed 90 images, equally split between negative images of climate change, positive images of nature, and neutral images. After four seconds, response scales appeared, sequentially, below the image. Participants randomly assigned to the control condition rated only valence and arousal. In two experimental conditions, participants rated how much the image represented either climate change or hope, then rated valence and arousal. We tested effects with two linear mixed-effects models with random intercepts for participant and image, and a random slope for image type by participant. Fixed effects were condition (treatment coded), image type (sum-to-zero coded), and the interactions. Rating climate change increased negativity and negative emotion, whereas rating hope increased negativity but upregulated positive arousal and downregulated negative arousal. Results suggest that thinking about relevance to contexts beyond the self can affect emotion. These evaluations may involve processes similar to affect labelling, which, like hope ratings, can downregulate negative (Lieberman et al., 2011) and upregulate positive emotion (Vlasenko et al., 2021). More research would be necessary to compare relevance contexts to appraisals of relevance to one's own goals (Lazarus, 1991; Moors, 2017; Scherer, 2009). Lazarus, R. S. (1991). Cognition and motivation in emotion. American Psychologist, 46(4), 352–367. http://dx.doi.org/10.1037/0003-066X.46.4.352 Lieberman, M. D., Inagaki, T. K., Tabibnia, G., & Crockett, M. J. (2011). Subjective responses to emotional stimuli during labeling, reappraisal, and distraction. Emotion, 11(3), 468–480. https://doi.org/10.1037/a0023503 McRae, K., & Gross, J. J. (2020). Emotion regulation. Emotion, 20(1), 1. https://doi.org/10.1037/emo0000703 Moors, A. (2017). Appraisal Theory of Emotion. In V. Zeigler-Hill & T. K. Shackelford (Eds.), Encyclopedia of Personality and Individual Differences (pp. 1–9). Springer International Publishing. https://doi.org/10.1007/978-3-319-28099-8_493-1 Opitz, P. C., Cavanagh, S. R., & Urry, H. L. (2015). Uninstructed emotion regulation choice in four studies of cognitive reappraisal,. Personality and Individual Differences, 86, 455–464. https://doi.org/10.1016/j.paid.2015.06.048 Scherer, K. R. (2009). The dynamic architecture of emotion: Evidence for the component process model. Cognition & Emotion, 23(7), 1307–1351. https://doi.org/10.1080/02699930902928969 Scherer, K. R. (2022). Theory convergence in emotion science is timely and realistic. Cognition and Emotion, 36(2), 154–170. https://doi.org/10.1080/02699931.2021.1973378 Vlasenko, V. V., Rogers, E. G., & Waugh, C. E. (2021). Affect labelling increases the intensity of positive emotions. Cognition and Emotion, 35(7), 1350–1364. https://doi.org/10.1080/02699931.2021.1959302"]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["Political polarisation remains a major barrier to effective climate action, as fear-based messaging often reinforces ideological resistance rather than fostering engagement. This study explores cognitive reappraisal—a psychological strategy that reframes distressing narratives—as a potential tool for reducing defensiveness and inspiring pro-environmental behavior across ideological divides. Drawing on emotion regulation theory (Gross, 1998) and consumer culture perspectives, this research investigates whether reappraisal-based climate communication can increase hope, enhance self-efficacy, and promote constructive engagement. This study employs a two-phase experimental design. Phase 1 examines the emotional and cognitive impact of climate messaging across three conditions: (1) reappraisal-based (framing climate action as achievable and collaborative), (2) fear-based (highlighting catastrophic consequences of inaction), and (3) neutral (providing factual information). Participants (N = 400) are stratified by political ideology, and measures include emotional response (hope, fear), ideological defensiveness, and climate policy support. Phase 2 (N = 600) extends this analysis by examining behavioural intentions, including sustainable consumption and environmental actions. As an ongoing project, preliminary insights suggest that reappraisal messaging may foster more inclusive and action-oriented climate engagement by shifting focus from fear to empowerment and collective efficacy. This research contributes to consumer culture theory (CCT) by examining how psychological mechanisms shape climate discourse and legacy-building. Findings will offer practical guidance for marketing practitioners, policymakers, and NGOs in designing climate campaigns that resonate across ideological divides. By reimagining climate narratives through cognitive reappraisal, this study aims to transform socio-political legacies of climate discourse and promote a more constructive, inclusive, and action-driven approach to environmental communication. Keywords: Cognitive Reappraisal, Climate Communication, Emotion Regulation, Political Polarization, Consumer Culture"]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["When we think of social interactions between humans, we might think of the way we talk with each other to express our intentions and emotions, or our how we use our facial expressions to communicate an emotional state. However, there is another level in social interactions, driven by physiological activity. Not only do we re-act to others' emotions with changes in physiological activity such as heart rate or electrodermal activity, but we also seem to inter-act on a physiological level. Physiological synchrony, the co-regulation of physiological activity in a physiological measure across time has been found to be related to some positive outcomes, like better treatment outcomes based on client-therapist interactions. However, variations in synchrony might depend on situational factors, including emotional states. This symposium will discuss both trait and situational correlates of being in-sync or not, across various contexts. Roydon Goldsack will present a study investigating how physiological synchrony varies across emotional states and intensity levels when actors perform guided by a dramaturg and its impact on perceived effectiveness of a performance. Another context which requires perspective taking and hence adaptation to situational changes is joint action. When switching between tasks requiring collaboration, we need to read the other person's state. Sarah Boukarras will discuss how physiological synchrony changes based on these demands, and also consider variations in social anxiety. Sharing a moment of moment of intense stress takes the situational adaptation into the opposite direction. The last two presentations will focus on the effects of physical stress through the cold pressor test on physiological synchrony in couples. Bernadette Denk will speak about how partner stress decreases cardiac synchronization in romantic couples, and Aaron Hissey will present a study that included variation in personality to investigate the role of physiological synchrony in partner support during such a stressful situation.\n\nTo synchronise or not to synchronise? Investigating physiological synchrony in emotional performances\nRoydon Goldsack1,2, Nicola Hyland3 & Hedwig Eisenbarth2\n1School of Engineering, Victoria University of Wellington, New Zealand\n2School of Psychology, Victoria University of Wellington, New Zealand\n3School of School of English, Film, Theatre, Media and Communication, and Art History, Victoria University of Wellington, New Zealand\n\nInterpersonal collaboration, such as between audience members and musical performers, benefit from increased co-regulation of physiological activity i.e. synchrony. Additionally, emotional responses of audience members and their synchrony vary across different types of performances, such as variation in emotional content. However, these effects have been scarcely investigated in the context of theatrical performance let alone in an actor-director dyadic interaction. This context varies from the strictly audience-performer relationship as there is direct collaboration and impact on the final performance. We therefore hypothesized that variation in physiological synchrony between actor and director is related to actor-perceived effectiveness of the performance. We sampled actor and director heart rate, chest expansion and body acceleration across ~30 hours of performance varying in emotion and intensity. Actors (n = 2) rated their emotional state and performance convincingness after each recorded performance. Physiological Synchrony for heart rate, chest expansion and body acceleration were calculated using Surrogate Synchrony. T-Tests of estimated surrogate synchrony effect sizes indicated significant synchrony for almost all measures of synchrony, except non-absolute heart rate synchrony. Results from Linear Mixed Models showed that Physiological Synchrony varied significantly by the emotion performed, the level of intensity performed, and the physiological measure used. However, physiological synchrony was only rarely significantly related to the self-reported emotional state of the Actor and not at all related to the effectiveness of the performance. These findings suggest that the impact of physiological synchrony for performance might depend on the content of the performance. \n\n\nTask switching during nonverbal interactions promotes cardiac synchrony, while social anxiety reduces it. Considering the role of reciprocal attention in physiological synchrony.\nSarah Boukarras1,2, Valerio Placidi1,3,4, Federico Rossano1,2,4, Vanessa Era1,2, Salvatore Maria Aglioti1,2,4 & Matteo Candidi1,2\n1 Department of Psychology, Sapienza University of Rome, Italy\n2 Santa Lucia Foundation (IRCCS), Rome, Italy\n3 School of Advanced Studies, Centre for Neuroscience, University of Camerino, Camerino, Italy\n4 Sapienza University of Rome and CLN2S@Sapienza, Italian Institute of Technology, Rome, Italy\n\nIn nonverbal joint action tasks, two or more individuals must coordinate their movements in space and time to achieve a shared goal. This ability relies on processes of reciprocal prediction and monitoring, perception-action integration, and perspective-taking, all occurring simultaneously within the dyad or group. Such coordination can lead to the emergence of autonomic synchrony, as demonstrated in previous studies. However, the extent to which contextual and individual factors influence or modulate this synchrony in joint actions remains underexplored. In this study, we investigated how cardiac synchrony in joint actions is shaped by contextual demands—specifically, leader-follower roles and task novelty—as well as by dyad-level differences in willingness and ability to interact, measured through Social Anxiety and Perspective Taking. Our primary finding was that physiological synchrony increased whenever the dyad switched to a slightly modified version of the task. This suggests that the need to adapt and learn something new together enhances the interpersonal synchronization of physiological states. Additionally, subclinical social anxiety—characterized by an excessive shift of attention toward the self—hindered the emergence of physiological synchrony and reduced participants' enjoyment of the interaction. These findings indicate that physiological alignment is not merely a byproduct of behavioural coordination or shared task demands. Instead, it may reflect fundamental processes of reciprocal attention and social monitoring that support successful joint action.\n\n\nPartner stress decreases cardiac synchronization in romantic couples\nBernadette F. Denk1,2, Maria Meier1, Sebastian Ocklenburg3, 4, 5, Julian Packheiser6, Stella Wienhold1,2, Nina Volkmer1, 2, Raphaela J. Gaertner1, Elea S.C. Klink1, Stephanie J. Dimitroff7, Annika B.E. Benz1 & Jens C. Pruessner1,2\n1University of Konstanz, Konstanz, Germany\n2Centre for the Advanced Study of Collective Behaviour, Konstanz, Germany\n3Department of Psychology, Medical School Hamburg, Hamburg, Germany\n4ICAN Institute for Cognitive and Affective Neuroscience, Medical School Hamburg, Hamburg, Germany\n5Institute for Cognitive Neuroscience, Biopsychology, Faculty of Psychology, Ruhr University Bochum, Bochum, Germany\n6Social Neuroscience Lab, Ruhr University Bochum, Bochum, Germany\n7University of Montana, Missoula, Montana, USA\n\nPhysiological synchrony (PS), i.e., the alignment of physiological changes across individuals, is an established phenomenon characterizing social interactions. The degree to which interaction partners synchronize may depend on various relationship- and situation-specific factors. Stress profoundly affects behavior and cognition, but its effect on PS is still unknown. In a preregistered study, we thus investigated the effect of stress on PS in N = 75 romantic couples (mean age = 22.66 ±2.99, 51% female). Partners were separated upon arrival in the laboratory. In n = 38 stress dyads, one partner underwent the Socially Evaluated Cold Pressor Task (SECPT) while the other partner completed a non-stressful control task; in control dyads, both partners underwent the non-stressful task. After completing the intervention separately, partners were reunited and participated in a non-verbal synchronization task, a walking task, and an unstructured interaction. PS was operationalized by calculating cross-wavelet power of partners' heart rate trajectories. We hypothesized that PS would be altered in couples with one stressed partner compared to the non-stressed control group. Across all interaction tasks, PS was lower in stress than in control dyads. Our findings indicate that stress disrupts PS. In the discussion, we present possible mechanisms for this effect. Our results highlight that stress is not only an intra- but also an interpersonal phenomenon affecting interpersonal physiological processes and social interactions beyond the acute stressor. \n\n\nHarmful to Relationships, Helpful in Adversity: The Nuanced Role of Psychopathic Traits in Partner Support, Stress and Physiological Synchronisation\nAaron Hissey, Matt Hammond & Hedwig Eisenbarth\nSchool of Psychology, Victoria University of Wellington, New Zealand\n\nPsychopathic traits are associated with poorer romantic relationship functioning, yet their role in shaping partner stress responses during times of adversity remains unclear. This study explores associations among psychopathic traits, partner support, and stress in 100 romantic couples (N = 200) during a stress-induction task. We also examine whether psychopathic traits are related to physiological synchronization between partners and whether synchronization mediates links between psychopathic traits and stress. To assess physiological stress and synchronization, we measured heart rate, respiration, and skin conductance. Results suggest that individuals with higher psychopathic traits provide less support during times of stress, engage in less supportive relationships overall, and report poorer relationship quality. However, higher psychopathic traits were correlated with lower subjective stress and skin conductance scores during the stress-induction task, as well as lower heart rate scores for partners. These findings suggest that psychopathic traits may serve as a protective factor for stress in individuals, with some evidence indicating minor protection for partners as well. Furthermore, psychopathic traits were generally negatively associated with physiological synchronization, although evidence that synchronization mediates links between psychopathic traits and stress is limited. Our findings indicate that psychopathic traits offer some resilience to stress, but also undermine relationship quality, highlighting the complex role of psychopathic traits in romantic relationships."]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["NA"]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["NA"]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["NA"]}]},{"name":"div","attribs":{},"children":[{"name":"p","attribs":{},"children":["NA"]}]}]},{"id":"Nb","name":"Nb","type":"character","maxWidth":50},{"id":"Title","name":"Title","type":"character","minWidth":400},{"id":"Authors","name":"Authors","type":"character","minWidth":200},{"id":"Abstract","name":"Abstract","type":"character","show":false}],"searchable":true,"pagination":false,"highlight":true,"dataKey":"0273b9b5abc563de69b9d7d96458f11c"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/www\.cere2025\.com\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><img src="https://www.univ-grenoble-alpes.fr/uas/SITEUI/UGA_LOGO_PAGE_INTERIEURE/logo_epe_blanc_sans_marges.svg" class="img-fluid" width="150"></p>
</div>   
    <div class="nav-footer-center">
<p>#CERE2025<br> Université Grenoble Alpes, July 16-18, 2025<br></p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.isre.org/mpage/cere">
      <i class="bi bi-globe" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/CERE_Emotion">
      <i class="bi bi-twitter-x" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.instagram.com/CERE_Emotion/">
      <i class="bi bi-instagram" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>