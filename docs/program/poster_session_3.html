<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Poster Session 3 – CERE2025 - 10th Conference of the Consortium of European Research on Emotion</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../images/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-3b2160a2fc92221658aa6ab2fa9f3c79.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="../site_libs/core-js-2.5.3/shim.min.js"></script>
<script src="../site_libs/react-18.2.0/react.min.js"></script>
<script src="../site_libs/react-18.2.0/react-dom.min.js"></script>
<script src="../site_libs/reactwidget-2.0.0/react-tools.js"></script>
<link href="../site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="../site_libs/reactable-0.4.4/reactable.css" rel="stylesheet">
<script src="../site_libs/reactable-binding-0.4.4/reactable.js"></script>


<link rel="stylesheet" href="../assets/styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/logoCERE2025.png" alt="" class="navbar-logo">
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-program" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Program</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-program">    
        <li>
    <a class="dropdown-item" href="../program/index.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_16.html">
 <span class="dropdown-text">July 16</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_17.html">
 <span class="dropdown-text">July 17</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../program/days/july_18.html">
 <span class="dropdown-text">July 18</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-keynotes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Keynotes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-keynotes">    
        <li>
    <a class="dropdown-item" href="../keynotes/agnes_moors.html">
 <span class="dropdown-text">Prof.&nbsp;Agnes Moors</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../keynotes/jose-miguel_fernandez-dols.html">
 <span class="dropdown-text">Prof.&nbsp;José-Miguel Fernández-Dols</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../keynotes/steven_heine.html">
 <span class="dropdown-text">Prof.&nbsp;Steve Heine</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../submission/index.html"> 
<span class="menu-text">Instructions for Presenters</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-registration" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Registration</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-registration">    
        <li>
    <a class="dropdown-item" href="../attend/registration.html">
 <span class="dropdown-text">Registration Information</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://uga.azur-colloque.fr/inscription/en/232/inscription" target="_blank">
 <span class="dropdown-text">Log In the Registration Portal</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-attend" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Attend</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-attend">    
        <li>
    <a class="dropdown-item" href="../attend/venue.html">
 <span class="dropdown-text">Venue</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/accommodation.html">
 <span class="dropdown-text">Accommodation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/social.html">
 <span class="dropdown-text">Social Events</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../attend/transportation.html">
 <span class="dropdown-text">Transportation</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-people" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">People</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-people">    
        <li>
    <a class="dropdown-item" href="../people/index.html">
 <span class="dropdown-text">Organising Committee</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../people/committee.html">
 <span class="dropdown-text">Scientific Committee</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../faq.html"> 
<span class="menu-text">FAQ</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://x.com/CERE_Emotion" title="" class="quarto-navigation-tool px-1" aria-label="" target="_blank"><i class="bi bi-twitter-x"></i></a>
    <a href="https://www.instagram.com/CERE_Emotion/" title="" class="quarto-navigation-tool px-1" aria-label="" target="_blank"><i class="bi bi-instagram"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <div id="quarto-announcement" data-announcement-id="a099f15fa5df9b7c51d563318a7a5b0d" class="alert alert-info hidden"><i class="bi bi-info-circle quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>A new version of the program is available <a href="https://www.cere2025.com/program/">here</a> (July 4th)</p>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Poster Session 3</h1>
</div>



<div class="quarto-title-meta column-page">

    
  
    
  </div>
  


</header>


<p>Abstracts available when clicking on “Show Abstract” buttons:</p>
<div class="cell">
<div class="cell-output-display">
<div class="reactable html-widget html-fill-item" id="htmlwidget-25d90cccfaa5d28ab5d4" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-25d90cccfaa5d28ab5d4">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"Title":["Comparing the effectiveness of putatively adaptive and maladaptive emotion regulation strategies: An experience sampling study","Validation of Affect Labeling as an implicit emotion regulation task in a Greek-speaking sample","Neuroticism and the neural basis of implicit cognitive reappraisal: an fMRI study","Emotion Regulation Flexibility Through the Lens of Resting-State Functional Connectivity","Boredom and Arousal: A Multilevel Meta-Analysis","Do we exhibit differential immune responses to different types of disgust?","Evidence on female sexual arousal as an emotional state unconsciously triggered by sexual stimuli","How Honour Amplifies the Perceived Threat of Jealousy, and Controlling Behaviour","Dimensional and Categorical Emotional Ratings of Russian Nouns: The Database ENRuN-2","Four-dimensional neural space for moral emotions","Comparing your \"happy\" to my \"happy\": How to assess the affective space of an individuum","Exploring Emotional Granularity through Freely Generated Mental and Bodily Labels: A Network Analytic Approach","The Role of Categorization in Emotion Differentiation","The Dimensionality of Positive Valence","Attachment dimensions predict how and why people regulate their partner's emotions: A daily diary dyadic study","From Appraisals to Action: The Influence of Compassion and Distress on Prosocial Behavior","Investigating the interplay of self- and other-oriented benefits in motivational and experiential component of prosocial behavior","Subjective valuation from individual decision-making to joint action","Develop emotional intelligence through mentalisation with Emocube for inclusion through trust and empathy","The impact of incidental emotions on decision making in job interviews","Lack of robust emotion effects on attentional breadth: four web-based experiments","Physiological Manifestations in Strategic Decision-Making under Conditions of Uncertainty: Insights from the Iowa Gambling Task","Musical Emotion Transfer in Expert Listeners","Prosodic Emotion Recognition is Associated with Musical Abilities in Children","Moral Emotions vs. Bildung: Navigating Professional Formation in Academic Teaching and Learning","CambiaColore: a movement-based technology for socio-emotional learning in the classroom","Compensatory Mechanisms and Affective Consequences in Femininity and STEM Professional Goal Pursuits","DiffuseFace: a database of AI-generated face portraits to enrich diversity in emotion research.","A scoping review on positive emotions in autism","Processing negative stimuli and beyond: Emotional dynamics in at-risk individuals with independent or co-occurring anxiety and depression symptoms","Dissociative reactions - on the transient inability to feel emotions"],"Authors":["Rasskazova Mariia, Lyusin Dmitry","Constantinou Elena, Koursarou Sofia","Várkonyi Gergő, Rendes Réka, Deák Anita","Ohad Tal, Madar Asaf, Tavor Ido, Sheppes Gal, Yeshurun Yaara","Stempfer Lisa, Stoll Sarah E. M., Fries Jonathan, Pekrun Reinhard, Goetz Thomas","Mungur Ramandeep, Harris Lasana, Purcell Daniel, Ogbe Orezi","Joana Carvalho, Rosa Pedro, Silva Samuel","Shaban Azad Hadi, Giner-Sorolla Roger, Pina Afroditi, Grigoropoulos Iraklis","Sysoeva Tatiana, Lyusin Dmitry","Chen Jinglu, Santavirta Severi, Putkinen Vesa, Boggio Paulo Sérgio, Nummenmaa Lauri","Horn Francisca, Kreuzpointner Ludwig, Wüst Stefan, Schwarzbach Jens V., Kudielka Brigitte M.","Telazzi Ilaria, Biassoni Federica, Ninivaggi Elisa, Viaggi Eleonora, Balzarotti Stefania","Suchkpva Ekaterina, Lyusin Dmitry","Brandolini Gabriel, Carter Olivia, Koval Peter","Maccann Carolyn, Wu Bernice","Garrido-Macías Marta, Valor Segura Inmaculada, María Teresa Guzmán","Monnor Teerawat, Preuschoff Kerstin, Ugazio Giuseppe","Navare Uma, Belkaid Marwen","Gehringer Carol","Jendroska Fabian, Wuttke Yannick","Martin Kolnes Martin, Uusberg Andero","Yaghoubian Elahe, Moghimi Ali, Izadifar Morteza, Kobravi Hamidreza, Totonchi Nilufar","Varga Peter, Parkinson Brian","Fasano Maria Celeste, Nuti Gianni, Monaci Mariagrazia, Filippa Manuela","Musaeus Peter","Ceccaldi Eleonora","Zaman Sadia, Spychalska-Waszek Hanna, Doerflinger Johannes T, Gollwitzer Peter M., Byrka Katarzyna","Firmani Alessia","Moreno Laura, Manfredi Mirella, Di Poi Giona, Gruber June, Mcpartland James C., Samson Andrea","Rendes Réka, Lang Diana Agnes, Varkonyi Gergo, Deak Anita","Daniels Judith"],"Abstract":["Emotion regulation (ER) refers to the ability to regulate the intensity, frequency, and duration of emotions. One of the key questions is the relation between ER strategies adaptiveness, i.e. to which extent a strategy is related to long-term outcomes, and effectiveness, i.e. to which extent a strategy changes emotion at the moment. This study examined the effectiveness of putatively adaptive (cognitive reappraisal, problem solving, and acceptance) and maladaptive (suppression, rumination, and avoidance) ER strategies using experience sampling.    Method. For ten days, participants (N = 112, aged 18–52, M = 27.30, SD = 8.74; 99 females, 13 males) reported to which extent they experienced seven negative emotions (anxiety, irritation, loneliness, guilt, depression, apathy) and used the aforementioned ER strategies since the previous report. Six-point Likert scales were used for responses. Two indices of the use of ER strategies were analyzed, frequency (how often a strategy is used) and intensity (how intensely a strategy was employed at the moments when it was used). The direct measure of strategy effectiveness was the correlation between the intensity of its use and a decrease in negative affect calculated across all measurement points within a participant.   The differences between the effectiveness of adaptive and maladaptive ER strategies were not statistically significant. Noteworthy, adaptive strategies correlated positively with a decrease in negative affect, whereas negative correlations were obtained for maladaptive strategies. The use of strategies was also associated with higher average negative affect, with this effect being larger for frequency compared to intensity. These associations were weaker for adaptive strategies which can be interpreted as their more flexible use and may indirectly indicate their higher effectiveness. To better understand the comparative effectiveness of these strategies, in future it would be useful to include other relevant variables in the analysis, such as emotion differentiation and emotional reactivity.   Key words: emotion regulation, negative affect, experience sampling","Objectives: Previous studies have shown that merely labeling an emotion can have emotion regulatory effects, from modulating brain activity to dampening the subjective experience of emotion. The aim of this study was to validate a modified Affect Labeling task (Constantinou et al., 2014) in Greek by examining its effect on subjective emotion experiences and its association with self-reported emotion regulation difficulties. Methods: Sixty-six (so far) Greek-speaking young adults completed six picture viewing trials (3 pleasant, 3 unpleasant), under three within-subject conditions: merely viewing the pictures, labeling the depicted emotion or labeling the content depicted on each picture. After each trial participants rated their experienced pleasantness (valence) and arousal. Accuracy and response time during the labeling tasks were recorded, while participants also completed the Difficulties in Emotion Regulation Scale (DERS), as a construct validity measure.  Results: Preliminary results showed that both content and affect labeling resulted in dampened negative emotion (increased valence and reduced arousal), but only content labeling dampened pleasant emotion. Correlation analyses showed that content and affect labeling effects were highly correlated with each other, but were both unrelated to the accuracy or speed of labeling. Furthermore, affect labeling effects were unrelated to participants' self-reported difficulty in emotion regulation. Discussion: Current findings replicate previous studies confirming that affect labeling can dampen both the valence and arousal components of emotions, particularly negative ones. The fact that affect labeling produces emotion regulatory effects comparable to those of content labeling, and unrelated to participants' performance, may indicate that affect labeling effects rely on a symbolic conversion mechanism inherent in the process of labeling (regardless of what is labeled). The lack of correlations with self-reported difficulties in emotion regulation, further confirms the implicit nature of the labeling effects and supports the usefulness of the task among individuals with emotion regulation deficits. ","Cognitive reappraisal is a form of emotion regulation that entails the systematic reframing of an emotion-eliciting stimulus (e.g. changing one's construal of an emotional event). It is a skill with notable individual differences and trait neuroticism is one of the primary sources of this variability. Therefore, in our study, we aimed to explore the neural basis of cognitive reappraisal while also investigating how neuroticism modulates the observed associations. 40 young adults filled in the neuroticism subscale of the Big Five Inventory, and we registered their brain activation in an implicit reappraisal task comprising 15 pairs of social-emotional images with negative and non-negative captions. Outside the scanner, participants were presented with the same images and instructed to rate their emotional experiences on valence and arousal dimensions. Whole-brain analysis revealed that both negatively and non-negatively labeled images recruited prefrontal control cortices (e.g. vlPFC), suggesting that stimulus captions inherently evoked regulatory operations. ROI analysis showed that arousal (but not valence) ratings correlated significantly with reappraisal-related activation in the vlPFC, dlPFC, dmPFC and caudate, indicating that our paradigm was more effective in capturing arousal (versus valence) modulation. Finally, our analyses implicated that neuroticism played a moderator role between regulatory brain activation and reappraisal success of arousal in that successful reappraisal required more neural and cognitive resources in high (compared to low) trait scorers. Taken together, our results corroborate the notion that many forms of emotion regulation rely on large-scale brain networks, however, it also demonstrates that the functioning of the network might depend on trait-level individual differences, which needs to be further addressed in future research.","Emotion regulation flexibility (ERF) is the ability to adjust regulatory strategies to differing circumstances. Although ERF was shown to be linked with individuals' well-being, the neural mechanisms underlying it are currently unknown. In this study, we set out to explore the neural correlates of ERF, and specifically test the hypothesis that more flexible connectivity between brain networks will be associated with more flexible emotion regulation. To test this, 40 participants underwent behavioral evaluation of ERF ability and resting-state fMRI scanning, as resting-state fMRI has been shown to represent trait-like aspects of network functional connectivity. The behavioral task included aversive words of high and low intensity, and participants were required to choose between two strategies to regulate their emotions: distraction or reappraisal. Behavioral results revealed large variability in ERF scores (M=20.13±15.83), which enabled the examination of individual differences in neural functional connectivity. Preliminary neuroimaging results revealed that ERF scores were negatively correlated with functional connectivity between the Control Network and Attention Networks, and the Default Mode Network (DMN), such that the stronger the connectivity between these networks, the lower the emotion regulation flexibility score. These findings suggest that lower connectivity between neural networks involved in control, attention, and theory of mind processes, may allow for more effective switching between emotion regulation strategies, which characterize individuals with high emotion flexibility capacity. ","Boredom is often described as a negative emotion characterized by low physiological arousal. However, empirical studies on the level of arousal associated with boredom remain contradictory. Narrative reviews have discussed these findings, but the available evidence has not yet been analyzed quantitatively. Therefore, we conducted a multilevel meta-analysis on the boredom-arousal relation in correlational and experimental studies. A comprehensive literature search was performed in November 2023. Overall, 214 effect sizes from 75 unique samples fulfilled the inclusion criteria (total participant sample size N = 6,570; 47.45% female). The analysis yielded a significantly negative average effect size (d = -0.36; 95% CI [-0.49, -0.22]). The correlational evidence suggested that more intensely experienced boredom was related to reduced arousal, r = -.13, 95% CI [-.22, -.05]. The aggregated experimental evidence showed that the state of boredom was associated with significantly lower arousal as compared to various control conditions; d = -0.40, 95% CI [-0.59, -0.22]. However, moderator analyses suggested that arousal was not significantly lower in boredom as compared to neutral conditions. All types of physiological indicators showed significant negative relations to boredom, except for heart rate variability. There was no indication of a publication bias. In sum, we present the first meta-analytic study on the relation between boredom and arousal which suggests that boredom is best characterized as a low-arousal emotion. Implications for emotion theory and practice are discussed.","Background: Disgust is hypothesised to have evolved to detect pathogens, later being coopted into the social domain. Chapman and colleagues' (2009) argued that moral and physical disgust were the same emotion, owing to both evoking the same facial expression. Conversely, Tybur and colleagues (2009) argued that disgust can be split into three distinct domains: Pathogen, Sexual, and Moral. Previous studies have shown that the perception of disgusting images can lead to a preparatory immune response (e.g. Stevenson et al., 2012). It is unclear, however, if any specific type of disgust drives this effect. For instance, seeing human excrement may be associated with a pathogen/disease threat, hence a preparatory immune response is logical. Conversely, witnessing someone commit fraud should not be associated with a disease threat, yet may still be both appraised and described as disgusting (though anger may also be a significant emotion in moral disgust (Giner-Sorolla et al., 2018)). To better understand if all disgust is the same, we test if all types of disgust produce the same immune response. Methods: In this between-subjects study, participants are placed in one of four groups with 34 participants per group (n = 136). Each group is shown scenarios (captioned images) that were designed to evoke one of pathogen, sexual, or moral disgust, with the control group being non-moral anger. We measure the salivary immune responses for the following pro-inflammatory cytokines: TNF-alpha, IL-6, and IL-1 beta. Predicted results: There will be a significant difference in condition, with Pathogen Disgust eliciting a significantly higher immune response compared to both the Moral Disgust and Control conditions. The Moral Disgust condition will elicit a significantly higher immune response compared to the Control condition. No predictions are made regarding Sexual Disgust owing to the scant research in this area. Please note that data analysis is ongoing. ","Background: Sexual arousal has been defined as an emotional state underpinning sexual response. Information-processing models of sexual response consider that sexual arousal develops from the unconscious appraisal of sexual stimuli and progresses toward stages of overt sexual behavior. Sexual arousal as an emotional state is expected to be indexed by the privileged allocation of pre-attentional/unconscious resources toward sexual stimuli. Yet, evidence of the unconscious appraisal of sexual stimuli in women lacks empirical evidence; the onset of female sexual arousal remains a topic of debate. \nAim and Methods: The current study aimed to collect evidence on the unconscious processing of sexual stimuli (male and female nudes), as opposed to non-sexual (dressed male and female characters) and neutral (objects) stimuli, in cisgender, heterosexual women. Forty-seven women performed a breaking continuous flash suppression task (b-CFS); for each stimulus condition (sexual, non-sexual, and neutral condition), its upside-down version allowed the disentangling of the effects of low-level features. \nResults: Data were analyzed through a Linear Mixed Model approach. Findings revealed that the sexual stimulus condition did not affect pre-attentional responses, as indexed by women's reaction times toward the images. Furthermore, follow-up Pearson's correlations showed that women's reaction times toward sexual cues were not associated with participant's propensity to get sexually aroused or sexually inhibited. \nConclusion: In all, despite theoretical assumptions that consider female sexual arousal as an emotional state emerging at the unconscious level of information processing, findings do not support such a claim. Indeed, female sexual arousal likely develops through a complex chain of psychosocial events, being shaped by a series of learning and socializing processes.","In many Middle Eastern cultures, “gheirat” is an honour-based protective emotional reaction to relational boundary violations which usually elicit jealousy in other cultures. The present study explored and compared the experience of gheirat in Greece and UK as honour and non-honour cultures. 236 British and 262 Greek psychology students took part in an online survey and were asked to describe an experience where a 3rd person or/and a loved one were getting too close to the other. Participants rated their affective states during the experience, and completed questionnaires on dispositional jealousy, honour orientation, and attitude towards intimate partner violence. Greek participants appraised the experience of relational boundary violation as more threatening to their loved one compared to British participants. Furthermore, they reported higher levels of feeling “worried”, “vigilant”, “controlling”, and “outraged” during the experience. Greek participants also scored higher on preventive jealousy (but not reactive and anxious jealousy), acceptance of sexual violence, and psychological violence. This heightening of preventive jealousy with honour was also observed within both cultures. Greek participants scored higher on all subscales of honour orientation. These results suggest that jealousy-eliciting situations are experienced as more threatening to the loved one in honour cultures. This may lead to preventive jealousy tendencies, and higher acceptance of controlling behaviour (a form of psychological violence), which is a response to higher acceptance of sexual violence by society.","Databases with emotional ratings of words are used in a wide array of emotion and cognitive research including the processing of emotional information, mood induction, and sentiment analysis. There are two main approaches to emotional ratings used in the development of such databases: dimensional, where words are rated along the major affective dimensions such as valence and arousal, and categorical, where associations with discrete emotion categories such as happiness or anger are rated. These databases exist in many languages but until now, there has only been a small Russian database containing 378 nouns. We present its expanded and advanced version ENRuN-2 that contains approximately 6,000 Russian nouns of different frequency and length. ENRuN-2 includes both dimensional (valence and arousal) and categorical (happiness, sadness, anger, fear, and disgust) ratings for each word, as well as information on word frequency and length. Each word was rated by at least 10 male and 10 female native Russian speakers aged between 18 and 77 years old (M = 24.54, SD = 9.84). Psychometric analysis showed high reliability and validity of the obtained ratings for all scales. Intra-rater consistency ranged from 0.744 for sadness to 0.935 for happiness, and inter-rater consistency varied from 0.873 for arousal to 0.961 for valence. Validity was estimated by the correlations between the ENRuN-2 and previous ratings, which were no smaller than 0.854 across different scales. Relationships between the scales replicate typical patterns found in the similar databases, including a U-shaped relationship between valence and arousal, and moderate negative associations between ratings for negative emotion categories. ENRuN-2 is a free access database and allows for the addition of new words and emotional rating scales.","Moral reasoning is an intuitive process guided by abstract moral principles and life experiences that individuals use to evaluate moral dilemmas and make decisions regarding right and wrong. Moral foundations theory proposes a framework of intuitive moral reasoning across populations, yet the brain basis of processing different moral dimensions remains unclear. Here we mapped brain networks involved in moral reasoning during naturalistic movie viewing. A total of 104 participants watched a Finnish film Käsky during functional MR imaging. The movie depicts an emotional and morally complex story about the Finnish civil war. Dynamic ratings of 20 emotions and moral dimensions, derived from the moral foundations theory, were collected from 43 viewers. Dimensionality reduction was employed to identify the dependencies among the moral dimensions, while general linear model, cumulative analysis and intersubject correlation (ISC) analysis identified associations between high-order moral dimensions and brain activity. Our analysis revealed four primary moral dimensions: virtue (positive morality), hierarchy (collective respect), rebellion (self-interest), and vice (moral transgressions). These dimensions reflect two key aspects of moral perception: (1) the evaluation of behaviors as morally right or wrong, and (2) the assessment of whether these behaviors are directed towards individuals or groups. Each of these clusters exhibited distinct neural activation patterns. The vice cluster demonstrated the most extensive positive activation, while the hierarchy cluster was associated with significant negative activation. Both the anterior cingulate cortex and the middle cingulate cortex showed positive activation exclusively in response to the vice cluster, suggesting that this may represent a neural signature for vice-related moral reasoning. ISC analysis and cumulative mapping highlighted widespread brain activation during moral scenes, encompassing extensive cortical areas, cingulate cortex, and striatum. Collectively, our results support a four-dimensional neural and psychological space for moral reasoning, which engages extensive brain regions and distinct patterns across moral foundations.","Emotions are of utmost relevance for our everyday life as well as in the development and maintenance of psychological disorders. Regarding theories underlying these constructs, research mainly focusses on a generalizing perspective for all humans, neglecting the inherent individual component. By developing an instrument that measures the individual affective space of a person, we endeavor to apply the personalized medicine approach to emotions and transfer the results to psychiatry and psychotherapy for better diagnostics, treatments, and prevention interventions. Therefore, we compared three methods to assess individual mental representation of emotions: 1) A Multi-Arrangement Task (MAT), 2) Pairwise Comparisons (PC), and 3) Self-Assessment Manikin (SAM) rating scales. Using a within-subjects design with N = 100, emotionally loaded adjectives of the Affective Norms for English words (ANEW) were arranged or rated according to the respective method on a computer monitor with subsequent calculation of a dissimilarity matrix (DSM). Analyzing these DSMs showed good test-retest reliabilities for each method while clear differences emerged in the exploratory analyses. Dimensionality analyses using multidimensional scaling showed two or three dimensions yielding an ideal solution to represent the data in the SAM with some participants using up to five dimensions in the MAT. Plotting the affective spaces into polygons revealed the highest correlation of the surface areas in the MAT, indicating that the MAT might be the better instrument when the focus is on assessing emotion differentiation. Trying to identify underlying group structures with Ward-clustering was not successful in any of the three methods.","Emotional granularity (EG) refers to the ability to make fine-grained distinctions among emotional states, reflecting individual differences in the use of emotion concepts to construct emotional experiences. Traditional approaches to EG have primarily focused on mental state terms. However, it has recently been suggested that incorporating bodily terms alongside mental descriptors provides a more comprehensive representation of emotional experiences. According to this perspective, we employed a network analytic approach to explore EG across different levels of analysis. Eighty-five women suffering from chronic pelvic pain participated in a one-month diary study. For each pain episode, participants freely generated and rated affective labels describing their current affective experience and subsequently evaluated their emotional state using a set of 14 negative emotional adjectives. Preliminary results indicate that participants used a broad range of affective labels, encompassing both mental and bodily terms. Notably, differences emerged in the network structure between individuals with high and low EG. Women with lower EG reported a greater number of affective labels, primarily mental in nature; conversely, those with higher EG exhibited a greater number of distinct emotion communities and a more coherent pattern of connections. Overall, our findings emphasize the value of assessing EG beyond standardized lists of mental state terms. Incorporating both mental and bodily descriptors may offer a more accurate definition and operationalization of the construct. A conceptual framework that is less strictly mentalistic could provide a more comprehensive representation of the complexity of emotional experiences.","Emotion differentiation (ED) refers to an individual's ability to distinguish between their emotions. This capacity is a significant predictor of effective emotion regulation and psychological well-being. The present study aimed to explore the cognitive underpinnings of ED by examining its relationship with categorization. Participants (N = 74, aged 18–53, M = 24.23, SD = 7.86; 52 females, 22 males) completed two versions of a card sorting task (emotional and neutral) and underwent a 10-day experience sampling protocol. ED was measured using the inverse ICC (3, k) with Fisher's z-transformation. Categorization was assessed as the average number of categories created across four subtests for each task version. Results revealed a significant positive correlation between number of categories in the emotional and neutral versions of the sorting task (r(74) = .57, p < .001). Additionally, positive and negative ED measures were positively correlated (r(74) = .24, p = .041). However, no significant correlation was found between number of categories and ED. These findings suggest that while categorization is consistent across emotional and neutral contexts, it does not serve as a cognitive basis for ED. This raises intriguing questions about the nature of ED, as it may operate in a distinct psychological space, potentially independent of traditional cognitive processes. Further research is needed to uncover the mechanisms underlying ED and its unique role in emotional functioning.   Key words: emotion differentiation, categorization, experience sampling","Positive valence is the intrinsic positivity or pleasantness of an emotion, feeling, or mood. Emotion researchers disagree on whether positive valence is unidimensional - a single spectrum ranging from minimally positive to maximally positive - or multidimensional - a complex construct that accommodates multiple distinct ways an emotion can be experienced as positive. To test whether positive valence is unidimensional or multidimensional, we provided participants (N=292, Female=61%, Age: M=19.96, SD=5.66) choices between video stimuli from different emotion categories (Admiration, Amusement, Awe, Romantic-Love, and Surprise) while utilising a film+instructions mood induction procedure. Participants selected the response option which resembled their more ideal emotional state, and also rated the videos on valence, emotional-intensity and novelty (adapted from Affect Rating Dial). Results showed participants reliably chose the option with higher valence, regardless of emotional category (Predictions=2113/2308, Accuracy=91.55%, WAIC=1.258). This provides evidence that valence functions as a 'common currency' across these different positive emotions, pointing towards the unidimensionality of valence by suggesting a shared form of positivity. We also generated stimuli with response options combining videos from multiple emotional categories to explore how valence was operationalised in the decision-making process. Rather than using a lexicographic, winner-takes-all, or loser-takes-all strategy, results showed participants usually summed the valence of individual videos to determine decision outcomes (Predictions=2121/2906, Accuracy=73%, WAIC=1.635). This suggests individuals tend to aggregate the valence of complex stimuli in an additive process when determining their ideal emotional state.\n\nFinally, participants made judgements about their experience of 11 positive emotions in terms of 15 candidate valence dimensions (e.g., pleasure, goal-congruence, action-tendency, morality, object-appraisal, inner-reinforcer). We utilised factor analysis to discern whether valence emerged as a single unified factor (unidimensional) or whether distinct elements of valence emerged as multiple factors (multidimensional). Parallel analysis, a reliable method for determining how many factors to retain, indicated that only one of these factors was statistically significant beyond random chance. This finding lends further support in favour of the unidimensional view of positive valence. ","Attachment anxiety and attachment avoidance underlie many patterns of interaction in adult relationships. The current study examines whether these attachment dimensions predict the emotion regulation goals and strategies people use to regulate their partner's emotions. In our study, 195 opposite-sex couples recruited from Prolific completed a short attachment assessment and 6 end-of-day surveys over 3 consecutive weekends. Actor Partner Interdependence Models were used to model the effect of attachment on regulation goals and regulation strategies. For instrumental regulation goals, several actor effects were significant for both men and women: 1) attachment anxiety predicted greater pro-social goals (increase closeness/reduce conflict) and impression management goals; 2) attachment avoidance predicted greater ‘gain power' goals. Actor effects on hedonic goals (make self feel better, make partner feel better, make partner feel worse) and partner effects on all goals differed for men versus women. For all three affect worsening strategies (criticizing, withdrawing, pressuring), attachment avoidance showed significant actor *and* partner effects for both men and women, with stronger goal formation and greater use of strategies in all cases. Of the five affect-improving strategies, only one actor effect (and no partner effects) was significant for both men and women: Avoidant attachment predicted lower valuing. This study demonstrates that adult attachment—and particularly attachment avoidance— is an important driver of why people attempt to regulate their partner's emotions (regulation goals) and also how they do it (regulation strategies). ","Every day, we encounter situations where others need our help. The literature indicates that the perception (appraisals) of those in need influences the level of compassion experienced and, consequently, the willingness to help. However, it remains unclear how distress affects helping behavior. Studies suggest, first, that there are two types of distress and, furthermore, that self-focused and other-oriented distress have distinct impacts on helping behavior, highlighting the importance of distinguishing between the two forms. Thus, the main aim of this research is to explore the role of appraisals, as well as emotions of distress and compassion, in shaping helping behavior. To carry out the study, a sample of 1,542 participants from the general population was used (Mean age = 50.99, SD = 18.42; 50.7% women and 49.7% men), who were recruited through a survey company (NETQUEST) in June 2023. The measures included in the analysis were a suffering scenario, the observer's assessments (identification with the person in need, attribution of responsibility, and perceived self-efficacy), emotions of compassion and distress, and helping behavior (specific and general). Results revealed that both compassion and other-oriented distress mediated the relationship between appraisals and helping behavior. Specifically, greater similarity to the person in need, lower attribution of responsibility, and higher perceived efficacy were linked to increased levels of compassion and distress, which, in turn, were associated with a stronger desire to provide both specific and general help. This study broadens our understanding of how compassion and distress can improve helping tendencies in stressful situations.","Prosocial behavior is fundamental to social cohesion, encompassing diverse interactions where individuals exert effort to benefit others, ranging from helping to collaboration. While prosociality manifests in various forms, its multifaceted nature is often unexamined and instead observed as a unitary construct. Although this approach provides valuable insights and facilitates systematic assessment, it may overlook nuances of this behavior. To contribute to addressing this gab, this project adopted a componential approach to emotion to investigate key components of prosocial behavior—effort mobilization and affective experience following task completion—in different combinations of self- and other-oriented benefits. A redesigned version of an effort-based slider task was employed, where different dimensions of the effort and affective experiences were assessed using self-report, heart rate variability (HRV) analysis and performance-based measures obtained during task performance. Participants (N = 51; 16 males, 28.38 ± 6.58 years; 35 females, 24.11 ± 4.03 years) took part in a multi-agent session (with 3–5 participants per session). Preliminary analyses indicate that participants show greater motivation and experience more positive affect when tasks provide direct benefits to themselves. Data analysis is ongoing, and final results will be presented at the conference.","Individuals choose between available options based on their respective values. Valuation is thus a core affective process involved in decision-making. Crucially, this process is not purely objective but can rather depend on various factors including goals, emotions, and contexts. Recent studies in individual decision-making have captured the subjective aspect of valuation with paradigms manipulating outcome contexts and showing that action values are estimated with respect to potentially achievable outcomes. Yet, the computational mechanisms underlying subjective valuation and how they unfold in joint action contexts remain unclear. In particular, since joint action implies taking partners into account in one's action planning, differences in the partner's available rewards can be expected to affect decision-making. In this work, we will present an experiment investigating value-based decision-making in a collaborative setting. We will also examine whether existing computational models can account for subjective valuation in such joint action contexts. Thus, this study is a first step in understanding how subjective valuation operates in joint action.","The development of emotional intelligence within our educational system largely depends on teachers' interest in emotions. We aim to demonstrate that mastering emotional argumentation and mentalization (Debbané, 2020) deserves greater recognition within the school curriculum. Helping young people articulate their emotions, express themselves, and persuade others of their feelings can mitigate cultural inequalities that reinforce socio-economic disparities and promote exclusion (Breton, 2006). There is no true communication if dialogue does not foster critical thinking, and without communication, there is no education (Freire, 1993). We seek to train pupils from their early school years to develop mentalization skills, considering inter- and intrapersonal trust (Clément, 2010) as fundamental to mastering emotional argumentation, fostering autonomy, and enhancing motivation. Emocube (Gehringer, 2003), a playful tool and social game, facilitates the development of emotional skills and promotes peer inclusion through the free expression of primary emotions. The ability to recognize, understand, and express one's own emotions—as well as those of others—supports behavioural regulation, prevents emotional confusion, and reduces aggression by creating a healthy distance between painful experiences and the present moment, thus fostering empathy (Pons et al., 2004). When taking the TEC2000color test, pupils primarily began with the image of joy, preferring to argue about pleasure while also demonstrating the ability to mentalize fear, sadness, and anger. The use of the Argumentum Model of Topics (AMT) from Rigotti and Greco (2009) provides a framework for analysing children's arguments and assessing the impact of Emocube on their verbal development. Socio-affective communication promotes peer inclusion and improves academic success by fostering a more socially equitable educational system. The ability to mentalize enhances the joy of thinking (Zittoun, 2024), fosters social harmony, and strengthens interpersonal relationships—an essential skill in an era marked by large-scale migratory transitions","The evaluation of candidates during the application process aims to be as objective as possible. For this reason, many companies train their recruiters and educate about bias. \nDespite this continuous effort some biases are difficult to control and mostly remain nonconscious. \nIncidental emotions influence decisions through carryover processes from previous and unrelated situations. \nFollowing the Appraisal Tendency Framework (ATF) the impact of specific emotions derives from cognitive and motivational processes, influencing the content and dept of thought. This present study aims to investigate incidental emotions in the context of job interviews, which may act as an everyday bias in the assessment of job candidates. \nAccording to the ATF, happiness and anger, associated with the appraisal of certainty, are leading to a more heuristic processing. Thus, both emotions are more likely to act as information and be included in the evaluation of the candidate. \nTherefore, the incidental emotion of happiness should lead to a significantly higher rating of a job candidate than anger. As sadness is linked to the appraisal of uncertainty, research has shown that this emotion promotes systematic processing. \nWith regard to previous findings, the present study hypothesizes that sadness will lead to a significantly higher rating of candidates than anger, although both emotions originate from negative valence. Testing the hypotheses in the three conditions anger, happiness and sadness the emotions will be induced by a memory recall and writing task for the participants. \nAfter measuring the emotionality, each participant will receive the same video of a job interview. Subsequently, the attitude toward the job candidate, the candidate's employability and other control variables will be measured. This study aims to provide initial data on the presence of incidental emotions in the process of job interviews. Results could potentially increase awareness of subconscious biases and inform future research.","The notion that emotions influence attentional breadth has inspired extensive research. However, recent studies have produced mixed results. We present findings from two studies encompassing four high-powered web experiments that examined the effects of emotion on attentional breadth using different emotional manipulations and attention measures. In the first study, we manipulated the goal conduciveness and power appraisals in a game-like task and assessed their impact on attentional breadth, measured by the flanker (n = 236) and Navon tasks (n = 215). While high power appraisals enhanced overall task performance, neither appraisal dimension influenced attentional breadth. Furthermore, additional analysis of valence and motivational intensity effects yield no significant results. In the second study, we used autobiographical recall (n = 196) and affective images (n = 200) to evoke positive and negative states. Attentional breadth was measured with the Navon task coupled with induction sensitivity and mouse tracking analyses. We again did not find robust effects of emotional states on attentional breadth. Instead, negative imagery led to a slight broadening of attention (β = 0.014, β = 0.021, p < .05) and higher control (β = 0.009, p = .03) and goal-congruence (β = 0.004, p = .02) appraisals showed modest associations with broad attention. Overall, findings from these two studies contribute to a growing body of null results, underscoring the importance of further research to establish clearer boundary conditions for emotional influences on attentional breadth and calling for replication and theoretical refinement in this complex field.","Decision-making is a key topic in cognitive sciences and neuroeconomics. While many studies have analyzed individual performance in the Iowa Gambling Task (IGT), few have examined the physiological manifestations during the task and their alignment with participants' strategies. This study aimed to investigate decision-making under uncertainty in a stress-free environment (free from time constraints or emotional interventions) using a modified IGT. Twenty-eight participants (12 men, 16 women; age range: 21.96 ± 3.82 years) completed the task in five stages, with 50 trials in each stage. Four physiological signals were recorded: BVP (Blood Volume Pulse), temperature, Resp (Respiration), and SCR (Skin Conductance Response). The average selection time decreased across stages. At first, participants preferred disadvantageous cards (A and B) but gradually shifted to advantageous cards (C and D). Initial stages showed an increase in body temperature, and an LF/HF ratio above one, indicating increased sympathetic activity and physiological stress. As the task progressed, individuals adapted to the rules and adopted more optimal strategies. Stage 4 marked a turning point, with significant decreases in SCR and an LF/HF ratio below one, reflecting reduced stress. In the final stage, decreased BVP and an LF/HF ratio of one indicated a balance between the sympathetic and parasympathetic systems. Finally, it can be acknowledged that the task structure was useful in identifying the roles of the cards. Additionally, advancing in conditions of uncertainty through decision-making reflects a dynamic balance between neural systems related to reward and stress.  Keywords: Decision-making, Uncertainty, Physiological manifestations, Gambling strategies, Iowa Gambling Task, adaptation","Music listeners have been the subject of numerous studies to understand their behaviours and preferences in response to composers' creative output. No previous research, however, has directly compared composers' intentions and techniques with listener evaluations. This is partly the result of a majority of previous empirical studies into music listening relying on college student and general population samples, which might not have the consistent expertise necessary to reliably evaluate the technical mechanics of original compositions as well as other psychological effects (Berlyne, 1974; Simonton, 2010). Responding to this gap in the literature, the present study compared the predictive effects of 47 composers' affective intentions and felt emotions on a panel of expert listeners' evaluations of the specific emotional impact of their original compositions. Composers were asked to rate their feelings and intentions using the adjective format of Yik and colleagues' (2011) 12-Point Affect Circumplex (12-PAC) as well as an aesthetic emotion item. Experts rated their responses using the same adjective items. We found that both composer intentions and composer felt emotions were significantly correlated with expert ratings for all affect items. There were stronger standard effects (β) for intended than felt emotions, suggesting that expert listener responses are primarily driven by the affective content composers intend to convey, but that, to a lesser but still significant extent, composers' ambient felt emotions also play a role in determining how listeners respond to their music. This study demonstrates the importance of examining both composer and listener effects and paves the way for future research that should examine the locus of emotion in both composers and listeners with greater precision.","Emotional prosody recognition — the ability to interpret emotions conveyed through pitch, rhythm, and dynamic intonation profiles — is crucial for children's social and emotional development. This study examined emotional prosody recognition in 7-8-year-old children, focusing on the influence of musical skills, gender differences, and affective-motivational traits. A total of 649 children (280 girls) were exposed to linguistically meaningless stimuli expressing four emotions (anger, fear, happiness, sadness) and neutral expressions. Participants rated the type and intensity of perceived emotions on continuous scales, and their musical abilities were assessed. Additional data on affective, motivational, and musical characteristics were collected via questionnaires. Findings reveal a clear hierarchy in emotion recognition accuracy in childhood, with anger (M = 3.28, p < .001) and joy (M = 2.28, p < .001) as the most recognizable emotions. A significant gender effect was observed, with girls outperforming boys in overall emotion recognition (p = .045), particularly for negative emotions such as fear (p = .045) and sadness (p = .045). Emotional prosody recognition was significantly correlated with both melodic (.18) and rhythmic abilities (.20), with stronger associations observed for anger and sadness, for the latter only with rhythmic ability sadness. Additionally, musical reward sensitivity, empathy, attention, and extrinsic motivation were positively associated with emotion recognition. Gender differences emerged in these relationships, with girls showing stronger correlations with motivation-related variables (.19) and boys demonstrating stronger links with empathy-related traits (.15). This study is the first to investigate in detail the factors influencing emotional prosody recognition in a large sample of 7-8-year-old children, highlighting the critical role of musical abilities and sensitivity. The findings suggest early musical training as a promising tool to support emotional development in young children.","University education involves discipline-specific ways of knowing and is an affective, evaluative process where moral emotions shape experiences for both students and teachers. Emotions such as shame, guilt, pride, and elevation influence moral development and professional identity formation, particularly in ethically significant disciplines. While research has explored emotions in motivation and achievement (Pekrun, 2006; Eynde & Turner, 2006), moral emotions remain understudied in academic life. Drawing on moral psychology (Haidt, 2003; Gray & Wegner, 2011) and empirical studies on moral emotions (Tangney et al., 2007), this paper examines how teachers regulate moral norms, embody values, and navigate ethical dilemmas in pedagogy. We also analyze how students experience moral emotions in response to feedback, assessment, and peer interactions. Klafki's concept of Bildung emphasizes autonomy and long-term moral growth, while moral emotions serve as immediate, socially embedded responses reinforcing norms. We explore whether Bildung fosters self-reflection beyond immediate emotional reactions. \nUsing a narrative and microphenomenological case study, preliminary findings suggest moral emotions play a dual role: shame may hinder engagement, while guilt can foster ethical responsibility. Likewise, emotions like elevation and admiration—elicited by witnessing acts of virtue, including scientific excellence—enhance motivation. These findings highlight the need for pedagogical frameworks that integrate moral emotions into a spiral curriculum centered on Bildung and professional identity development. Rather than offering stand-alone ethics or well-being courses, universities should embed discussions of moral emotions across disciplines. By mapping their role in learning, this research contributes to understanding how academic environments shape moral sensibilities and professional identities.","This work presents CambiaColore, a movement-based technology for emotional expression in children. Co-designed with teachers and educators, it provides teachers with an engaging tool for socio-emotional learning. Recognizing, regulating, and expressing emotions are key skills that foster self-regulation, well-being, and social integration. Many classroom curricula address these abilities, yet research shows teachers often lack confidence in implementing them. Technology can help by offering engaging ways to support socio-emotional learning by helping students better grasp the complexity behind these abilities. Following these premises, we co-designed CambiaColore, to foster emotional reflection and expression in the classroom in primary school children. The system consists of: a computer, a glass table, a retroreflective paint roller, a camera, and a projector. Users interact by rolling the paint roller over specific areas on the table, each corresponding to an emotion-associated color, and by moving the roller to create digital paintings that visually represent their feelings. Designed for group settings, it generates a final collective canvas displaying the class's emotions. Saved drawings can be used for further discussion on emotional antecedents and how group emotions shape the overall picture (i.e. the emotional atmosphere of the classroom). CambiaColore aims to help children name, express, and accept all emotions, including negative ones, reinforcing self-awareness and emotional regulation. It also encourages movement-based emotional expression, highlighting the link between emotions and bodily states, and helps students understand the interplay between their emotions and those of their peers. Moreover, CambiaColore will be used to collect a dataset of children's drawings, associated emotions (as verbally expressed by the children), and movement data. This dataset will enable studies on the relationship between color choices, drawing characteristics, and emotional states (both at the individual and group level), potentially enhancing the system with feedback features to help teachers better understand and support students' emotions.","Pursuing multiple identity goals among women in Science, Technology, Engineering, and Mathematics (STEM) often involves striving to excel as both competent STEM professionals and feminine individuals. Success in attaining identity goal-relevant symbols fosters a sense of completeness, while failure results in incompleteness, leading to distinct affective outcomes. In two empirical studies, we examined women's emotional states in STEM experiencing completeness and/or incompleteness in the dual identity goals of femininity and STEM professionalism. In Study 1, findings revealed that failure in both femininity and STEM identity goals elicited greater guilt and diminished pride compared to achieving self-completion in at least one identity goal. Study 2 further explored compensatory mechanisms, showing that women who were incomplete in either femininity or STEM professionalism and were given opportunities to engage in compensatory activities reported lower guilt than those without such opportunities. Notably, no differences were observed based on the specific nature of the identity goal (femininity or STEM professionalism). We discuss the nature of compensatory effects concerning affective outcomes when pursuing identity goals. ","We present DiffuseFace, a database of AI-generated face portraits designed to address the limitations of traditional databases and enhance diversity in emotion studies. Traditional databases, such as CEED (Benda & Scherf, 2020) and FACES (Ebner et al., 2010), typically include photographs of real actors captured in controlled environments. While these stimuli have proven invaluable, their creation demands substantial time and financial resources and raises privacy concerns related to material sharing. These constraints may contribute to the limited representation of ethnicities and facial expressions in such databases, ultimately reducing diversity and potentially hampering the generalizability of findings (Barrett et al., 2019). Recently, psychological research has highlighted the potential of generative AI (Demszky et al., 2023) in advancing research methodologies. We extend this approach to emotion research by leveraging generative AI to create a large, diverse face database with reduced costs and fewer constraints compared to traditional methods. DiffuseFace comprises 600 portraits of women and men from 20 nationalities, displaying 14 distinct emotional expressions (e.g., amusement, shame) and a neutral pose, generated using the open-source Stable Diffusion model. Building on prior research (Holland et al., 2019), we will collect data on attitudes toward generative AI, perceived realism, and emotion recognition ratings from 500 U.S. participants. We will also evaluate whether AI-generated stimuli are comparable to real-actor portraits in characteristics critical to emotion research. Preliminary data collected from 260 individuals indicate that these AI-generated faces are perceived as highly realistic and that their emotional expressions are generally well-recognized. These findings underscore the potential of generative AI to produce diverse, high-quality stimuli efficiently, improving the generalizability of psychological and emotion research.","Difficulties with positive emotion have been described across a variety of clinical conditions. Yet few studies have systematically reviewed the role of positive emotions in autism spectrum conditions. A scoping review on positive emotions in autism can potentially detect preserved or even enhanced positive emotions in this population and shed light on the similarities and differences between individuals with and without autism.","The emotional correlates of anxiety and depression have been extensively studied due to their substantial overlap. While a growing body of research has explored their relationship with affective processes, there is limited research on how co-occurring symptoms interact with emotional dynamics at subclinical level. Drawing from recent empirical findings on the core components within the anxiety-depression symptom network, we propose an expanded tripartite model, incorporating perceived control alongside positive (PA) and negative affect (NA). We hypothesized that subclinical anxiety and depression symptom severity and co-occurrence would influence the experience of NA, PA, and the level of perceived control across several emotional episodes, not limited to those elicited by negative stimuli.     The objective of the present study is to examine the differences in consecutive phases of an emotion induction task between low risk, depression risk, anxiety risk and comorbid risk groups. A sample of 284 individuals without diagnosed psychiatric disorders were presented movie clips to elicit neutral, negative and positive emotions. We inserted a recovery period to assess how participants would return to an emotional equilibrium after negative stimuli, Participants rated their emotional experience and perceived control at baseline and after each stimulus using PANAS.    Our findings indicated that participants with anxiety, depression, or comorbid risk differed in NA, PA and perceived control measured at baseline and after recovery with the largest differences between the low risk and comorbid risk groups. The results also show that NA, PA and perceived control during emotional episodes successfully predict the inclusion in low and high-risk groups presenting independent or co-occuring symptoms. By highlighting the patterns between emotional dynamics and affective symptoms, this study offers a valuable insight on how laboratory experiments could be of great importance in detecting at-risk individuals for anxiety, depression and co-occuring symptoms. ","It has long been recognized that dissociative processing is common in the general population and constitutes a transdiagnostic factor in mental health disorders. One of its core features is the transient inability to feel emotions, a phenomenon often referred to as emotional numbing. In the past, most studies investigating emotional numbing induced a dissociative state in their participants by reactivating a previous dissociative reaction the person exhibited during a traumatic event. Therefore, most experimental studies employed a script-driven imagery paradigm during which the participant is asked to re-imagine the worst moment during the traumatic event. We will present three studies that employed dissociative induction techniques unrelated to traumatic experiences, which are less aversive in nature and circumvent potential confounders such as initial upregulation of physiological arousal. In total, N = 688 first year university students underwent a dissociation induction and recorded their acute dissociative reactions via self-report. Two different dissociation inductions were used: an interpersonal eye gazing task during reduced illumination (n = 404) and a prolonged, passive scrolling task using digital material (n = 284). Both were conceptualized to induce a form of trance characterized by depersonalization, derealization and emotional numbing. The extent of this reaction will be analyzed regarding several potential predictors including childhood trauma, trait tendencies to dissociate, emotional reactivity, and attachment patterns. Results will be presented at the conference."],"Group":["Emotion Regulation 3","Emotion Regulation 3","Emotion Regulation 3","Emotion Regulation 3","Specific Emotions","Specific Emotions","Specific Emotions","Specific Emotions","Dimensions of Emotions/Arousal and Valence","Dimensions of Emotions/Arousal and Valence","Dimensions of Emotions/Arousal and Valence","Dimensions of Emotions/Arousal and Valence","Dimensions of Emotions/Arousal and Valence","Dimensions of Emotions/Arousal and Valence","Emotions and Social Relations 2","Emotions and Social Relations 2","Emotions and Social Relations 2","Cognition and Emotion 2","Cognition and Emotion 2","Cognition and Emotion 2","Cognition and Emotion 2","Cognition and Emotion 2","Music and Emotion","Music and Emotion","Emotions and educational psychology","Emotions and educational psychology","Emotions and educational psychology","AI and Emotion","Mental health","Mental health","Mental health"]},"columns":[{"id":"Title","name":"Title","type":"character","minWidth":400},{"id":"Authors","name":"Authors","type":"character","minWidth":200},{"id":"Abstract","name":"","type":"character","sortable":false,"cell":[{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]},{"name":"button","attribs":{},"children":["Show Abstract"]}]},{"id":"Group","name":"Group","type":"character","minWidth":200}],"groupBy":["Group"],"searchable":true,"pagination":false,"defaultExpanded":true,"onClick":"function(rowInfo, column) {window.alert(rowInfo.values['Abstract'])}","highlight":true,"rowStyle":"function(rowInfo) {\n    if (rowInfo.subRows.length) {\n      return { borderBottom: '3px solid #E84E0F' }\n    }\n  }","dataKey":"caa9532499f9b037ae7ea30ba12e5cc0"},"children":[]},"class":"reactR_markup"},"evals":["tag.attribs.onClick","tag.attribs.rowStyle"],"jsHooks":[]}</script>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/www\.cere2025\.com\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><img src="https://www.univ-grenoble-alpes.fr/uas/SITEUI/UGA_LOGO_PAGE_INTERIEURE/logo_epe_blanc_sans_marges.svg" class="img-fluid" width="150"></p>
</div>   
    <div class="nav-footer-center">
<p>#CERE2025<br> Université Grenoble Alpes, July 16-18, 2025<br></p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.isre.org/mpage/cere">
      <i class="bi bi-globe" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/CERE_Emotion">
      <i class="bi bi-twitter-x" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.instagram.com/CERE_Emotion/">
      <i class="bi bi-instagram" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>